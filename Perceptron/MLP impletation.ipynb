{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f015783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ec18e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of predictions: 0.33\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'We enjoyed our stay so much. The weather was not great, but everything else was perfect',\n",
    "    'Going to think twice before staying here again. The wifi was spotty and the rooms smaller than advertised',\n",
    "    'The perfect place to relax and recharge',\n",
    "    'Never had such a relaxing vacation.',\n",
    "    'The pictures were misleading, so I was expecting the common areas to be bigger. But the service was good',\n",
    "    'There were no clean linens when I got to my room and the breakfast options were not that many',\n",
    "    'Was expecting it to be a bit far from historical downtown, but it was almost impossible to drive through those narrow roads',\n",
    "    'I thought that waking up with the chickens was fun, but I was wrong',\n",
    "    'Great place for a quick getaway from the city. Everyone is friendly and polite',\n",
    "    'Unfortunately it was raining during our stay, and there weren\\'t many options for indoors activities. Everything was great, but there was literally no other options besides being in the rain',\n",
    "    'The town festival was postponed, so the area was a complete ghost twon. We were the only guests. Not the experience I was looking for.',\n",
    "    'We had a lovely time. It\\'s a fantastic place to go with the children, they loved all the animals.',\n",
    "    'A little bit off the beaten track, but completely worth it. You can hear the birds sing in the morning and then you are greeted with the biggest, sincerest smiles from the owners. Loved it!',\n",
    "    'It was good to be outside in the country, visiting old town. Everything was prepared to the upmost detail.',\n",
    "    'Staff was friendly. Going to come back for sure',\n",
    "    'They didn\\t have enough staff for the amount of guests. It tooj some time to get our breakfastand we had to wait 20 minutes to get more information about the old town',\n",
    "    'The pictures looked way different',\n",
    "    'Best weekend in the countrside I\\'ve ever had.',\n",
    "    'Terrible, Slow staff, slow town. Only good thing was being surrounded by nature.',\n",
    "    'Not as clean as advertised. Found some cobwebs in the corner of the room',\n",
    "    'It was a peaceful getaway in the countryside',\n",
    "    'Everyone was nice. Had a good time.'\n",
    "    'The kids loved running around in nature, we loved the old town. Definitely going back.',  \n",
    "    'Had worse experience',\n",
    "    'Surprised this was much different than what was on the website.',\n",
    "    'Not that mindblowing',\n",
    "    \n",
    "]\n",
    "\n",
    "targets = [1,0,1,1,1,0,0,0,1,0,0,1,1,1,0,0,1,0,0,1,1,1,1,0,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, targets, test_size=0.1, random_state=123)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, norm='l1')\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = Perceptron(random_state=457)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "score = np.round(metrics.accuracy_score(y_test, predictions), 2)\n",
    "\n",
    "print(\"Mean accuracy of predictions: \" +str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2719b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f02f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831c3bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 87)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba8f6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPreceptron(X_train, X_test, y_train, y_test, num_neurons=2):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes = num_neurons, max_iter = 35, activation='relu', solver='sgd',verbose=10, random_state=762, learning_rate='invscaling')\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(X_test)\n",
    "    score = np.round(metrics.accuracy_score(y_test, predictions), 2)\n",
    "\n",
    "    print(\"Mean accuracy of predictions: \" +str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dd15052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69612600\n",
      "Iteration 2, loss = 0.69611779\n",
      "Iteration 3, loss = 0.69611258\n",
      "Iteration 4, loss = 0.69610749\n",
      "Iteration 5, loss = 0.69610248\n",
      "Iteration 6, loss = 0.69609758\n",
      "Iteration 7, loss = 0.69609280\n",
      "Iteration 8, loss = 0.69608816\n",
      "Iteration 9, loss = 0.69608367\n",
      "Iteration 10, loss = 0.69607933\n",
      "Iteration 11, loss = 0.69607513\n",
      "Iteration 12, loss = 0.69607107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n"
     ]
    }
   ],
   "source": [
    "buildPreceptron(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4faa2cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71364975\n",
      "Iteration 2, loss = 0.71361024\n",
      "Iteration 3, loss = 0.71358517\n",
      "Iteration 4, loss = 0.71356064\n",
      "Iteration 5, loss = 0.71353654\n",
      "Iteration 6, loss = 0.71351296\n",
      "Iteration 7, loss = 0.71348999\n",
      "Iteration 8, loss = 0.71346768\n",
      "Iteration 9, loss = 0.71344607\n",
      "Iteration 10, loss = 0.71342517\n",
      "Iteration 11, loss = 0.71340498\n",
      "Iteration 12, loss = 0.71338549\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n"
     ]
    }
   ],
   "source": [
    "buildPreceptron(X_train, X_test, y_train, y_test, num_neurons=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63efd144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69381674\n",
      "Iteration 2, loss = 0.69379509\n",
      "Iteration 3, loss = 0.69378136\n",
      "Iteration 4, loss = 0.69376793\n",
      "Iteration 5, loss = 0.69375473\n",
      "Iteration 6, loss = 0.69374182\n",
      "Iteration 7, loss = 0.69372925\n",
      "Iteration 8, loss = 0.69371703\n",
      "Iteration 9, loss = 0.69370521\n",
      "Iteration 10, loss = 0.69369377\n",
      "Iteration 11, loss = 0.69368272\n",
      "Iteration 12, loss = 0.69367206\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n"
     ]
    }
   ],
   "source": [
    "buildPreceptron(X_train, X_test, y_train, y_test, num_neurons=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b840df6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69807704\n",
      "Iteration 2, loss = 0.69806607\n",
      "Iteration 3, loss = 0.69805911\n",
      "Iteration 4, loss = 0.69805229\n",
      "Iteration 5, loss = 0.69804559\n",
      "Iteration 6, loss = 0.69803903\n",
      "Iteration 7, loss = 0.69803263\n",
      "Iteration 8, loss = 0.69802642\n",
      "Iteration 9, loss = 0.69802040\n",
      "Iteration 10, loss = 0.69801457\n",
      "Iteration 11, loss = 0.69800894\n",
      "Iteration 12, loss = 0.69800350\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n"
     ]
    }
   ],
   "source": [
    "buildPreceptron(X_train, X_test, y_train, y_test, num_neurons=146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efeb5009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Iteration 1, loss = 0.78718555\n",
      "Iteration 2, loss = 0.78707669\n",
      "Iteration 3, loss = 0.78700763\n",
      "Iteration 4, loss = 0.78694003\n",
      "Iteration 5, loss = 0.78687362\n",
      "Iteration 6, loss = 0.78680866\n",
      "Iteration 7, loss = 0.78674536\n",
      "Iteration 8, loss = 0.78668389\n",
      "Iteration 9, loss = 0.78662434\n",
      "Iteration 10, loss = 0.78656674\n",
      "Iteration 11, loss = 0.78651110\n",
      "Iteration 12, loss = 0.78645740\n",
      "Iteration 13, loss = 0.78640560\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "2\n",
      "Iteration 1, loss = 0.69612600\n",
      "Iteration 2, loss = 0.69611779\n",
      "Iteration 3, loss = 0.69611258\n",
      "Iteration 4, loss = 0.69610749\n",
      "Iteration 5, loss = 0.69610248\n",
      "Iteration 6, loss = 0.69609758\n",
      "Iteration 7, loss = 0.69609280\n",
      "Iteration 8, loss = 0.69608816\n",
      "Iteration 9, loss = 0.69608367\n",
      "Iteration 10, loss = 0.69607933\n",
      "Iteration 11, loss = 0.69607513\n",
      "Iteration 12, loss = 0.69607107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "3\n",
      "Iteration 1, loss = 0.71631376\n",
      "Iteration 2, loss = 0.71628767\n",
      "Iteration 3, loss = 0.71627111\n",
      "Iteration 4, loss = 0.71625490\n",
      "Iteration 5, loss = 0.71623898\n",
      "Iteration 6, loss = 0.71622340\n",
      "Iteration 7, loss = 0.71620821\n",
      "Iteration 8, loss = 0.71619347\n",
      "Iteration 9, loss = 0.71617918\n",
      "Iteration 10, loss = 0.71616536\n",
      "Iteration 11, loss = 0.71615201\n",
      "Iteration 12, loss = 0.71613912\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "4\n",
      "Iteration 1, loss = 0.84369167\n",
      "Iteration 2, loss = 0.84340893\n",
      "Iteration 3, loss = 0.84322962\n",
      "Iteration 4, loss = 0.84305416\n",
      "Iteration 5, loss = 0.84288182\n",
      "Iteration 6, loss = 0.84271326\n",
      "Iteration 7, loss = 0.84254908\n",
      "Iteration 8, loss = 0.84238968\n",
      "Iteration 9, loss = 0.84223528\n",
      "Iteration 10, loss = 0.84208600\n",
      "Iteration 11, loss = 0.84194183\n",
      "Iteration 12, loss = 0.84180271\n",
      "Iteration 13, loss = 0.84166854\n",
      "Iteration 14, loss = 0.84153918\n",
      "Iteration 15, loss = 0.84141445\n",
      "Iteration 16, loss = 0.84129417\n",
      "Iteration 17, loss = 0.84117816\n",
      "Iteration 18, loss = 0.84106622\n",
      "Iteration 19, loss = 0.84095816\n",
      "Iteration 20, loss = 0.84085379\n",
      "Iteration 21, loss = 0.84075292\n",
      "Iteration 22, loss = 0.84065537\n",
      "Iteration 23, loss = 0.84056097\n",
      "Iteration 24, loss = 0.84046955\n",
      "Iteration 25, loss = 0.84038095\n",
      "Iteration 26, loss = 0.84029501\n",
      "Iteration 27, loss = 0.84021160\n",
      "Iteration 28, loss = 0.84013058\n",
      "Iteration 29, loss = 0.84005181\n",
      "Iteration 30, loss = 0.83997518\n",
      "Iteration 31, loss = 0.83990056\n",
      "Iteration 32, loss = 0.83982786\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "5\n",
      "Iteration 1, loss = 0.71364975\n",
      "Iteration 2, loss = 0.71361024\n",
      "Iteration 3, loss = 0.71358517\n",
      "Iteration 4, loss = 0.71356064\n",
      "Iteration 5, loss = 0.71353654\n",
      "Iteration 6, loss = 0.71351296\n",
      "Iteration 7, loss = 0.71348999\n",
      "Iteration 8, loss = 0.71346768\n",
      "Iteration 9, loss = 0.71344607\n",
      "Iteration 10, loss = 0.71342517\n",
      "Iteration 11, loss = 0.71340498\n",
      "Iteration 12, loss = 0.71338549\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "6\n",
      "Iteration 1, loss = 0.70839019\n",
      "Iteration 2, loss = 0.70835482\n",
      "Iteration 3, loss = 0.70833238\n",
      "Iteration 4, loss = 0.70831042\n",
      "Iteration 5, loss = 0.70828885\n",
      "Iteration 6, loss = 0.70826775\n",
      "Iteration 7, loss = 0.70824719\n",
      "Iteration 8, loss = 0.70822722\n",
      "Iteration 9, loss = 0.70820789\n",
      "Iteration 10, loss = 0.70818918\n",
      "Iteration 11, loss = 0.70817112\n",
      "Iteration 12, loss = 0.70815369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "7\n",
      "Iteration 1, loss = 0.76600760\n",
      "Iteration 2, loss = 0.76591658\n",
      "Iteration 3, loss = 0.76585884\n",
      "Iteration 4, loss = 0.76580231\n",
      "Iteration 5, loss = 0.76574678\n",
      "Iteration 6, loss = 0.76569244\n",
      "Iteration 7, loss = 0.76563951\n",
      "Iteration 8, loss = 0.76558809\n",
      "Iteration 9, loss = 0.76553828\n",
      "Iteration 10, loss = 0.76549010\n",
      "Iteration 11, loss = 0.76544356\n",
      "Iteration 12, loss = 0.76539864\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "8\n",
      "Iteration 1, loss = 0.69381674\n",
      "Iteration 2, loss = 0.69379509\n",
      "Iteration 3, loss = 0.69378136\n",
      "Iteration 4, loss = 0.69376793\n",
      "Iteration 5, loss = 0.69375473\n",
      "Iteration 6, loss = 0.69374182\n",
      "Iteration 7, loss = 0.69372925\n",
      "Iteration 8, loss = 0.69371703\n",
      "Iteration 9, loss = 0.69370521\n",
      "Iteration 10, loss = 0.69369377\n",
      "Iteration 11, loss = 0.69368272\n",
      "Iteration 12, loss = 0.69367206\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "9\n",
      "Iteration 1, loss = 0.78057794\n",
      "Iteration 2, loss = 0.78040620\n",
      "Iteration 3, loss = 0.78029728\n",
      "Iteration 4, loss = 0.78019072\n",
      "Iteration 5, loss = 0.78008605\n",
      "Iteration 6, loss = 0.77998369\n",
      "Iteration 7, loss = 0.77988398\n",
      "Iteration 8, loss = 0.77978719\n",
      "Iteration 9, loss = 0.77969343\n",
      "Iteration 10, loss = 0.77960279\n",
      "Iteration 11, loss = 0.77951525\n",
      "Iteration 12, loss = 0.77943078\n",
      "Iteration 13, loss = 0.77934933\n",
      "Iteration 14, loss = 0.77927079\n",
      "Iteration 15, loss = 0.77919506\n",
      "Iteration 16, loss = 0.77912205\n",
      "Iteration 17, loss = 0.77905163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "10\n",
      "Iteration 1, loss = 0.69959198\n",
      "Iteration 2, loss = 0.69956607\n",
      "Iteration 3, loss = 0.69954963\n",
      "Iteration 4, loss = 0.69953352\n",
      "Iteration 5, loss = 0.69951769\n",
      "Iteration 6, loss = 0.69950220\n",
      "Iteration 7, loss = 0.69948710\n",
      "Iteration 8, loss = 0.69947243\n",
      "Iteration 9, loss = 0.69945821\n",
      "Iteration 10, loss = 0.69944446\n",
      "Iteration 11, loss = 0.69943116\n",
      "Iteration 12, loss = 0.69941832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "11\n",
      "Iteration 1, loss = 0.70014510\n",
      "Iteration 2, loss = 0.70011327\n",
      "Iteration 3, loss = 0.70009307\n",
      "Iteration 4, loss = 0.70007331\n",
      "Iteration 5, loss = 0.70005389\n",
      "Iteration 6, loss = 0.70003489\n",
      "Iteration 7, loss = 0.70001638\n",
      "Iteration 8, loss = 0.69999841\n",
      "Iteration 9, loss = 0.69998100\n",
      "Iteration 10, loss = 0.69996416\n",
      "Iteration 11, loss = 0.69994790\n",
      "Iteration 12, loss = 0.69993220\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "12\n",
      "Iteration 1, loss = 0.69597786\n",
      "Iteration 2, loss = 0.69597194\n",
      "Iteration 3, loss = 0.69596818\n",
      "Iteration 4, loss = 0.69596450\n",
      "Iteration 5, loss = 0.69596088\n",
      "Iteration 6, loss = 0.69595734\n",
      "Iteration 7, loss = 0.69595389\n",
      "Iteration 8, loss = 0.69595054\n",
      "Iteration 9, loss = 0.69594729\n",
      "Iteration 10, loss = 0.69594415\n",
      "Iteration 11, loss = 0.69594111\n",
      "Iteration 12, loss = 0.69593818\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "13\n",
      "Iteration 1, loss = 0.70619340\n",
      "Iteration 2, loss = 0.70616488\n",
      "Iteration 3, loss = 0.70614678\n",
      "Iteration 4, loss = 0.70612907\n",
      "Iteration 5, loss = 0.70611167\n",
      "Iteration 6, loss = 0.70609464\n",
      "Iteration 7, loss = 0.70607806\n",
      "Iteration 8, loss = 0.70606195\n",
      "Iteration 9, loss = 0.70604635\n",
      "Iteration 10, loss = 0.70603126\n",
      "Iteration 11, loss = 0.70601669\n",
      "Iteration 12, loss = 0.70600262\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "14\n",
      "Iteration 1, loss = 0.68807807\n",
      "Iteration 2, loss = 0.68806799\n",
      "Iteration 3, loss = 0.68806160\n",
      "Iteration 4, loss = 0.68805533\n",
      "Iteration 5, loss = 0.68804918\n",
      "Iteration 6, loss = 0.68804315\n",
      "Iteration 7, loss = 0.68803728\n",
      "Iteration 8, loss = 0.68803158\n",
      "Iteration 9, loss = 0.68802605\n",
      "Iteration 10, loss = 0.68802070\n",
      "Iteration 11, loss = 0.68801553\n",
      "Iteration 12, loss = 0.68801054\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "15\n",
      "Iteration 1, loss = 0.70288499\n",
      "Iteration 2, loss = 0.70285279\n",
      "Iteration 3, loss = 0.70283237\n",
      "Iteration 4, loss = 0.70281239\n",
      "Iteration 5, loss = 0.70279277\n",
      "Iteration 6, loss = 0.70277358\n",
      "Iteration 7, loss = 0.70275488\n",
      "Iteration 8, loss = 0.70273673\n",
      "Iteration 9, loss = 0.70271915\n",
      "Iteration 10, loss = 0.70270215\n",
      "Iteration 11, loss = 0.70268574\n",
      "Iteration 12, loss = 0.70266990\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "16\n",
      "Iteration 1, loss = 0.71171452\n",
      "Iteration 2, loss = 0.71167487\n",
      "Iteration 3, loss = 0.71164971\n",
      "Iteration 4, loss = 0.71162509\n",
      "Iteration 5, loss = 0.71160090\n",
      "Iteration 6, loss = 0.71157723\n",
      "Iteration 7, loss = 0.71155418\n",
      "Iteration 8, loss = 0.71153179\n",
      "Iteration 9, loss = 0.71151010\n",
      "Iteration 10, loss = 0.71148912\n",
      "Iteration 11, loss = 0.71146886\n",
      "Iteration 12, loss = 0.71144930\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "17\n",
      "Iteration 1, loss = 0.72390693\n",
      "Iteration 2, loss = 0.72387228\n",
      "Iteration 3, loss = 0.72385029\n",
      "Iteration 4, loss = 0.72382878\n",
      "Iteration 5, loss = 0.72380765\n",
      "Iteration 6, loss = 0.72378698\n",
      "Iteration 7, loss = 0.72376689\n",
      "Iteration 8, loss = 0.72374748\n",
      "Iteration 9, loss = 0.72372867\n",
      "Iteration 10, loss = 0.72371049\n",
      "Iteration 11, loss = 0.72369294\n",
      "Iteration 12, loss = 0.72367600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "18\n",
      "Iteration 1, loss = 0.69268759\n",
      "Iteration 2, loss = 0.69267747\n",
      "Iteration 3, loss = 0.69267105\n",
      "Iteration 4, loss = 0.69266477\n",
      "Iteration 5, loss = 0.69265859\n",
      "Iteration 6, loss = 0.69265255\n",
      "Iteration 7, loss = 0.69264666\n",
      "Iteration 8, loss = 0.69264094\n",
      "Iteration 9, loss = 0.69263539\n",
      "Iteration 10, loss = 0.69263003\n",
      "Iteration 11, loss = 0.69262485\n",
      "Iteration 12, loss = 0.69261984\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "19\n",
      "Iteration 1, loss = 0.70144738\n",
      "Iteration 2, loss = 0.70142954\n",
      "Iteration 3, loss = 0.70141823\n",
      "Iteration 4, loss = 0.70140716\n",
      "Iteration 5, loss = 0.70139628\n",
      "Iteration 6, loss = 0.70138563\n",
      "Iteration 7, loss = 0.70137526\n",
      "Iteration 8, loss = 0.70136519\n",
      "Iteration 9, loss = 0.70135543\n",
      "Iteration 10, loss = 0.70134600\n",
      "Iteration 11, loss = 0.70133688\n",
      "Iteration 12, loss = 0.70132808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "20\n",
      "Iteration 1, loss = 0.69602412\n",
      "Iteration 2, loss = 0.69600989\n",
      "Iteration 3, loss = 0.69600087\n",
      "Iteration 4, loss = 0.69599203\n",
      "Iteration 5, loss = 0.69598334\n",
      "Iteration 6, loss = 0.69597484\n",
      "Iteration 7, loss = 0.69596655\n",
      "Iteration 8, loss = 0.69595850\n",
      "Iteration 9, loss = 0.69595070\n",
      "Iteration 10, loss = 0.69594315\n",
      "Iteration 11, loss = 0.69593586\n",
      "Iteration 12, loss = 0.69592882\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "21\n",
      "Iteration 1, loss = 0.70664161\n",
      "Iteration 2, loss = 0.70661897\n",
      "Iteration 3, loss = 0.70660460\n",
      "Iteration 4, loss = 0.70659054\n",
      "Iteration 5, loss = 0.70657673\n",
      "Iteration 6, loss = 0.70656322\n",
      "Iteration 7, loss = 0.70655006\n",
      "Iteration 8, loss = 0.70653728\n",
      "Iteration 9, loss = 0.70652490\n",
      "Iteration 10, loss = 0.70651293\n",
      "Iteration 11, loss = 0.70650136\n",
      "Iteration 12, loss = 0.70649020\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "22\n",
      "Iteration 1, loss = 0.72130129\n",
      "Iteration 2, loss = 0.72122757\n",
      "Iteration 3, loss = 0.72118082\n",
      "Iteration 4, loss = 0.72113506\n",
      "Iteration 5, loss = 0.72109012\n",
      "Iteration 6, loss = 0.72104617\n",
      "Iteration 7, loss = 0.72100335\n",
      "Iteration 8, loss = 0.72096178\n",
      "Iteration 9, loss = 0.72092151\n",
      "Iteration 10, loss = 0.72088257\n",
      "Iteration 11, loss = 0.72084497\n",
      "Iteration 12, loss = 0.72080868\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "23\n",
      "Iteration 1, loss = 0.71661764\n",
      "Iteration 2, loss = 0.71657325\n",
      "Iteration 3, loss = 0.71654510\n",
      "Iteration 4, loss = 0.71651754\n",
      "Iteration 5, loss = 0.71649047\n",
      "Iteration 6, loss = 0.71646399\n",
      "Iteration 7, loss = 0.71643819\n",
      "Iteration 8, loss = 0.71641314\n",
      "Iteration 9, loss = 0.71638887\n",
      "Iteration 10, loss = 0.71636540\n",
      "Iteration 11, loss = 0.71634273\n",
      "Iteration 12, loss = 0.71632085\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "24\n",
      "Iteration 1, loss = 0.72175662\n",
      "Iteration 2, loss = 0.72171102\n",
      "Iteration 3, loss = 0.72168210\n",
      "Iteration 4, loss = 0.72165379\n",
      "Iteration 5, loss = 0.72162600\n",
      "Iteration 6, loss = 0.72159881\n",
      "Iteration 7, loss = 0.72157232\n",
      "Iteration 8, loss = 0.72154661\n",
      "Iteration 9, loss = 0.72152171\n",
      "Iteration 10, loss = 0.72149763\n",
      "Iteration 11, loss = 0.72147437\n",
      "Iteration 12, loss = 0.72145193\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "25\n",
      "Iteration 1, loss = 0.70301217\n",
      "Iteration 2, loss = 0.70296040\n",
      "Iteration 3, loss = 0.70292757\n",
      "Iteration 4, loss = 0.70289545\n",
      "Iteration 5, loss = 0.70286391\n",
      "Iteration 6, loss = 0.70283305\n",
      "Iteration 7, loss = 0.70280300\n",
      "Iteration 8, loss = 0.70277383\n",
      "Iteration 9, loss = 0.70274557\n",
      "Iteration 10, loss = 0.70271825\n",
      "Iteration 11, loss = 0.70269187\n",
      "Iteration 12, loss = 0.70266641\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "26\n",
      "Iteration 1, loss = 0.68921988\n",
      "Iteration 2, loss = 0.68920907\n",
      "Iteration 3, loss = 0.68920220\n",
      "Iteration 4, loss = 0.68919548\n",
      "Iteration 5, loss = 0.68918888\n",
      "Iteration 6, loss = 0.68918242\n",
      "Iteration 7, loss = 0.68917612\n",
      "Iteration 8, loss = 0.68917000\n",
      "Iteration 9, loss = 0.68916407\n",
      "Iteration 10, loss = 0.68915833\n",
      "Iteration 11, loss = 0.68915279\n",
      "Iteration 12, loss = 0.68914743\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "27\n",
      "Iteration 1, loss = 0.69783978\n",
      "Iteration 2, loss = 0.69781487\n",
      "Iteration 3, loss = 0.69779907\n",
      "Iteration 4, loss = 0.69778360\n",
      "Iteration 5, loss = 0.69776841\n",
      "Iteration 6, loss = 0.69775355\n",
      "Iteration 7, loss = 0.69773907\n",
      "Iteration 8, loss = 0.69772501\n",
      "Iteration 9, loss = 0.69771138\n",
      "Iteration 10, loss = 0.69769821\n",
      "Iteration 11, loss = 0.69768548\n",
      "Iteration 12, loss = 0.69767320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "28\n",
      "Iteration 1, loss = 0.71154268\n",
      "Iteration 2, loss = 0.71151963\n",
      "Iteration 3, loss = 0.71150500\n",
      "Iteration 4, loss = 0.71149069\n",
      "Iteration 5, loss = 0.71147662\n",
      "Iteration 6, loss = 0.71146286\n",
      "Iteration 7, loss = 0.71144946\n",
      "Iteration 8, loss = 0.71143644\n",
      "Iteration 9, loss = 0.71142383\n",
      "Iteration 10, loss = 0.71141163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.71139985\n",
      "Iteration 12, loss = 0.71138847\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "29\n",
      "Iteration 1, loss = 0.70939206\n",
      "Iteration 2, loss = 0.70934415\n",
      "Iteration 3, loss = 0.70931377\n",
      "Iteration 4, loss = 0.70928404\n",
      "Iteration 5, loss = 0.70925483\n",
      "Iteration 6, loss = 0.70922626\n",
      "Iteration 7, loss = 0.70919843\n",
      "Iteration 8, loss = 0.70917140\n",
      "Iteration 9, loss = 0.70914523\n",
      "Iteration 10, loss = 0.70911991\n",
      "Iteration 11, loss = 0.70909546\n",
      "Iteration 12, loss = 0.70907187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "30\n",
      "Iteration 1, loss = 0.70324266\n",
      "Iteration 2, loss = 0.70323612\n",
      "Iteration 3, loss = 0.70323197\n",
      "Iteration 4, loss = 0.70322791\n",
      "Iteration 5, loss = 0.70322392\n",
      "Iteration 6, loss = 0.70322001\n",
      "Iteration 7, loss = 0.70321620\n",
      "Iteration 8, loss = 0.70321250\n",
      "Iteration 9, loss = 0.70320891\n",
      "Iteration 10, loss = 0.70320544\n",
      "Iteration 11, loss = 0.70320208\n",
      "Iteration 12, loss = 0.70319884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "31\n",
      "Iteration 1, loss = 0.68731878\n",
      "Iteration 2, loss = 0.68730890\n",
      "Iteration 3, loss = 0.68730264\n",
      "Iteration 4, loss = 0.68729650\n",
      "Iteration 5, loss = 0.68729047\n",
      "Iteration 6, loss = 0.68728457\n",
      "Iteration 7, loss = 0.68727883\n",
      "Iteration 8, loss = 0.68727324\n",
      "Iteration 9, loss = 0.68726783\n",
      "Iteration 10, loss = 0.68726259\n",
      "Iteration 11, loss = 0.68725746\n",
      "Iteration 12, loss = 0.68725230\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "32\n",
      "Iteration 1, loss = 0.73947501\n",
      "Iteration 2, loss = 0.73937621\n",
      "Iteration 3, loss = 0.73931355\n",
      "Iteration 4, loss = 0.73925224\n",
      "Iteration 5, loss = 0.73919203\n",
      "Iteration 6, loss = 0.73913314\n",
      "Iteration 7, loss = 0.73907578\n",
      "Iteration 8, loss = 0.73902009\n",
      "Iteration 9, loss = 0.73896615\n",
      "Iteration 10, loss = 0.73891400\n",
      "Iteration 11, loss = 0.73886370\n",
      "Iteration 12, loss = 0.73881516\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "33\n",
      "Iteration 1, loss = 0.70919533\n",
      "Iteration 2, loss = 0.70914608\n",
      "Iteration 3, loss = 0.70911484\n",
      "Iteration 4, loss = 0.70908428\n",
      "Iteration 5, loss = 0.70905425\n",
      "Iteration 6, loss = 0.70902488\n",
      "Iteration 7, loss = 0.70899627\n",
      "Iteration 8, loss = 0.70896849\n",
      "Iteration 9, loss = 0.70894159\n",
      "Iteration 10, loss = 0.70891556\n",
      "Iteration 11, loss = 0.70889043\n",
      "Iteration 12, loss = 0.70886618\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "34\n",
      "Iteration 1, loss = 0.71061282\n",
      "Iteration 2, loss = 0.71059317\n",
      "Iteration 3, loss = 0.71058071\n",
      "Iteration 4, loss = 0.71056850\n",
      "Iteration 5, loss = 0.71055651\n",
      "Iteration 6, loss = 0.71054478\n",
      "Iteration 7, loss = 0.71053334\n",
      "Iteration 8, loss = 0.71052224\n",
      "Iteration 9, loss = 0.71051147\n",
      "Iteration 10, loss = 0.71050106\n",
      "Iteration 11, loss = 0.71049100\n",
      "Iteration 12, loss = 0.71048129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "35\n",
      "Iteration 1, loss = 0.69244962\n",
      "Iteration 2, loss = 0.69244295\n",
      "Iteration 3, loss = 0.69243872\n",
      "Iteration 4, loss = 0.69243458\n",
      "Iteration 5, loss = 0.69243051\n",
      "Iteration 6, loss = 0.69242652\n",
      "Iteration 7, loss = 0.69242264\n",
      "Iteration 8, loss = 0.69241887\n",
      "Iteration 9, loss = 0.69241521\n",
      "Iteration 10, loss = 0.69241167\n",
      "Iteration 11, loss = 0.69240825\n",
      "Iteration 12, loss = 0.69240495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "36\n",
      "Iteration 1, loss = 0.70290080\n",
      "Iteration 2, loss = 0.70287270\n",
      "Iteration 3, loss = 0.70285488\n",
      "Iteration 4, loss = 0.70283743\n",
      "Iteration 5, loss = 0.70282029\n",
      "Iteration 6, loss = 0.70280352\n",
      "Iteration 7, loss = 0.70278719\n",
      "Iteration 8, loss = 0.70277133\n",
      "Iteration 9, loss = 0.70275596\n",
      "Iteration 10, loss = 0.70274109\n",
      "Iteration 11, loss = 0.70272673\n",
      "Iteration 12, loss = 0.70271288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "37\n",
      "Iteration 1, loss = 0.71448965\n",
      "Iteration 2, loss = 0.71443397\n",
      "Iteration 3, loss = 0.71439865\n",
      "Iteration 4, loss = 0.71436410\n",
      "Iteration 5, loss = 0.71433015\n",
      "Iteration 6, loss = 0.71429696\n",
      "Iteration 7, loss = 0.71426462\n",
      "Iteration 8, loss = 0.71423323\n",
      "Iteration 9, loss = 0.71420282\n",
      "Iteration 10, loss = 0.71417342\n",
      "Iteration 11, loss = 0.71414502\n",
      "Iteration 12, loss = 0.71411763\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "38\n",
      "Iteration 1, loss = 0.70194118\n",
      "Iteration 2, loss = 0.70190562\n",
      "Iteration 3, loss = 0.70188307\n",
      "Iteration 4, loss = 0.70186100\n",
      "Iteration 5, loss = 0.70183932\n",
      "Iteration 6, loss = 0.70181811\n",
      "Iteration 7, loss = 0.70179745\n",
      "Iteration 8, loss = 0.70177739\n",
      "Iteration 9, loss = 0.70175797\n",
      "Iteration 10, loss = 0.70173918\n",
      "Iteration 11, loss = 0.70172103\n",
      "Iteration 12, loss = 0.70170352\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "39\n",
      "Iteration 1, loss = 0.70130685\n",
      "Iteration 2, loss = 0.70128729\n",
      "Iteration 3, loss = 0.70127489\n",
      "Iteration 4, loss = 0.70126274\n",
      "Iteration 5, loss = 0.70125081\n",
      "Iteration 6, loss = 0.70123914\n",
      "Iteration 7, loss = 0.70122777\n",
      "Iteration 8, loss = 0.70121673\n",
      "Iteration 9, loss = 0.70120603\n",
      "Iteration 10, loss = 0.70119568\n",
      "Iteration 11, loss = 0.70118569\n",
      "Iteration 12, loss = 0.70117604\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "40\n",
      "Iteration 1, loss = 0.71137706\n",
      "Iteration 2, loss = 0.71134002\n",
      "Iteration 3, loss = 0.71131653\n",
      "Iteration 4, loss = 0.71129354\n",
      "Iteration 5, loss = 0.71127095\n",
      "Iteration 6, loss = 0.71124886\n",
      "Iteration 7, loss = 0.71122733\n",
      "Iteration 8, loss = 0.71120643\n",
      "Iteration 9, loss = 0.71118619\n",
      "Iteration 10, loss = 0.71116661\n",
      "Iteration 11, loss = 0.71114769\n",
      "Iteration 12, loss = 0.71112944\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "41\n",
      "Iteration 1, loss = 0.71284967\n",
      "Iteration 2, loss = 0.71281255\n",
      "Iteration 3, loss = 0.71278905\n",
      "Iteration 4, loss = 0.71276605\n",
      "Iteration 5, loss = 0.71274347\n",
      "Iteration 6, loss = 0.71272138\n",
      "Iteration 7, loss = 0.71269986\n",
      "Iteration 8, loss = 0.71267897\n",
      "Iteration 9, loss = 0.71265873\n",
      "Iteration 10, loss = 0.71263916\n",
      "Iteration 11, loss = 0.71262026\n",
      "Iteration 12, loss = 0.71260186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "42\n",
      "Iteration 1, loss = 0.71144832\n",
      "Iteration 2, loss = 0.71140177\n",
      "Iteration 3, loss = 0.71137224\n",
      "Iteration 4, loss = 0.71134335\n",
      "Iteration 5, loss = 0.71131497\n",
      "Iteration 6, loss = 0.71128721\n",
      "Iteration 7, loss = 0.71126018\n",
      "Iteration 8, loss = 0.71123394\n",
      "Iteration 9, loss = 0.71120856\n",
      "Iteration 10, loss = 0.71118402\n",
      "Iteration 11, loss = 0.71116032\n",
      "Iteration 12, loss = 0.71113746\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "43\n",
      "Iteration 1, loss = 0.69454656\n",
      "Iteration 2, loss = 0.69453162\n",
      "Iteration 3, loss = 0.69452213\n",
      "Iteration 4, loss = 0.69451284\n",
      "Iteration 5, loss = 0.69450372\n",
      "Iteration 6, loss = 0.69449479\n",
      "Iteration 7, loss = 0.69448609\n",
      "Iteration 8, loss = 0.69447763\n",
      "Iteration 9, loss = 0.69446944\n",
      "Iteration 10, loss = 0.69446152\n",
      "Iteration 11, loss = 0.69445386\n",
      "Iteration 12, loss = 0.69444647\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "44\n",
      "Iteration 1, loss = 0.70641534\n",
      "Iteration 2, loss = 0.70636760\n",
      "Iteration 3, loss = 0.70633732\n",
      "Iteration 4, loss = 0.70630769\n",
      "Iteration 5, loss = 0.70627858\n",
      "Iteration 6, loss = 0.70625011\n",
      "Iteration 7, loss = 0.70622238\n",
      "Iteration 8, loss = 0.70619545\n",
      "Iteration 9, loss = 0.70616937\n",
      "Iteration 10, loss = 0.70614415\n",
      "Iteration 11, loss = 0.70611980\n",
      "Iteration 12, loss = 0.70609629\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "45\n",
      "Iteration 1, loss = 0.72912057\n",
      "Iteration 2, loss = 0.72903732\n",
      "Iteration 3, loss = 0.72898453\n",
      "Iteration 4, loss = 0.72893288\n",
      "Iteration 5, loss = 0.72888216\n",
      "Iteration 6, loss = 0.72883255\n",
      "Iteration 7, loss = 0.72878424\n",
      "Iteration 8, loss = 0.72873734\n",
      "Iteration 9, loss = 0.72869192\n",
      "Iteration 10, loss = 0.72864801\n",
      "Iteration 11, loss = 0.72860560\n",
      "Iteration 12, loss = 0.72856469\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "46\n",
      "Iteration 1, loss = 0.70345356\n",
      "Iteration 2, loss = 0.70341933\n",
      "Iteration 3, loss = 0.70339762\n",
      "Iteration 4, loss = 0.70337637\n",
      "Iteration 5, loss = 0.70335550\n",
      "Iteration 6, loss = 0.70333509\n",
      "Iteration 7, loss = 0.70331520\n",
      "Iteration 8, loss = 0.70329589\n",
      "Iteration 9, loss = 0.70327719\n",
      "Iteration 10, loss = 0.70325910\n",
      "Iteration 11, loss = 0.70324163\n",
      "Iteration 12, loss = 0.70322478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "47\n",
      "Iteration 1, loss = 0.69417275\n",
      "Iteration 2, loss = 0.69414710\n",
      "Iteration 3, loss = 0.69413083\n",
      "Iteration 4, loss = 0.69411490\n",
      "Iteration 5, loss = 0.69409925\n",
      "Iteration 6, loss = 0.69408394\n",
      "Iteration 7, loss = 0.69406902\n",
      "Iteration 8, loss = 0.69405454\n",
      "Iteration 9, loss = 0.69404050\n",
      "Iteration 10, loss = 0.69402693\n",
      "Iteration 11, loss = 0.69401382\n",
      "Iteration 12, loss = 0.69400116\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "48\n",
      "Iteration 1, loss = 0.69957168\n",
      "Iteration 2, loss = 0.69954316\n",
      "Iteration 3, loss = 0.69952506\n",
      "Iteration 4, loss = 0.69950736\n",
      "Iteration 5, loss = 0.69948996\n",
      "Iteration 6, loss = 0.69947295\n",
      "Iteration 7, loss = 0.69945637\n",
      "Iteration 8, loss = 0.69944027\n",
      "Iteration 9, loss = 0.69942468\n",
      "Iteration 10, loss = 0.69940960\n",
      "Iteration 11, loss = 0.69939503\n",
      "Iteration 12, loss = 0.69938098\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "49\n",
      "Iteration 1, loss = 0.71680258\n",
      "Iteration 2, loss = 0.71671583\n",
      "Iteration 3, loss = 0.71666064\n",
      "Iteration 4, loss = 0.71660647\n",
      "Iteration 5, loss = 0.71655321\n",
      "Iteration 6, loss = 0.71650111\n",
      "Iteration 7, loss = 0.71645034\n",
      "Iteration 8, loss = 0.71640104\n",
      "Iteration 9, loss = 0.71635336\n",
      "Iteration 10, loss = 0.71630752\n",
      "Iteration 11, loss = 0.71626327\n",
      "Iteration 12, loss = 0.71622057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "50\n",
      "Iteration 1, loss = 0.68962818\n",
      "Iteration 2, loss = 0.68962062\n",
      "Iteration 3, loss = 0.68961582\n",
      "Iteration 4, loss = 0.68961113\n",
      "Iteration 5, loss = 0.68960651\n",
      "Iteration 6, loss = 0.68960199\n",
      "Iteration 7, loss = 0.68959759\n",
      "Iteration 8, loss = 0.68959331\n",
      "Iteration 9, loss = 0.68958916\n",
      "Iteration 10, loss = 0.68958515\n",
      "Iteration 11, loss = 0.68958127\n",
      "Iteration 12, loss = 0.68957752\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "51\n",
      "Iteration 1, loss = 0.68901706\n",
      "Iteration 2, loss = 0.68900798\n",
      "Iteration 3, loss = 0.68900222\n",
      "Iteration 4, loss = 0.68899657\n",
      "Iteration 5, loss = 0.68899103\n",
      "Iteration 6, loss = 0.68898560\n",
      "Iteration 7, loss = 0.68898031\n",
      "Iteration 8, loss = 0.68897517\n",
      "Iteration 9, loss = 0.68897019\n",
      "Iteration 10, loss = 0.68896537\n",
      "Iteration 11, loss = 0.68896071\n",
      "Iteration 12, loss = 0.68895622\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "52\n",
      "Iteration 1, loss = 0.71420394\n",
      "Iteration 2, loss = 0.71415100\n",
      "Iteration 3, loss = 0.71411742\n",
      "Iteration 4, loss = 0.71408457\n",
      "Iteration 5, loss = 0.71405230\n",
      "Iteration 6, loss = 0.71402073\n",
      "Iteration 7, loss = 0.71398999\n",
      "Iteration 8, loss = 0.71396014\n",
      "Iteration 9, loss = 0.71393123\n",
      "Iteration 10, loss = 0.71390328\n",
      "Iteration 11, loss = 0.71387628\n",
      "Iteration 12, loss = 0.71385023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "53\n",
      "Iteration 1, loss = 0.69805986\n",
      "Iteration 2, loss = 0.69805155\n",
      "Iteration 3, loss = 0.69804628\n",
      "Iteration 4, loss = 0.69804112\n",
      "Iteration 5, loss = 0.69803604\n",
      "Iteration 6, loss = 0.69803107\n",
      "Iteration 7, loss = 0.69802623\n",
      "Iteration 8, loss = 0.69802153\n",
      "Iteration 9, loss = 0.69801698\n",
      "Iteration 10, loss = 0.69801259\n",
      "Iteration 11, loss = 0.69800834\n",
      "Iteration 12, loss = 0.69800424\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "54\n",
      "Iteration 1, loss = 0.69200179\n",
      "Iteration 2, loss = 0.69199164\n",
      "Iteration 3, loss = 0.69198519\n",
      "Iteration 4, loss = 0.69197887\n",
      "Iteration 5, loss = 0.69197267\n",
      "Iteration 6, loss = 0.69196659\n",
      "Iteration 7, loss = 0.69196067\n",
      "Iteration 8, loss = 0.69195491\n",
      "Iteration 9, loss = 0.69194934\n",
      "Iteration 10, loss = 0.69194394\n",
      "Iteration 11, loss = 0.69193873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.69193369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "55\n",
      "Iteration 1, loss = 0.69072987\n",
      "Iteration 2, loss = 0.69071119\n",
      "Iteration 3, loss = 0.69069933\n",
      "Iteration 4, loss = 0.69068773\n",
      "Iteration 5, loss = 0.69067632\n",
      "Iteration 6, loss = 0.69066517\n",
      "Iteration 7, loss = 0.69065430\n",
      "Iteration 8, loss = 0.69064374\n",
      "Iteration 9, loss = 0.69063351\n",
      "Iteration 10, loss = 0.69062361\n",
      "Iteration 11, loss = 0.69061405\n",
      "Iteration 12, loss = 0.69060483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "56\n",
      "Iteration 1, loss = 0.69931404\n",
      "Iteration 2, loss = 0.69930069\n",
      "Iteration 3, loss = 0.69929222\n",
      "Iteration 4, loss = 0.69928392\n",
      "Iteration 5, loss = 0.69927577\n",
      "Iteration 6, loss = 0.69926779\n",
      "Iteration 7, loss = 0.69926002\n",
      "Iteration 8, loss = 0.69925246\n",
      "Iteration 9, loss = 0.69924514\n",
      "Iteration 10, loss = 0.69923805\n",
      "Iteration 11, loss = 0.69923121\n",
      "Iteration 12, loss = 0.69922460\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "57\n",
      "Iteration 1, loss = 0.68455680\n",
      "Iteration 2, loss = 0.68454559\n",
      "Iteration 3, loss = 0.68453847\n",
      "Iteration 4, loss = 0.68453150\n",
      "Iteration 5, loss = 0.68452465\n",
      "Iteration 6, loss = 0.68451795\n",
      "Iteration 7, loss = 0.68451142\n",
      "Iteration 8, loss = 0.68450507\n",
      "Iteration 9, loss = 0.68449892\n",
      "Iteration 10, loss = 0.68449297\n",
      "Iteration 11, loss = 0.68448722\n",
      "Iteration 12, loss = 0.68448163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "58\n",
      "Iteration 1, loss = 0.70264846\n",
      "Iteration 2, loss = 0.70263490\n",
      "Iteration 3, loss = 0.70262629\n",
      "Iteration 4, loss = 0.70261787\n",
      "Iteration 5, loss = 0.70260960\n",
      "Iteration 6, loss = 0.70260150\n",
      "Iteration 7, loss = 0.70259361\n",
      "Iteration 8, loss = 0.70258594\n",
      "Iteration 9, loss = 0.70257852\n",
      "Iteration 10, loss = 0.70257133\n",
      "Iteration 11, loss = 0.70256444\n",
      "Iteration 12, loss = 0.70255782\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "59\n",
      "Iteration 1, loss = 0.68810055\n",
      "Iteration 2, loss = 0.68809102\n",
      "Iteration 3, loss = 0.68808497\n",
      "Iteration 4, loss = 0.68807904\n",
      "Iteration 5, loss = 0.68807322\n",
      "Iteration 6, loss = 0.68806752\n",
      "Iteration 7, loss = 0.68806196\n",
      "Iteration 8, loss = 0.68805658\n",
      "Iteration 9, loss = 0.68805136\n",
      "Iteration 10, loss = 0.68804631\n",
      "Iteration 11, loss = 0.68804143\n",
      "Iteration 12, loss = 0.68803671\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "60\n",
      "Iteration 1, loss = 0.69643611\n",
      "Iteration 2, loss = 0.69642515\n",
      "Iteration 3, loss = 0.69641820\n",
      "Iteration 4, loss = 0.69641139\n",
      "Iteration 5, loss = 0.69640470\n",
      "Iteration 6, loss = 0.69639816\n",
      "Iteration 7, loss = 0.69639178\n",
      "Iteration 8, loss = 0.69638558\n",
      "Iteration 9, loss = 0.69637957\n",
      "Iteration 10, loss = 0.69637377\n",
      "Iteration 11, loss = 0.69636815\n",
      "Iteration 12, loss = 0.69636273\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "61\n",
      "Iteration 1, loss = 0.70147900\n",
      "Iteration 2, loss = 0.70146211\n",
      "Iteration 3, loss = 0.70145139\n",
      "Iteration 4, loss = 0.70144089\n",
      "Iteration 5, loss = 0.70143058\n",
      "Iteration 6, loss = 0.70142048\n",
      "Iteration 7, loss = 0.70141065\n",
      "Iteration 8, loss = 0.70140109\n",
      "Iteration 9, loss = 0.70139183\n",
      "Iteration 10, loss = 0.70138287\n",
      "Iteration 11, loss = 0.70137421\n",
      "Iteration 12, loss = 0.70136585\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "62\n",
      "Iteration 1, loss = 0.70222626\n",
      "Iteration 2, loss = 0.70218923\n",
      "Iteration 3, loss = 0.70216575\n",
      "Iteration 4, loss = 0.70214276\n",
      "Iteration 5, loss = 0.70212019\n",
      "Iteration 6, loss = 0.70209811\n",
      "Iteration 7, loss = 0.70207660\n",
      "Iteration 8, loss = 0.70205571\n",
      "Iteration 9, loss = 0.70203548\n",
      "Iteration 10, loss = 0.70201592\n",
      "Iteration 11, loss = 0.70199702\n",
      "Iteration 12, loss = 0.70197879\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "63\n",
      "Iteration 1, loss = 0.70710611\n",
      "Iteration 2, loss = 0.70708553\n",
      "Iteration 3, loss = 0.70707247\n",
      "Iteration 4, loss = 0.70705969\n",
      "Iteration 5, loss = 0.70704714\n",
      "Iteration 6, loss = 0.70703485\n",
      "Iteration 7, loss = 0.70702288\n",
      "Iteration 8, loss = 0.70701126\n",
      "Iteration 9, loss = 0.70699999\n",
      "Iteration 10, loss = 0.70698918\n",
      "Iteration 11, loss = 0.70697890\n",
      "Iteration 12, loss = 0.70696898\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "64\n",
      "Iteration 1, loss = 0.68808820\n",
      "Iteration 2, loss = 0.68806647\n",
      "Iteration 3, loss = 0.68805268\n",
      "Iteration 4, loss = 0.68803918\n",
      "Iteration 5, loss = 0.68802592\n",
      "Iteration 6, loss = 0.68801295\n",
      "Iteration 7, loss = 0.68800031\n",
      "Iteration 8, loss = 0.68798803\n",
      "Iteration 9, loss = 0.68797614\n",
      "Iteration 10, loss = 0.68796463\n",
      "Iteration 11, loss = 0.68795352\n",
      "Iteration 12, loss = 0.68794280\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "65\n",
      "Iteration 1, loss = 0.68929433\n",
      "Iteration 2, loss = 0.68926655\n",
      "Iteration 3, loss = 0.68924893\n",
      "Iteration 4, loss = 0.68923168\n",
      "Iteration 5, loss = 0.68921473\n",
      "Iteration 6, loss = 0.68919816\n",
      "Iteration 7, loss = 0.68918200\n",
      "Iteration 8, loss = 0.68916631\n",
      "Iteration 9, loss = 0.68915111\n",
      "Iteration 10, loss = 0.68913641\n",
      "Iteration 11, loss = 0.68912221\n",
      "Iteration 12, loss = 0.68910851\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "66\n",
      "Iteration 1, loss = 0.69079303\n",
      "Iteration 2, loss = 0.69078393\n",
      "Iteration 3, loss = 0.69077816\n",
      "Iteration 4, loss = 0.69077251\n",
      "Iteration 5, loss = 0.69076696\n",
      "Iteration 6, loss = 0.69076152\n",
      "Iteration 7, loss = 0.69075622\n",
      "Iteration 8, loss = 0.69075108\n",
      "Iteration 9, loss = 0.69074609\n",
      "Iteration 10, loss = 0.69074126\n",
      "Iteration 11, loss = 0.69073660\n",
      "Iteration 12, loss = 0.69073210\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "67\n",
      "Iteration 1, loss = 0.69592805\n",
      "Iteration 2, loss = 0.69591783\n",
      "Iteration 3, loss = 0.69591134\n",
      "Iteration 4, loss = 0.69590499\n",
      "Iteration 5, loss = 0.69589875\n",
      "Iteration 6, loss = 0.69589264\n",
      "Iteration 7, loss = 0.69588669\n",
      "Iteration 8, loss = 0.69588091\n",
      "Iteration 9, loss = 0.69587530\n",
      "Iteration 10, loss = 0.69586988\n",
      "Iteration 11, loss = 0.69586464\n",
      "Iteration 12, loss = 0.69585959\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "68\n",
      "Iteration 1, loss = 0.70407815\n",
      "Iteration 2, loss = 0.70404616\n",
      "Iteration 3, loss = 0.70402587\n",
      "Iteration 4, loss = 0.70400600\n",
      "Iteration 5, loss = 0.70398648\n",
      "Iteration 6, loss = 0.70396738\n",
      "Iteration 7, loss = 0.70394878\n",
      "Iteration 8, loss = 0.70393071\n",
      "Iteration 9, loss = 0.70391320\n",
      "Iteration 10, loss = 0.70389627\n",
      "Iteration 11, loss = 0.70387991\n",
      "Iteration 12, loss = 0.70386413\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "69\n",
      "Iteration 1, loss = 0.70585794\n",
      "Iteration 2, loss = 0.70581710\n",
      "Iteration 3, loss = 0.70579120\n",
      "Iteration 4, loss = 0.70576585\n",
      "Iteration 5, loss = 0.70574096\n",
      "Iteration 6, loss = 0.70571661\n",
      "Iteration 7, loss = 0.70569289\n",
      "Iteration 8, loss = 0.70566994\n",
      "Iteration 9, loss = 0.70564777\n",
      "Iteration 10, loss = 0.70562634\n",
      "Iteration 11, loss = 0.70560565\n",
      "Iteration 12, loss = 0.70558573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "70\n",
      "Iteration 1, loss = 0.69814920\n",
      "Iteration 2, loss = 0.69813910\n",
      "Iteration 3, loss = 0.69813270\n",
      "Iteration 4, loss = 0.69812643\n",
      "Iteration 5, loss = 0.69812026\n",
      "Iteration 6, loss = 0.69811423\n",
      "Iteration 7, loss = 0.69810835\n",
      "Iteration 8, loss = 0.69810264\n",
      "Iteration 9, loss = 0.69809710\n",
      "Iteration 10, loss = 0.69809175\n",
      "Iteration 11, loss = 0.69808657\n",
      "Iteration 12, loss = 0.69808157\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "71\n",
      "Iteration 1, loss = 0.70674735\n",
      "Iteration 2, loss = 0.70671795\n",
      "Iteration 3, loss = 0.70669934\n",
      "Iteration 4, loss = 0.70668114\n",
      "Iteration 5, loss = 0.70666327\n",
      "Iteration 6, loss = 0.70664579\n",
      "Iteration 7, loss = 0.70662876\n",
      "Iteration 8, loss = 0.70661222\n",
      "Iteration 9, loss = 0.70659620\n",
      "Iteration 10, loss = 0.70658071\n",
      "Iteration 11, loss = 0.70656575\n",
      "Iteration 12, loss = 0.70655131\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "72\n",
      "Iteration 1, loss = 0.69495532\n",
      "Iteration 2, loss = 0.69494025\n",
      "Iteration 3, loss = 0.69493069\n",
      "Iteration 4, loss = 0.69492133\n",
      "Iteration 5, loss = 0.69491213\n",
      "Iteration 6, loss = 0.69490312\n",
      "Iteration 7, loss = 0.69489435\n",
      "Iteration 8, loss = 0.69488583\n",
      "Iteration 9, loss = 0.69487757\n",
      "Iteration 10, loss = 0.69486958\n",
      "Iteration 11, loss = 0.69486186\n",
      "Iteration 12, loss = 0.69485441\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "73\n",
      "Iteration 1, loss = 0.69216421\n",
      "Iteration 2, loss = 0.69215301\n",
      "Iteration 3, loss = 0.69214590\n",
      "Iteration 4, loss = 0.69213893\n",
      "Iteration 5, loss = 0.69213209\n",
      "Iteration 6, loss = 0.69212539\n",
      "Iteration 7, loss = 0.69211886\n",
      "Iteration 8, loss = 0.69211252\n",
      "Iteration 9, loss = 0.69210637\n",
      "Iteration 10, loss = 0.69210043\n",
      "Iteration 11, loss = 0.69209468\n",
      "Iteration 12, loss = 0.69208913\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "74\n",
      "Iteration 1, loss = 0.68675927\n",
      "Iteration 2, loss = 0.68674678\n",
      "Iteration 3, loss = 0.68673885\n",
      "Iteration 4, loss = 0.68673109\n",
      "Iteration 5, loss = 0.68672346\n",
      "Iteration 6, loss = 0.68671599\n",
      "Iteration 7, loss = 0.68670871\n",
      "Iteration 8, loss = 0.68670164\n",
      "Iteration 9, loss = 0.68669478\n",
      "Iteration 10, loss = 0.68668815\n",
      "Iteration 11, loss = 0.68668174\n",
      "Iteration 12, loss = 0.68667555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "75\n",
      "Iteration 1, loss = 0.69540918\n",
      "Iteration 2, loss = 0.69538900\n",
      "Iteration 3, loss = 0.69537620\n",
      "Iteration 4, loss = 0.69536367\n",
      "Iteration 5, loss = 0.69535135\n",
      "Iteration 6, loss = 0.69533931\n",
      "Iteration 7, loss = 0.69532757\n",
      "Iteration 8, loss = 0.69531617\n",
      "Iteration 9, loss = 0.69530512\n",
      "Iteration 10, loss = 0.69529444\n",
      "Iteration 11, loss = 0.69528412\n",
      "Iteration 12, loss = 0.69527415\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "76\n",
      "Iteration 1, loss = 0.69359663\n",
      "Iteration 2, loss = 0.69358808\n",
      "Iteration 3, loss = 0.69358265\n",
      "Iteration 4, loss = 0.69357734\n",
      "Iteration 5, loss = 0.69357211\n",
      "Iteration 6, loss = 0.69356700\n",
      "Iteration 7, loss = 0.69356202\n",
      "Iteration 8, loss = 0.69355718\n",
      "Iteration 9, loss = 0.69355249\n",
      "Iteration 10, loss = 0.69354795\n",
      "Iteration 11, loss = 0.69354356\n",
      "Iteration 12, loss = 0.69353932\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "77\n",
      "Iteration 1, loss = 0.69856723\n",
      "Iteration 2, loss = 0.69854711\n",
      "Iteration 3, loss = 0.69853435\n",
      "Iteration 4, loss = 0.69852185\n",
      "Iteration 5, loss = 0.69850958\n",
      "Iteration 6, loss = 0.69849757\n",
      "Iteration 7, loss = 0.69848587\n",
      "Iteration 8, loss = 0.69847451\n",
      "Iteration 9, loss = 0.69846350\n",
      "Iteration 10, loss = 0.69845286\n",
      "Iteration 11, loss = 0.69844257\n",
      "Iteration 12, loss = 0.69843265\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "78\n",
      "Iteration 1, loss = 0.69811756\n",
      "Iteration 2, loss = 0.69809480\n",
      "Iteration 3, loss = 0.69808036\n",
      "Iteration 4, loss = 0.69806623\n",
      "Iteration 5, loss = 0.69805235\n",
      "Iteration 6, loss = 0.69803877\n",
      "Iteration 7, loss = 0.69802554\n",
      "Iteration 8, loss = 0.69801270\n",
      "Iteration 9, loss = 0.69800025\n",
      "Iteration 10, loss = 0.69798821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.69797659\n",
      "Iteration 12, loss = 0.69796536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "79\n",
      "Iteration 1, loss = 0.70704492\n",
      "Iteration 2, loss = 0.70702305\n",
      "Iteration 3, loss = 0.70700917\n",
      "Iteration 4, loss = 0.70699558\n",
      "Iteration 5, loss = 0.70698224\n",
      "Iteration 6, loss = 0.70696919\n",
      "Iteration 7, loss = 0.70695647\n",
      "Iteration 8, loss = 0.70694412\n",
      "Iteration 9, loss = 0.70693216\n",
      "Iteration 10, loss = 0.70692059\n",
      "Iteration 11, loss = 0.70690942\n",
      "Iteration 12, loss = 0.70689863\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "80\n",
      "Iteration 1, loss = 0.69694297\n",
      "Iteration 2, loss = 0.69693249\n",
      "Iteration 3, loss = 0.69692584\n",
      "Iteration 4, loss = 0.69691932\n",
      "Iteration 5, loss = 0.69691292\n",
      "Iteration 6, loss = 0.69690665\n",
      "Iteration 7, loss = 0.69690054\n",
      "Iteration 8, loss = 0.69689461\n",
      "Iteration 9, loss = 0.69688886\n",
      "Iteration 10, loss = 0.69688329\n",
      "Iteration 11, loss = 0.69687791\n",
      "Iteration 12, loss = 0.69687272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "81\n",
      "Iteration 1, loss = 0.69294824\n",
      "Iteration 2, loss = 0.69293654\n",
      "Iteration 3, loss = 0.69292910\n",
      "Iteration 4, loss = 0.69292182\n",
      "Iteration 5, loss = 0.69291467\n",
      "Iteration 6, loss = 0.69290767\n",
      "Iteration 7, loss = 0.69290085\n",
      "Iteration 8, loss = 0.69289422\n",
      "Iteration 9, loss = 0.69288779\n",
      "Iteration 10, loss = 0.69288157\n",
      "Iteration 11, loss = 0.69287556\n",
      "Iteration 12, loss = 0.69286976\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "82\n",
      "Iteration 1, loss = 0.69334045\n",
      "Iteration 2, loss = 0.69331478\n",
      "Iteration 3, loss = 0.69329850\n",
      "Iteration 4, loss = 0.69328258\n",
      "Iteration 5, loss = 0.69326697\n",
      "Iteration 6, loss = 0.69325170\n",
      "Iteration 7, loss = 0.69323683\n",
      "Iteration 8, loss = 0.69322238\n",
      "Iteration 9, loss = 0.69320839\n",
      "Iteration 10, loss = 0.69319486\n",
      "Iteration 11, loss = 0.69318178\n",
      "Iteration 12, loss = 0.69316917\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "83\n",
      "Iteration 1, loss = 0.69093948\n",
      "Iteration 2, loss = 0.69091675\n",
      "Iteration 3, loss = 0.69090233\n",
      "Iteration 4, loss = 0.69088821\n",
      "Iteration 5, loss = 0.69087434\n",
      "Iteration 6, loss = 0.69086078\n",
      "Iteration 7, loss = 0.69084757\n",
      "Iteration 8, loss = 0.69083473\n",
      "Iteration 9, loss = 0.69082230\n",
      "Iteration 10, loss = 0.69081028\n",
      "Iteration 11, loss = 0.69079867\n",
      "Iteration 12, loss = 0.69078747\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "84\n",
      "Iteration 1, loss = 0.69255210\n",
      "Iteration 2, loss = 0.69253632\n",
      "Iteration 3, loss = 0.69252631\n",
      "Iteration 4, loss = 0.69251650\n",
      "Iteration 5, loss = 0.69250687\n",
      "Iteration 6, loss = 0.69249744\n",
      "Iteration 7, loss = 0.69248826\n",
      "Iteration 8, loss = 0.69247934\n",
      "Iteration 9, loss = 0.69247069\n",
      "Iteration 10, loss = 0.69246233\n",
      "Iteration 11, loss = 0.69245425\n",
      "Iteration 12, loss = 0.69244646\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "85\n",
      "Iteration 1, loss = 0.71320809\n",
      "Iteration 2, loss = 0.71317624\n",
      "Iteration 3, loss = 0.71315603\n",
      "Iteration 4, loss = 0.71313626\n",
      "Iteration 5, loss = 0.71311683\n",
      "Iteration 6, loss = 0.71309783\n",
      "Iteration 7, loss = 0.71307932\n",
      "Iteration 8, loss = 0.71306135\n",
      "Iteration 9, loss = 0.71304393\n",
      "Iteration 10, loss = 0.71302709\n",
      "Iteration 11, loss = 0.71301083\n",
      "Iteration 12, loss = 0.71299513\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "86\n",
      "Iteration 1, loss = 0.69158624\n",
      "Iteration 2, loss = 0.69157206\n",
      "Iteration 3, loss = 0.69156306\n",
      "Iteration 4, loss = 0.69155426\n",
      "Iteration 5, loss = 0.69154560\n",
      "Iteration 6, loss = 0.69153713\n",
      "Iteration 7, loss = 0.69152888\n",
      "Iteration 8, loss = 0.69152087\n",
      "Iteration 9, loss = 0.69151310\n",
      "Iteration 10, loss = 0.69150559\n",
      "Iteration 11, loss = 0.69149833\n",
      "Iteration 12, loss = 0.69149133\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "87\n",
      "Iteration 1, loss = 0.69719217\n",
      "Iteration 2, loss = 0.69718318\n",
      "Iteration 3, loss = 0.69717748\n",
      "Iteration 4, loss = 0.69717189\n",
      "Iteration 5, loss = 0.69716641\n",
      "Iteration 6, loss = 0.69716103\n",
      "Iteration 7, loss = 0.69715579\n",
      "Iteration 8, loss = 0.69715068\n",
      "Iteration 9, loss = 0.69714572\n",
      "Iteration 10, loss = 0.69714092\n",
      "Iteration 11, loss = 0.69713628\n",
      "Iteration 12, loss = 0.69713179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "88\n",
      "Iteration 1, loss = 0.71389176\n",
      "Iteration 2, loss = 0.71384782\n",
      "Iteration 3, loss = 0.71381995\n",
      "Iteration 4, loss = 0.71379268\n",
      "Iteration 5, loss = 0.71376590\n",
      "Iteration 6, loss = 0.71373970\n",
      "Iteration 7, loss = 0.71371418\n",
      "Iteration 8, loss = 0.71368940\n",
      "Iteration 9, loss = 0.71366541\n",
      "Iteration 10, loss = 0.71364220\n",
      "Iteration 11, loss = 0.71361979\n",
      "Iteration 12, loss = 0.71359817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "89\n",
      "Iteration 1, loss = 0.69487287\n",
      "Iteration 2, loss = 0.69485991\n",
      "Iteration 3, loss = 0.69485169\n",
      "Iteration 4, loss = 0.69484363\n",
      "Iteration 5, loss = 0.69483571\n",
      "Iteration 6, loss = 0.69482796\n",
      "Iteration 7, loss = 0.69482041\n",
      "Iteration 8, loss = 0.69481308\n",
      "Iteration 9, loss = 0.69480597\n",
      "Iteration 10, loss = 0.69479909\n",
      "Iteration 11, loss = 0.69479246\n",
      "Iteration 12, loss = 0.69478607\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "90\n",
      "Iteration 1, loss = 0.69637094\n",
      "Iteration 2, loss = 0.69635398\n",
      "Iteration 3, loss = 0.69634323\n",
      "Iteration 4, loss = 0.69633270\n",
      "Iteration 5, loss = 0.69632235\n",
      "Iteration 6, loss = 0.69631223\n",
      "Iteration 7, loss = 0.69630237\n",
      "Iteration 8, loss = 0.69629280\n",
      "Iteration 9, loss = 0.69628352\n",
      "Iteration 10, loss = 0.69627454\n",
      "Iteration 11, loss = 0.69626588\n",
      "Iteration 12, loss = 0.69625751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "91\n",
      "Iteration 1, loss = 0.69342079\n",
      "Iteration 2, loss = 0.69341081\n",
      "Iteration 3, loss = 0.69340448\n",
      "Iteration 4, loss = 0.69339828\n",
      "Iteration 5, loss = 0.69339218\n",
      "Iteration 6, loss = 0.69338624\n",
      "Iteration 7, loss = 0.69338045\n",
      "Iteration 8, loss = 0.69337482\n",
      "Iteration 9, loss = 0.69336936\n",
      "Iteration 10, loss = 0.69336410\n",
      "Iteration 11, loss = 0.69335918\n",
      "Iteration 12, loss = 0.69335453\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "92\n",
      "Iteration 1, loss = 0.69393231\n",
      "Iteration 2, loss = 0.69391927\n",
      "Iteration 3, loss = 0.69391099\n",
      "Iteration 4, loss = 0.69390289\n",
      "Iteration 5, loss = 0.69389492\n",
      "Iteration 6, loss = 0.69388712\n",
      "Iteration 7, loss = 0.69387953\n",
      "Iteration 8, loss = 0.69387215\n",
      "Iteration 9, loss = 0.69386499\n",
      "Iteration 10, loss = 0.69385807\n",
      "Iteration 11, loss = 0.69385138\n",
      "Iteration 12, loss = 0.69384493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "93\n",
      "Iteration 1, loss = 0.69934266\n",
      "Iteration 2, loss = 0.69932776\n",
      "Iteration 3, loss = 0.69931830\n",
      "Iteration 4, loss = 0.69930904\n",
      "Iteration 5, loss = 0.69929995\n",
      "Iteration 6, loss = 0.69929105\n",
      "Iteration 7, loss = 0.69928238\n",
      "Iteration 8, loss = 0.69927396\n",
      "Iteration 9, loss = 0.69926581\n",
      "Iteration 10, loss = 0.69925792\n",
      "Iteration 11, loss = 0.69925029\n",
      "Iteration 12, loss = 0.69924293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "94\n",
      "Iteration 1, loss = 0.69958846\n",
      "Iteration 2, loss = 0.69957449\n",
      "Iteration 3, loss = 0.69956563\n",
      "Iteration 4, loss = 0.69955695\n",
      "Iteration 5, loss = 0.69954840\n",
      "Iteration 6, loss = 0.69954003\n",
      "Iteration 7, loss = 0.69953188\n",
      "Iteration 8, loss = 0.69952396\n",
      "Iteration 9, loss = 0.69951628\n",
      "Iteration 10, loss = 0.69950885\n",
      "Iteration 11, loss = 0.69950167\n",
      "Iteration 12, loss = 0.69949474\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "95\n",
      "Iteration 1, loss = 0.68989447\n",
      "Iteration 2, loss = 0.68987972\n",
      "Iteration 3, loss = 0.68987036\n",
      "Iteration 4, loss = 0.68986120\n",
      "Iteration 5, loss = 0.68985220\n",
      "Iteration 6, loss = 0.68984339\n",
      "Iteration 7, loss = 0.68983481\n",
      "Iteration 8, loss = 0.68982648\n",
      "Iteration 9, loss = 0.68981840\n",
      "Iteration 10, loss = 0.68981059\n",
      "Iteration 11, loss = 0.68980304\n",
      "Iteration 12, loss = 0.68979576\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "96\n",
      "Iteration 1, loss = 0.69976791\n",
      "Iteration 2, loss = 0.69975833\n",
      "Iteration 3, loss = 0.69975225\n",
      "Iteration 4, loss = 0.69974630\n",
      "Iteration 5, loss = 0.69974045\n",
      "Iteration 6, loss = 0.69973472\n",
      "Iteration 7, loss = 0.69972914\n",
      "Iteration 8, loss = 0.69972371\n",
      "Iteration 9, loss = 0.69971846\n",
      "Iteration 10, loss = 0.69971337\n",
      "Iteration 11, loss = 0.69970845\n",
      "Iteration 12, loss = 0.69970371\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "97\n",
      "Iteration 1, loss = 0.69485560\n",
      "Iteration 2, loss = 0.69484601\n",
      "Iteration 3, loss = 0.69483993\n",
      "Iteration 4, loss = 0.69483397\n",
      "Iteration 5, loss = 0.69482812\n",
      "Iteration 6, loss = 0.69482246\n",
      "Iteration 7, loss = 0.69481695\n",
      "Iteration 8, loss = 0.69481159\n",
      "Iteration 9, loss = 0.69480641\n",
      "Iteration 10, loss = 0.69480139\n",
      "Iteration 11, loss = 0.69479654\n",
      "Iteration 12, loss = 0.69479186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "98\n",
      "Iteration 1, loss = 0.69429676\n",
      "Iteration 2, loss = 0.69428401\n",
      "Iteration 3, loss = 0.69427592\n",
      "Iteration 4, loss = 0.69426800\n",
      "Iteration 5, loss = 0.69426021\n",
      "Iteration 6, loss = 0.69425259\n",
      "Iteration 7, loss = 0.69424517\n",
      "Iteration 8, loss = 0.69423795\n",
      "Iteration 9, loss = 0.69423096\n",
      "Iteration 10, loss = 0.69422420\n",
      "Iteration 11, loss = 0.69421766\n",
      "Iteration 12, loss = 0.69421135\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "99\n",
      "Iteration 1, loss = 0.68789361\n",
      "Iteration 2, loss = 0.68788290\n",
      "Iteration 3, loss = 0.68787610\n",
      "Iteration 4, loss = 0.68786945\n",
      "Iteration 5, loss = 0.68786290\n",
      "Iteration 6, loss = 0.68785650\n",
      "Iteration 7, loss = 0.68785025\n",
      "Iteration 8, loss = 0.68784418\n",
      "Iteration 9, loss = 0.68783830\n",
      "Iteration 10, loss = 0.68783261\n",
      "Iteration 11, loss = 0.68782712\n",
      "Iteration 12, loss = 0.68782181\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "100\n",
      "Iteration 1, loss = 0.68704731\n",
      "Iteration 2, loss = 0.68703670\n",
      "Iteration 3, loss = 0.68702996\n",
      "Iteration 4, loss = 0.68702336\n",
      "Iteration 5, loss = 0.68701687\n",
      "Iteration 6, loss = 0.68701052\n",
      "Iteration 7, loss = 0.68700433\n",
      "Iteration 8, loss = 0.68699832\n",
      "Iteration 9, loss = 0.68699249\n",
      "Iteration 10, loss = 0.68698685\n",
      "Iteration 11, loss = 0.68698140\n",
      "Iteration 12, loss = 0.68697614\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "101\n",
      "Iteration 1, loss = 0.68984838\n",
      "Iteration 2, loss = 0.68983426\n",
      "Iteration 3, loss = 0.68982530\n",
      "Iteration 4, loss = 0.68981652\n",
      "Iteration 5, loss = 0.68980790\n",
      "Iteration 6, loss = 0.68979949\n",
      "Iteration 7, loss = 0.68979130\n",
      "Iteration 8, loss = 0.68978335\n",
      "Iteration 9, loss = 0.68977565\n",
      "Iteration 10, loss = 0.68976820\n",
      "Iteration 11, loss = 0.68976100\n",
      "Iteration 12, loss = 0.68975406\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "102\n",
      "Iteration 1, loss = 0.69971848\n",
      "Iteration 2, loss = 0.69970323\n",
      "Iteration 3, loss = 0.69969354\n",
      "Iteration 4, loss = 0.69968407\n",
      "Iteration 5, loss = 0.69967475\n",
      "Iteration 6, loss = 0.69966564\n",
      "Iteration 7, loss = 0.69965676\n",
      "Iteration 8, loss = 0.69964813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.69963978\n",
      "Iteration 10, loss = 0.69963169\n",
      "Iteration 11, loss = 0.69962388\n",
      "Iteration 12, loss = 0.69961634\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "103\n",
      "Iteration 1, loss = 0.68874815\n",
      "Iteration 2, loss = 0.68873603\n",
      "Iteration 3, loss = 0.68872833\n",
      "Iteration 4, loss = 0.68872079\n",
      "Iteration 5, loss = 0.68871338\n",
      "Iteration 6, loss = 0.68870613\n",
      "Iteration 7, loss = 0.68869907\n",
      "Iteration 8, loss = 0.68869220\n",
      "Iteration 9, loss = 0.68868554\n",
      "Iteration 10, loss = 0.68867910\n",
      "Iteration 11, loss = 0.68867288\n",
      "Iteration 12, loss = 0.68866687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "104\n",
      "Iteration 1, loss = 0.69934019\n",
      "Iteration 2, loss = 0.69931647\n",
      "Iteration 3, loss = 0.69930142\n",
      "Iteration 4, loss = 0.69928669\n",
      "Iteration 5, loss = 0.69927222\n",
      "Iteration 6, loss = 0.69925807\n",
      "Iteration 7, loss = 0.69924428\n",
      "Iteration 8, loss = 0.69923089\n",
      "Iteration 9, loss = 0.69921792\n",
      "Iteration 10, loss = 0.69920537\n",
      "Iteration 11, loss = 0.69919325\n",
      "Iteration 12, loss = 0.69918156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "105\n",
      "Iteration 1, loss = 0.71573410\n",
      "Iteration 2, loss = 0.71568731\n",
      "Iteration 3, loss = 0.71565763\n",
      "Iteration 4, loss = 0.71562859\n",
      "Iteration 5, loss = 0.71560014\n",
      "Iteration 6, loss = 0.71557232\n",
      "Iteration 7, loss = 0.71554522\n",
      "Iteration 8, loss = 0.71551892\n",
      "Iteration 9, loss = 0.71549344\n",
      "Iteration 10, loss = 0.71546881\n",
      "Iteration 11, loss = 0.71544495\n",
      "Iteration 12, loss = 0.71542189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "106\n",
      "Iteration 1, loss = 0.70452490\n",
      "Iteration 2, loss = 0.70447348\n",
      "Iteration 3, loss = 0.70444087\n",
      "Iteration 4, loss = 0.70440896\n",
      "Iteration 5, loss = 0.70437763\n",
      "Iteration 6, loss = 0.70434698\n",
      "Iteration 7, loss = 0.70431712\n",
      "Iteration 8, loss = 0.70428814\n",
      "Iteration 9, loss = 0.70426006\n",
      "Iteration 10, loss = 0.70423292\n",
      "Iteration 11, loss = 0.70420669\n",
      "Iteration 12, loss = 0.70418139\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "107\n",
      "Iteration 1, loss = 0.70229769\n",
      "Iteration 2, loss = 0.70227443\n",
      "Iteration 3, loss = 0.70225968\n",
      "Iteration 4, loss = 0.70224524\n",
      "Iteration 5, loss = 0.70223106\n",
      "Iteration 6, loss = 0.70221718\n",
      "Iteration 7, loss = 0.70220367\n",
      "Iteration 8, loss = 0.70219054\n",
      "Iteration 9, loss = 0.70217783\n",
      "Iteration 10, loss = 0.70216553\n",
      "Iteration 11, loss = 0.70215365\n",
      "Iteration 12, loss = 0.70214219\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "108\n",
      "Iteration 1, loss = 0.69671170\n",
      "Iteration 2, loss = 0.69670326\n",
      "Iteration 3, loss = 0.69669791\n",
      "Iteration 4, loss = 0.69669266\n",
      "Iteration 5, loss = 0.69668751\n",
      "Iteration 6, loss = 0.69668246\n",
      "Iteration 7, loss = 0.69667755\n",
      "Iteration 8, loss = 0.69667277\n",
      "Iteration 9, loss = 0.69666814\n",
      "Iteration 10, loss = 0.69666366\n",
      "Iteration 11, loss = 0.69665933\n",
      "Iteration 12, loss = 0.69665515\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "109\n",
      "Iteration 1, loss = 0.69874437\n",
      "Iteration 2, loss = 0.69872954\n",
      "Iteration 3, loss = 0.69872013\n",
      "Iteration 4, loss = 0.69871091\n",
      "Iteration 5, loss = 0.69870186\n",
      "Iteration 6, loss = 0.69869300\n",
      "Iteration 7, loss = 0.69868437\n",
      "Iteration 8, loss = 0.69867598\n",
      "Iteration 9, loss = 0.69866785\n",
      "Iteration 10, loss = 0.69865999\n",
      "Iteration 11, loss = 0.69865240\n",
      "Iteration 12, loss = 0.69864506\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "110\n",
      "Iteration 1, loss = 0.69968546\n",
      "Iteration 2, loss = 0.69966323\n",
      "Iteration 3, loss = 0.69964914\n",
      "Iteration 4, loss = 0.69963534\n",
      "Iteration 5, loss = 0.69962178\n",
      "Iteration 6, loss = 0.69960851\n",
      "Iteration 7, loss = 0.69959559\n",
      "Iteration 8, loss = 0.69958304\n",
      "Iteration 9, loss = 0.69957089\n",
      "Iteration 10, loss = 0.69955913\n",
      "Iteration 11, loss = 0.69954777\n",
      "Iteration 12, loss = 0.69953681\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "111\n",
      "Iteration 1, loss = 0.69911784\n",
      "Iteration 2, loss = 0.69910588\n",
      "Iteration 3, loss = 0.69909829\n",
      "Iteration 4, loss = 0.69909086\n",
      "Iteration 5, loss = 0.69908355\n",
      "Iteration 6, loss = 0.69907640\n",
      "Iteration 7, loss = 0.69906943\n",
      "Iteration 8, loss = 0.69906268\n",
      "Iteration 9, loss = 0.69905616\n",
      "Iteration 10, loss = 0.69904985\n",
      "Iteration 11, loss = 0.69904375\n",
      "Iteration 12, loss = 0.69903786\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "112\n",
      "Iteration 1, loss = 0.69848102\n",
      "Iteration 2, loss = 0.69845792\n",
      "Iteration 3, loss = 0.69844326\n",
      "Iteration 4, loss = 0.69842892\n",
      "Iteration 5, loss = 0.69841483\n",
      "Iteration 6, loss = 0.69840104\n",
      "Iteration 7, loss = 0.69838761\n",
      "Iteration 8, loss = 0.69837457\n",
      "Iteration 9, loss = 0.69836194\n",
      "Iteration 10, loss = 0.69834972\n",
      "Iteration 11, loss = 0.69833792\n",
      "Iteration 12, loss = 0.69832654\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "113\n",
      "Iteration 1, loss = 0.70042047\n",
      "Iteration 2, loss = 0.70040888\n",
      "Iteration 3, loss = 0.70040152\n",
      "Iteration 4, loss = 0.70039432\n",
      "Iteration 5, loss = 0.70038724\n",
      "Iteration 6, loss = 0.70038032\n",
      "Iteration 7, loss = 0.70037357\n",
      "Iteration 8, loss = 0.70036702\n",
      "Iteration 9, loss = 0.70036067\n",
      "Iteration 10, loss = 0.70035452\n",
      "Iteration 11, loss = 0.70034858\n",
      "Iteration 12, loss = 0.70034285\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "114\n",
      "Iteration 1, loss = 0.69565669\n",
      "Iteration 2, loss = 0.69564464\n",
      "Iteration 3, loss = 0.69563698\n",
      "Iteration 4, loss = 0.69562949\n",
      "Iteration 5, loss = 0.69562212\n",
      "Iteration 6, loss = 0.69561491\n",
      "Iteration 7, loss = 0.69560789\n",
      "Iteration 8, loss = 0.69560106\n",
      "Iteration 9, loss = 0.69559445\n",
      "Iteration 10, loss = 0.69558804\n",
      "Iteration 11, loss = 0.69558186\n",
      "Iteration 12, loss = 0.69557588\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "115\n",
      "Iteration 1, loss = 0.69937446\n",
      "Iteration 2, loss = 0.69936234\n",
      "Iteration 3, loss = 0.69935465\n",
      "Iteration 4, loss = 0.69934712\n",
      "Iteration 5, loss = 0.69933972\n",
      "Iteration 6, loss = 0.69933247\n",
      "Iteration 7, loss = 0.69932542\n",
      "Iteration 8, loss = 0.69931856\n",
      "Iteration 9, loss = 0.69931191\n",
      "Iteration 10, loss = 0.69930548\n",
      "Iteration 11, loss = 0.69929927\n",
      "Iteration 12, loss = 0.69929327\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "116\n",
      "Iteration 1, loss = 0.69087455\n",
      "Iteration 2, loss = 0.69086345\n",
      "Iteration 3, loss = 0.69085640\n",
      "Iteration 4, loss = 0.69084951\n",
      "Iteration 5, loss = 0.69084273\n",
      "Iteration 6, loss = 0.69083609\n",
      "Iteration 7, loss = 0.69082963\n",
      "Iteration 8, loss = 0.69082335\n",
      "Iteration 9, loss = 0.69081726\n",
      "Iteration 10, loss = 0.69081137\n",
      "Iteration 11, loss = 0.69080568\n",
      "Iteration 12, loss = 0.69080019\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "117\n",
      "Iteration 1, loss = 0.69195543\n",
      "Iteration 2, loss = 0.69194694\n",
      "Iteration 3, loss = 0.69194156\n",
      "Iteration 4, loss = 0.69193628\n",
      "Iteration 5, loss = 0.69193110\n",
      "Iteration 6, loss = 0.69192602\n",
      "Iteration 7, loss = 0.69192107\n",
      "Iteration 8, loss = 0.69191627\n",
      "Iteration 9, loss = 0.69191161\n",
      "Iteration 10, loss = 0.69190710\n",
      "Iteration 11, loss = 0.69190278\n",
      "Iteration 12, loss = 0.69189864\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "118\n",
      "Iteration 1, loss = 0.69388057\n",
      "Iteration 2, loss = 0.69386859\n",
      "Iteration 3, loss = 0.69386099\n",
      "Iteration 4, loss = 0.69385354\n",
      "Iteration 5, loss = 0.69384623\n",
      "Iteration 6, loss = 0.69383907\n",
      "Iteration 7, loss = 0.69383209\n",
      "Iteration 8, loss = 0.69382531\n",
      "Iteration 9, loss = 0.69381875\n",
      "Iteration 10, loss = 0.69381240\n",
      "Iteration 11, loss = 0.69380627\n",
      "Iteration 12, loss = 0.69380034\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "119\n",
      "Iteration 1, loss = 0.69806642\n",
      "Iteration 2, loss = 0.69805154\n",
      "Iteration 3, loss = 0.69804211\n",
      "Iteration 4, loss = 0.69803287\n",
      "Iteration 5, loss = 0.69802379\n",
      "Iteration 6, loss = 0.69801490\n",
      "Iteration 7, loss = 0.69800625\n",
      "Iteration 8, loss = 0.69799784\n",
      "Iteration 9, loss = 0.69798969\n",
      "Iteration 10, loss = 0.69798181\n",
      "Iteration 11, loss = 0.69797419\n",
      "Iteration 12, loss = 0.69796684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "120\n",
      "Iteration 1, loss = 0.68657218\n",
      "Iteration 2, loss = 0.68656114\n",
      "Iteration 3, loss = 0.68655412\n",
      "Iteration 4, loss = 0.68654726\n",
      "Iteration 5, loss = 0.68654051\n",
      "Iteration 6, loss = 0.68653391\n",
      "Iteration 7, loss = 0.68652748\n",
      "Iteration 8, loss = 0.68652123\n",
      "Iteration 9, loss = 0.68651518\n",
      "Iteration 10, loss = 0.68650932\n",
      "Iteration 11, loss = 0.68650367\n",
      "Iteration 12, loss = 0.68649821\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "121\n",
      "Iteration 1, loss = 0.69666861\n",
      "Iteration 2, loss = 0.69665718\n",
      "Iteration 3, loss = 0.69664992\n",
      "Iteration 4, loss = 0.69664282\n",
      "Iteration 5, loss = 0.69663583\n",
      "Iteration 6, loss = 0.69662900\n",
      "Iteration 7, loss = 0.69662234\n",
      "Iteration 8, loss = 0.69661586\n",
      "Iteration 9, loss = 0.69660959\n",
      "Iteration 10, loss = 0.69660352\n",
      "Iteration 11, loss = 0.69659765\n",
      "Iteration 12, loss = 0.69659199\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "122\n",
      "Iteration 1, loss = 0.69498398\n",
      "Iteration 2, loss = 0.69497107\n",
      "Iteration 3, loss = 0.69496287\n",
      "Iteration 4, loss = 0.69495483\n",
      "Iteration 5, loss = 0.69494693\n",
      "Iteration 6, loss = 0.69493921\n",
      "Iteration 7, loss = 0.69493168\n",
      "Iteration 8, loss = 0.69492437\n",
      "Iteration 9, loss = 0.69491728\n",
      "Iteration 10, loss = 0.69491042\n",
      "Iteration 11, loss = 0.69490380\n",
      "Iteration 12, loss = 0.69489740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "123\n",
      "Iteration 1, loss = 0.70040099\n",
      "Iteration 2, loss = 0.70038711\n",
      "Iteration 3, loss = 0.70037830\n",
      "Iteration 4, loss = 0.70036968\n",
      "Iteration 5, loss = 0.70036120\n",
      "Iteration 6, loss = 0.70035291\n",
      "Iteration 7, loss = 0.70034483\n",
      "Iteration 8, loss = 0.70033697\n",
      "Iteration 9, loss = 0.70032936\n",
      "Iteration 10, loss = 0.70032201\n",
      "Iteration 11, loss = 0.70031491\n",
      "Iteration 12, loss = 0.70030806\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "124\n",
      "Iteration 1, loss = 0.70322502\n",
      "Iteration 2, loss = 0.70319650\n",
      "Iteration 3, loss = 0.70317841\n",
      "Iteration 4, loss = 0.70316071\n",
      "Iteration 5, loss = 0.70314332\n",
      "Iteration 6, loss = 0.70312631\n",
      "Iteration 7, loss = 0.70310974\n",
      "Iteration 8, loss = 0.70309365\n",
      "Iteration 9, loss = 0.70307807\n",
      "Iteration 10, loss = 0.70306300\n",
      "Iteration 11, loss = 0.70304844\n",
      "Iteration 12, loss = 0.70303440\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "125\n",
      "Iteration 1, loss = 0.69008182\n",
      "Iteration 2, loss = 0.69006645\n",
      "Iteration 3, loss = 0.69005670\n",
      "Iteration 4, loss = 0.69004716\n",
      "Iteration 5, loss = 0.69003778\n",
      "Iteration 6, loss = 0.69002860\n",
      "Iteration 7, loss = 0.69001966\n",
      "Iteration 8, loss = 0.69001097\n",
      "Iteration 9, loss = 0.69000256\n",
      "Iteration 10, loss = 0.68999442\n",
      "Iteration 11, loss = 0.68998655\n",
      "Iteration 12, loss = 0.68997896\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68802205\n",
      "Iteration 2, loss = 0.68801044\n",
      "Iteration 3, loss = 0.68800307\n",
      "Iteration 4, loss = 0.68799586\n",
      "Iteration 5, loss = 0.68798877\n",
      "Iteration 6, loss = 0.68798183\n",
      "Iteration 7, loss = 0.68797506\n",
      "Iteration 8, loss = 0.68796849\n",
      "Iteration 9, loss = 0.68796212\n",
      "Iteration 10, loss = 0.68795596\n",
      "Iteration 11, loss = 0.68795001\n",
      "Iteration 12, loss = 0.68794426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "127\n",
      "Iteration 1, loss = 0.69317277\n",
      "Iteration 2, loss = 0.69316373\n",
      "Iteration 3, loss = 0.69315799\n",
      "Iteration 4, loss = 0.69315237\n",
      "Iteration 5, loss = 0.69314685\n",
      "Iteration 6, loss = 0.69314145\n",
      "Iteration 7, loss = 0.69313618\n",
      "Iteration 8, loss = 0.69313106\n",
      "Iteration 9, loss = 0.69312610\n",
      "Iteration 10, loss = 0.69312130\n",
      "Iteration 11, loss = 0.69311666\n",
      "Iteration 12, loss = 0.69311219\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "128\n",
      "Iteration 1, loss = 0.70628281\n",
      "Iteration 2, loss = 0.70626846\n",
      "Iteration 3, loss = 0.70625935\n",
      "Iteration 4, loss = 0.70625043\n",
      "Iteration 5, loss = 0.70624166\n",
      "Iteration 6, loss = 0.70623308\n",
      "Iteration 7, loss = 0.70622472\n",
      "Iteration 8, loss = 0.70621660\n",
      "Iteration 9, loss = 0.70620873\n",
      "Iteration 10, loss = 0.70620111\n",
      "Iteration 11, loss = 0.70619375\n",
      "Iteration 12, loss = 0.70618665\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "129\n",
      "Iteration 1, loss = 0.69815021\n",
      "Iteration 2, loss = 0.69812624\n",
      "Iteration 3, loss = 0.69811109\n",
      "Iteration 4, loss = 0.69809629\n",
      "Iteration 5, loss = 0.69808175\n",
      "Iteration 6, loss = 0.69806752\n",
      "Iteration 7, loss = 0.69805367\n",
      "Iteration 8, loss = 0.69804022\n",
      "Iteration 9, loss = 0.69802719\n",
      "Iteration 10, loss = 0.69801459\n",
      "Iteration 11, loss = 0.69800242\n",
      "Iteration 12, loss = 0.69799068\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "130\n",
      "Iteration 1, loss = 0.69122699\n",
      "Iteration 2, loss = 0.69121822\n",
      "Iteration 3, loss = 0.69121265\n",
      "Iteration 4, loss = 0.69120721\n",
      "Iteration 5, loss = 0.69120185\n",
      "Iteration 6, loss = 0.69119661\n",
      "Iteration 7, loss = 0.69119150\n",
      "Iteration 8, loss = 0.69118653\n",
      "Iteration 9, loss = 0.69118172\n",
      "Iteration 10, loss = 0.69117706\n",
      "Iteration 11, loss = 0.69117256\n",
      "Iteration 12, loss = 0.69116822\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "131\n",
      "Iteration 1, loss = 0.70039487\n",
      "Iteration 2, loss = 0.70038196\n",
      "Iteration 3, loss = 0.70037377\n",
      "Iteration 4, loss = 0.70036574\n",
      "Iteration 5, loss = 0.70035788\n",
      "Iteration 6, loss = 0.70035018\n",
      "Iteration 7, loss = 0.70034269\n",
      "Iteration 8, loss = 0.70033541\n",
      "Iteration 9, loss = 0.70032835\n",
      "Iteration 10, loss = 0.70032153\n",
      "Iteration 11, loss = 0.70031493\n",
      "Iteration 12, loss = 0.70030857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "132\n",
      "Iteration 1, loss = 0.69102305\n",
      "Iteration 2, loss = 0.69100472\n",
      "Iteration 3, loss = 0.69099310\n",
      "Iteration 4, loss = 0.69098173\n",
      "Iteration 5, loss = 0.69097056\n",
      "Iteration 6, loss = 0.69095964\n",
      "Iteration 7, loss = 0.69094899\n",
      "Iteration 8, loss = 0.69093865\n",
      "Iteration 9, loss = 0.69092863\n",
      "Iteration 10, loss = 0.69091894\n",
      "Iteration 11, loss = 0.69090958\n",
      "Iteration 12, loss = 0.69090058\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "133\n",
      "Iteration 1, loss = 0.69357962\n",
      "Iteration 2, loss = 0.69357128\n",
      "Iteration 3, loss = 0.69356598\n",
      "Iteration 4, loss = 0.69356080\n",
      "Iteration 5, loss = 0.69355570\n",
      "Iteration 6, loss = 0.69355072\n",
      "Iteration 7, loss = 0.69354585\n",
      "Iteration 8, loss = 0.69354113\n",
      "Iteration 9, loss = 0.69353655\n",
      "Iteration 10, loss = 0.69353213\n",
      "Iteration 11, loss = 0.69352784\n",
      "Iteration 12, loss = 0.69352369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "134\n",
      "Iteration 1, loss = 0.69308579\n",
      "Iteration 2, loss = 0.69307198\n",
      "Iteration 3, loss = 0.69306322\n",
      "Iteration 4, loss = 0.69305464\n",
      "Iteration 5, loss = 0.69304621\n",
      "Iteration 6, loss = 0.69303796\n",
      "Iteration 7, loss = 0.69302993\n",
      "Iteration 8, loss = 0.69302212\n",
      "Iteration 9, loss = 0.69301455\n",
      "Iteration 10, loss = 0.69300723\n",
      "Iteration 11, loss = 0.69300015\n",
      "Iteration 12, loss = 0.69299332\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "135\n",
      "Iteration 1, loss = 0.69470143\n",
      "Iteration 2, loss = 0.69469226\n",
      "Iteration 3, loss = 0.69468643\n",
      "Iteration 4, loss = 0.69468073\n",
      "Iteration 5, loss = 0.69467512\n",
      "Iteration 6, loss = 0.69466964\n",
      "Iteration 7, loss = 0.69466429\n",
      "Iteration 8, loss = 0.69465909\n",
      "Iteration 9, loss = 0.69465405\n",
      "Iteration 10, loss = 0.69464918\n",
      "Iteration 11, loss = 0.69464447\n",
      "Iteration 12, loss = 0.69463992\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "136\n",
      "Iteration 1, loss = 0.70641239\n",
      "Iteration 2, loss = 0.70637259\n",
      "Iteration 3, loss = 0.70634730\n",
      "Iteration 4, loss = 0.70632254\n",
      "Iteration 5, loss = 0.70629821\n",
      "Iteration 6, loss = 0.70627441\n",
      "Iteration 7, loss = 0.70625123\n",
      "Iteration 8, loss = 0.70622871\n",
      "Iteration 9, loss = 0.70620690\n",
      "Iteration 10, loss = 0.70618580\n",
      "Iteration 11, loss = 0.70616542\n",
      "Iteration 12, loss = 0.70614575\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "137\n",
      "Iteration 1, loss = 0.70525299\n",
      "Iteration 2, loss = 0.70524134\n",
      "Iteration 3, loss = 0.70523395\n",
      "Iteration 4, loss = 0.70522670\n",
      "Iteration 5, loss = 0.70521959\n",
      "Iteration 6, loss = 0.70521262\n",
      "Iteration 7, loss = 0.70520583\n",
      "Iteration 8, loss = 0.70519924\n",
      "Iteration 9, loss = 0.70519285\n",
      "Iteration 10, loss = 0.70518667\n",
      "Iteration 11, loss = 0.70518069\n",
      "Iteration 12, loss = 0.70517492\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "138\n",
      "Iteration 1, loss = 0.69942194\n",
      "Iteration 2, loss = 0.69940370\n",
      "Iteration 3, loss = 0.69939213\n",
      "Iteration 4, loss = 0.69938080\n",
      "Iteration 5, loss = 0.69936967\n",
      "Iteration 6, loss = 0.69935878\n",
      "Iteration 7, loss = 0.69934816\n",
      "Iteration 8, loss = 0.69933785\n",
      "Iteration 9, loss = 0.69932787\n",
      "Iteration 10, loss = 0.69931820\n",
      "Iteration 11, loss = 0.69930887\n",
      "Iteration 12, loss = 0.69929986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "139\n",
      "Iteration 1, loss = 0.69431158\n",
      "Iteration 2, loss = 0.69429785\n",
      "Iteration 3, loss = 0.69428914\n",
      "Iteration 4, loss = 0.69428062\n",
      "Iteration 5, loss = 0.69427224\n",
      "Iteration 6, loss = 0.69426406\n",
      "Iteration 7, loss = 0.69425612\n",
      "Iteration 8, loss = 0.69424842\n",
      "Iteration 9, loss = 0.69424095\n",
      "Iteration 10, loss = 0.69423373\n",
      "Iteration 11, loss = 0.69422676\n",
      "Iteration 12, loss = 0.69422002\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "140\n",
      "Iteration 1, loss = 0.68979120\n",
      "Iteration 2, loss = 0.68977797\n",
      "Iteration 3, loss = 0.68976957\n",
      "Iteration 4, loss = 0.68976135\n",
      "Iteration 5, loss = 0.68975326\n",
      "Iteration 6, loss = 0.68974535\n",
      "Iteration 7, loss = 0.68973764\n",
      "Iteration 8, loss = 0.68973016\n",
      "Iteration 9, loss = 0.68972290\n",
      "Iteration 10, loss = 0.68971588\n",
      "Iteration 11, loss = 0.68970909\n",
      "Iteration 12, loss = 0.68970254\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "141\n",
      "Iteration 1, loss = 0.70346868\n",
      "Iteration 2, loss = 0.70342689\n",
      "Iteration 3, loss = 0.70340039\n",
      "Iteration 4, loss = 0.70337446\n",
      "Iteration 5, loss = 0.70334898\n",
      "Iteration 6, loss = 0.70332407\n",
      "Iteration 7, loss = 0.70329981\n",
      "Iteration 8, loss = 0.70327625\n",
      "Iteration 9, loss = 0.70325343\n",
      "Iteration 10, loss = 0.70323137\n",
      "Iteration 11, loss = 0.70321006\n",
      "Iteration 12, loss = 0.70318950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "142\n",
      "Iteration 1, loss = 0.69481578\n",
      "Iteration 2, loss = 0.69480269\n",
      "Iteration 3, loss = 0.69479438\n",
      "Iteration 4, loss = 0.69478624\n",
      "Iteration 5, loss = 0.69477825\n",
      "Iteration 6, loss = 0.69477041\n",
      "Iteration 7, loss = 0.69476277\n",
      "Iteration 8, loss = 0.69475534\n",
      "Iteration 9, loss = 0.69474814\n",
      "Iteration 10, loss = 0.69474118\n",
      "Iteration 11, loss = 0.69473445\n",
      "Iteration 12, loss = 0.69472796\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "143\n",
      "Iteration 1, loss = 0.70562506\n",
      "Iteration 2, loss = 0.70558975\n",
      "Iteration 3, loss = 0.70556736\n",
      "Iteration 4, loss = 0.70554545\n",
      "Iteration 5, loss = 0.70552393\n",
      "Iteration 6, loss = 0.70550287\n",
      "Iteration 7, loss = 0.70548236\n",
      "Iteration 8, loss = 0.70546245\n",
      "Iteration 9, loss = 0.70544313\n",
      "Iteration 10, loss = 0.70542445\n",
      "Iteration 11, loss = 0.70540640\n",
      "Iteration 12, loss = 0.70538898\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "144\n",
      "Iteration 1, loss = 0.69480815\n",
      "Iteration 2, loss = 0.69479951\n",
      "Iteration 3, loss = 0.69479402\n",
      "Iteration 4, loss = 0.69478865\n",
      "Iteration 5, loss = 0.69478337\n",
      "Iteration 6, loss = 0.69477820\n",
      "Iteration 7, loss = 0.69477317\n",
      "Iteration 8, loss = 0.69476827\n",
      "Iteration 9, loss = 0.69476353\n",
      "Iteration 10, loss = 0.69475894\n",
      "Iteration 11, loss = 0.69475450\n",
      "Iteration 12, loss = 0.69475022\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "145\n",
      "Iteration 1, loss = 0.69231479\n",
      "Iteration 2, loss = 0.69230146\n",
      "Iteration 3, loss = 0.69229300\n",
      "Iteration 4, loss = 0.69228471\n",
      "Iteration 5, loss = 0.69227657\n",
      "Iteration 6, loss = 0.69226861\n",
      "Iteration 7, loss = 0.69226084\n",
      "Iteration 8, loss = 0.69225330\n",
      "Iteration 9, loss = 0.69224599\n",
      "Iteration 10, loss = 0.69223892\n",
      "Iteration 11, loss = 0.69223209\n",
      "Iteration 12, loss = 0.69222549\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "146\n",
      "Iteration 1, loss = 0.69807704\n",
      "Iteration 2, loss = 0.69806607\n",
      "Iteration 3, loss = 0.69805911\n",
      "Iteration 4, loss = 0.69805229\n",
      "Iteration 5, loss = 0.69804559\n",
      "Iteration 6, loss = 0.69803903\n",
      "Iteration 7, loss = 0.69803263\n",
      "Iteration 8, loss = 0.69802642\n",
      "Iteration 9, loss = 0.69802040\n",
      "Iteration 10, loss = 0.69801457\n",
      "Iteration 11, loss = 0.69800894\n",
      "Iteration 12, loss = 0.69800350\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "147\n",
      "Iteration 1, loss = 0.69432044\n",
      "Iteration 2, loss = 0.69430903\n",
      "Iteration 3, loss = 0.69430179\n",
      "Iteration 4, loss = 0.69429469\n",
      "Iteration 5, loss = 0.69428772\n",
      "Iteration 6, loss = 0.69428090\n",
      "Iteration 7, loss = 0.69427424\n",
      "Iteration 8, loss = 0.69426778\n",
      "Iteration 9, loss = 0.69426151\n",
      "Iteration 10, loss = 0.69425545\n",
      "Iteration 11, loss = 0.69424959\n",
      "Iteration 12, loss = 0.69424394\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "148\n",
      "Iteration 1, loss = 0.69444878\n",
      "Iteration 2, loss = 0.69443507\n",
      "Iteration 3, loss = 0.69442637\n",
      "Iteration 4, loss = 0.69441784\n",
      "Iteration 5, loss = 0.69440947\n",
      "Iteration 6, loss = 0.69440127\n",
      "Iteration 7, loss = 0.69439329\n",
      "Iteration 8, loss = 0.69438553\n",
      "Iteration 9, loss = 0.69437800\n",
      "Iteration 10, loss = 0.69437073\n",
      "Iteration 11, loss = 0.69436370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.69435691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "149\n",
      "Iteration 1, loss = 0.69171353\n",
      "Iteration 2, loss = 0.69169894\n",
      "Iteration 3, loss = 0.69168968\n",
      "Iteration 4, loss = 0.69168061\n",
      "Iteration 5, loss = 0.69167171\n",
      "Iteration 6, loss = 0.69166301\n",
      "Iteration 7, loss = 0.69165453\n",
      "Iteration 8, loss = 0.69164630\n",
      "Iteration 9, loss = 0.69163832\n",
      "Iteration 10, loss = 0.69163059\n",
      "Iteration 11, loss = 0.69162313\n",
      "Iteration 12, loss = 0.69161593\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "150\n",
      "Iteration 1, loss = 0.71118248\n",
      "Iteration 2, loss = 0.71114328\n",
      "Iteration 3, loss = 0.71111842\n",
      "Iteration 4, loss = 0.71109410\n",
      "Iteration 5, loss = 0.71107020\n",
      "Iteration 6, loss = 0.71104683\n",
      "Iteration 7, loss = 0.71102406\n",
      "Iteration 8, loss = 0.71100196\n",
      "Iteration 9, loss = 0.71098055\n",
      "Iteration 10, loss = 0.71095990\n",
      "Iteration 11, loss = 0.71093993\n",
      "Iteration 12, loss = 0.71092066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "151\n",
      "Iteration 1, loss = 0.69213405\n",
      "Iteration 2, loss = 0.69212016\n",
      "Iteration 3, loss = 0.69211137\n",
      "Iteration 4, loss = 0.69210277\n",
      "Iteration 5, loss = 0.69209432\n",
      "Iteration 6, loss = 0.69208605\n",
      "Iteration 7, loss = 0.69207799\n",
      "Iteration 8, loss = 0.69207017\n",
      "Iteration 9, loss = 0.69206258\n",
      "Iteration 10, loss = 0.69205524\n",
      "Iteration 11, loss = 0.69204815\n",
      "Iteration 12, loss = 0.69204130\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "152\n",
      "Iteration 1, loss = 0.70615388\n",
      "Iteration 2, loss = 0.70612765\n",
      "Iteration 3, loss = 0.70611101\n",
      "Iteration 4, loss = 0.70609473\n",
      "Iteration 5, loss = 0.70607875\n",
      "Iteration 6, loss = 0.70606311\n",
      "Iteration 7, loss = 0.70604788\n",
      "Iteration 8, loss = 0.70603308\n",
      "Iteration 9, loss = 0.70601875\n",
      "Iteration 10, loss = 0.70600490\n",
      "Iteration 11, loss = 0.70599152\n",
      "Iteration 12, loss = 0.70597860\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "153\n",
      "Iteration 1, loss = 0.69250994\n",
      "Iteration 2, loss = 0.69249714\n",
      "Iteration 3, loss = 0.69248903\n",
      "Iteration 4, loss = 0.69248108\n",
      "Iteration 5, loss = 0.69247327\n",
      "Iteration 6, loss = 0.69246562\n",
      "Iteration 7, loss = 0.69245817\n",
      "Iteration 8, loss = 0.69245094\n",
      "Iteration 9, loss = 0.69244393\n",
      "Iteration 10, loss = 0.69243714\n",
      "Iteration 11, loss = 0.69243059\n",
      "Iteration 12, loss = 0.69242426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "154\n",
      "Iteration 1, loss = 0.69487627\n",
      "Iteration 2, loss = 0.69486452\n",
      "Iteration 3, loss = 0.69485707\n",
      "Iteration 4, loss = 0.69484977\n",
      "Iteration 5, loss = 0.69484260\n",
      "Iteration 6, loss = 0.69483558\n",
      "Iteration 7, loss = 0.69482874\n",
      "Iteration 8, loss = 0.69482210\n",
      "Iteration 9, loss = 0.69481566\n",
      "Iteration 10, loss = 0.69480943\n",
      "Iteration 11, loss = 0.69480341\n",
      "Iteration 12, loss = 0.69479759\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "155\n",
      "Iteration 1, loss = 0.69073308\n",
      "Iteration 2, loss = 0.69071277\n",
      "Iteration 3, loss = 0.69069988\n",
      "Iteration 4, loss = 0.69068726\n",
      "Iteration 5, loss = 0.69067486\n",
      "Iteration 6, loss = 0.69066274\n",
      "Iteration 7, loss = 0.69065092\n",
      "Iteration 8, loss = 0.69063944\n",
      "Iteration 9, loss = 0.69062832\n",
      "Iteration 10, loss = 0.69061757\n",
      "Iteration 11, loss = 0.69060718\n",
      "Iteration 12, loss = 0.69059715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "156\n",
      "Iteration 1, loss = 0.69722554\n",
      "Iteration 2, loss = 0.69720316\n",
      "Iteration 3, loss = 0.69718896\n",
      "Iteration 4, loss = 0.69717506\n",
      "Iteration 5, loss = 0.69716141\n",
      "Iteration 6, loss = 0.69714806\n",
      "Iteration 7, loss = 0.69713505\n",
      "Iteration 8, loss = 0.69712242\n",
      "Iteration 9, loss = 0.69711018\n",
      "Iteration 10, loss = 0.69709835\n",
      "Iteration 11, loss = 0.69708691\n",
      "Iteration 12, loss = 0.69707588\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "157\n",
      "Iteration 1, loss = 0.69548408\n",
      "Iteration 2, loss = 0.69546860\n",
      "Iteration 3, loss = 0.69545878\n",
      "Iteration 4, loss = 0.69544916\n",
      "Iteration 5, loss = 0.69543972\n",
      "Iteration 6, loss = 0.69543049\n",
      "Iteration 7, loss = 0.69542149\n",
      "Iteration 8, loss = 0.69541275\n",
      "Iteration 9, loss = 0.69540427\n",
      "Iteration 10, loss = 0.69539608\n",
      "Iteration 11, loss = 0.69538816\n",
      "Iteration 12, loss = 0.69538052\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "158\n",
      "Iteration 1, loss = 0.69222129\n",
      "Iteration 2, loss = 0.69220799\n",
      "Iteration 3, loss = 0.69219954\n",
      "Iteration 4, loss = 0.69219127\n",
      "Iteration 5, loss = 0.69218315\n",
      "Iteration 6, loss = 0.69217519\n",
      "Iteration 7, loss = 0.69216744\n",
      "Iteration 8, loss = 0.69215991\n",
      "Iteration 9, loss = 0.69215261\n",
      "Iteration 10, loss = 0.69214555\n",
      "Iteration 11, loss = 0.69213873\n",
      "Iteration 12, loss = 0.69213214\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "159\n",
      "Iteration 1, loss = 0.69768339\n",
      "Iteration 2, loss = 0.69767117\n",
      "Iteration 3, loss = 0.69766341\n",
      "Iteration 4, loss = 0.69765581\n",
      "Iteration 5, loss = 0.69764835\n",
      "Iteration 6, loss = 0.69764104\n",
      "Iteration 7, loss = 0.69763392\n",
      "Iteration 8, loss = 0.69762701\n",
      "Iteration 9, loss = 0.69762030\n",
      "Iteration 10, loss = 0.69761382\n",
      "Iteration 11, loss = 0.69760755\n",
      "Iteration 12, loss = 0.69760150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "160\n",
      "Iteration 1, loss = 0.69730972\n",
      "Iteration 2, loss = 0.69729243\n",
      "Iteration 3, loss = 0.69728146\n",
      "Iteration 4, loss = 0.69727071\n",
      "Iteration 5, loss = 0.69726016\n",
      "Iteration 6, loss = 0.69724983\n",
      "Iteration 7, loss = 0.69723977\n",
      "Iteration 8, loss = 0.69723000\n",
      "Iteration 9, loss = 0.69722053\n",
      "Iteration 10, loss = 0.69721137\n",
      "Iteration 11, loss = 0.69720252\n",
      "Iteration 12, loss = 0.69719398\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "161\n",
      "Iteration 1, loss = 0.69668793\n",
      "Iteration 2, loss = 0.69666665\n",
      "Iteration 3, loss = 0.69665315\n",
      "Iteration 4, loss = 0.69663994\n",
      "Iteration 5, loss = 0.69662697\n",
      "Iteration 6, loss = 0.69661427\n",
      "Iteration 7, loss = 0.69660190\n",
      "Iteration 8, loss = 0.69658990\n",
      "Iteration 9, loss = 0.69657826\n",
      "Iteration 10, loss = 0.69656701\n",
      "Iteration 11, loss = 0.69655615\n",
      "Iteration 12, loss = 0.69654566\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "162\n",
      "Iteration 1, loss = 0.70191127\n",
      "Iteration 2, loss = 0.70188882\n",
      "Iteration 3, loss = 0.70187458\n",
      "Iteration 4, loss = 0.70186064\n",
      "Iteration 5, loss = 0.70184694\n",
      "Iteration 6, loss = 0.70183354\n",
      "Iteration 7, loss = 0.70182049\n",
      "Iteration 8, loss = 0.70180782\n",
      "Iteration 9, loss = 0.70179554\n",
      "Iteration 10, loss = 0.70178368\n",
      "Iteration 11, loss = 0.70177223\n",
      "Iteration 12, loss = 0.70176118\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "163\n",
      "Iteration 1, loss = 0.69258097\n",
      "Iteration 2, loss = 0.69256027\n",
      "Iteration 3, loss = 0.69254713\n",
      "Iteration 4, loss = 0.69253428\n",
      "Iteration 5, loss = 0.69252165\n",
      "Iteration 6, loss = 0.69250929\n",
      "Iteration 7, loss = 0.69249726\n",
      "Iteration 8, loss = 0.69248556\n",
      "Iteration 9, loss = 0.69247423\n",
      "Iteration 10, loss = 0.69246328\n",
      "Iteration 11, loss = 0.69245269\n",
      "Iteration 12, loss = 0.69244248\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "164\n",
      "Iteration 1, loss = 0.70151951\n",
      "Iteration 2, loss = 0.70150820\n",
      "Iteration 3, loss = 0.70150103\n",
      "Iteration 4, loss = 0.70149400\n",
      "Iteration 5, loss = 0.70148709\n",
      "Iteration 6, loss = 0.70148033\n",
      "Iteration 7, loss = 0.70147375\n",
      "Iteration 8, loss = 0.70146735\n",
      "Iteration 9, loss = 0.70146114\n",
      "Iteration 10, loss = 0.70145514\n",
      "Iteration 11, loss = 0.70144934\n",
      "Iteration 12, loss = 0.70144374\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "165\n",
      "Iteration 1, loss = 0.69654183\n",
      "Iteration 2, loss = 0.69653014\n",
      "Iteration 3, loss = 0.69652273\n",
      "Iteration 4, loss = 0.69651546\n",
      "Iteration 5, loss = 0.69650832\n",
      "Iteration 6, loss = 0.69650134\n",
      "Iteration 7, loss = 0.69649453\n",
      "Iteration 8, loss = 0.69648791\n",
      "Iteration 9, loss = 0.69648150\n",
      "Iteration 10, loss = 0.69647529\n",
      "Iteration 11, loss = 0.69646930\n",
      "Iteration 12, loss = 0.69646351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "166\n",
      "Iteration 1, loss = 0.70323957\n",
      "Iteration 2, loss = 0.70322547\n",
      "Iteration 3, loss = 0.70321652\n",
      "Iteration 4, loss = 0.70320776\n",
      "Iteration 5, loss = 0.70319915\n",
      "Iteration 6, loss = 0.70319073\n",
      "Iteration 7, loss = 0.70318253\n",
      "Iteration 8, loss = 0.70317456\n",
      "Iteration 9, loss = 0.70316684\n",
      "Iteration 10, loss = 0.70315937\n",
      "Iteration 11, loss = 0.70315215\n",
      "Iteration 12, loss = 0.70314519\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "167\n",
      "Iteration 1, loss = 0.69530538\n",
      "Iteration 2, loss = 0.69529338\n",
      "Iteration 3, loss = 0.69528576\n",
      "Iteration 4, loss = 0.69527831\n",
      "Iteration 5, loss = 0.69527098\n",
      "Iteration 6, loss = 0.69526381\n",
      "Iteration 7, loss = 0.69525682\n",
      "Iteration 8, loss = 0.69525003\n",
      "Iteration 9, loss = 0.69524345\n",
      "Iteration 10, loss = 0.69523709\n",
      "Iteration 11, loss = 0.69523094\n",
      "Iteration 12, loss = 0.69522500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "168\n",
      "Iteration 1, loss = 0.69406659\n",
      "Iteration 2, loss = 0.69405560\n",
      "Iteration 3, loss = 0.69404858\n",
      "Iteration 4, loss = 0.69404170\n",
      "Iteration 5, loss = 0.69403494\n",
      "Iteration 6, loss = 0.69402832\n",
      "Iteration 7, loss = 0.69402187\n",
      "Iteration 8, loss = 0.69401560\n",
      "Iteration 9, loss = 0.69400951\n",
      "Iteration 10, loss = 0.69400363\n",
      "Iteration 11, loss = 0.69399794\n",
      "Iteration 12, loss = 0.69399244\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "169\n",
      "Iteration 1, loss = 0.69390670\n",
      "Iteration 2, loss = 0.69389183\n",
      "Iteration 3, loss = 0.69388239\n",
      "Iteration 4, loss = 0.69387315\n",
      "Iteration 5, loss = 0.69386407\n",
      "Iteration 6, loss = 0.69385519\n",
      "Iteration 7, loss = 0.69384654\n",
      "Iteration 8, loss = 0.69383812\n",
      "Iteration 9, loss = 0.69382996\n",
      "Iteration 10, loss = 0.69382206\n",
      "Iteration 11, loss = 0.69381443\n",
      "Iteration 12, loss = 0.69380706\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "170\n",
      "Iteration 1, loss = 0.68815297\n",
      "Iteration 2, loss = 0.68813949\n",
      "Iteration 3, loss = 0.68813093\n",
      "Iteration 4, loss = 0.68812256\n",
      "Iteration 5, loss = 0.68811433\n",
      "Iteration 6, loss = 0.68810628\n",
      "Iteration 7, loss = 0.68809843\n",
      "Iteration 8, loss = 0.68809080\n",
      "Iteration 9, loss = 0.68808342\n",
      "Iteration 10, loss = 0.68807627\n",
      "Iteration 11, loss = 0.68806933\n",
      "Iteration 12, loss = 0.68806260\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "171\n",
      "Iteration 1, loss = 0.69209244\n",
      "Iteration 2, loss = 0.69207166\n",
      "Iteration 3, loss = 0.69205848\n",
      "Iteration 4, loss = 0.69204558\n",
      "Iteration 5, loss = 0.69203290\n",
      "Iteration 6, loss = 0.69202051\n",
      "Iteration 7, loss = 0.69200852\n",
      "Iteration 8, loss = 0.69199687\n",
      "Iteration 9, loss = 0.69198560\n",
      "Iteration 10, loss = 0.69197470\n",
      "Iteration 11, loss = 0.69196417\n",
      "Iteration 12, loss = 0.69195401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "172\n",
      "Iteration 1, loss = 0.68933391\n",
      "Iteration 2, loss = 0.68932361\n",
      "Iteration 3, loss = 0.68931706\n",
      "Iteration 4, loss = 0.68931066\n",
      "Iteration 5, loss = 0.68930436\n",
      "Iteration 6, loss = 0.68929820\n",
      "Iteration 7, loss = 0.68929219\n",
      "Iteration 8, loss = 0.68928636\n",
      "Iteration 9, loss = 0.68928070\n",
      "Iteration 10, loss = 0.68927523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.68926994\n",
      "Iteration 12, loss = 0.68926483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "173\n",
      "Iteration 1, loss = 0.69965888\n",
      "Iteration 2, loss = 0.69963775\n",
      "Iteration 3, loss = 0.69962434\n",
      "Iteration 4, loss = 0.69961122\n",
      "Iteration 5, loss = 0.69959833\n",
      "Iteration 6, loss = 0.69958572\n",
      "Iteration 7, loss = 0.69957343\n",
      "Iteration 8, loss = 0.69956149\n",
      "Iteration 9, loss = 0.69954993\n",
      "Iteration 10, loss = 0.69953874\n",
      "Iteration 11, loss = 0.69952794\n",
      "Iteration 12, loss = 0.69951751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "174\n",
      "Iteration 1, loss = 0.69474208\n",
      "Iteration 2, loss = 0.69473196\n",
      "Iteration 3, loss = 0.69472554\n",
      "Iteration 4, loss = 0.69471925\n",
      "Iteration 5, loss = 0.69471307\n",
      "Iteration 6, loss = 0.69470702\n",
      "Iteration 7, loss = 0.69470112\n",
      "Iteration 8, loss = 0.69469540\n",
      "Iteration 9, loss = 0.69468984\n",
      "Iteration 10, loss = 0.69468447\n",
      "Iteration 11, loss = 0.69467928\n",
      "Iteration 12, loss = 0.69467426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "175\n",
      "Iteration 1, loss = 0.69688291\n",
      "Iteration 2, loss = 0.69686944\n",
      "Iteration 3, loss = 0.69686089\n",
      "Iteration 4, loss = 0.69685251\n",
      "Iteration 5, loss = 0.69684429\n",
      "Iteration 6, loss = 0.69683624\n",
      "Iteration 7, loss = 0.69682839\n",
      "Iteration 8, loss = 0.69682077\n",
      "Iteration 9, loss = 0.69681339\n",
      "Iteration 10, loss = 0.69680625\n",
      "Iteration 11, loss = 0.69679935\n",
      "Iteration 12, loss = 0.69679268\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "176\n",
      "Iteration 1, loss = 0.69796307\n",
      "Iteration 2, loss = 0.69794780\n",
      "Iteration 3, loss = 0.69793810\n",
      "Iteration 4, loss = 0.69792854\n",
      "Iteration 5, loss = 0.69791915\n",
      "Iteration 6, loss = 0.69790995\n",
      "Iteration 7, loss = 0.69790098\n",
      "Iteration 8, loss = 0.69789227\n",
      "Iteration 9, loss = 0.69788382\n",
      "Iteration 10, loss = 0.69787565\n",
      "Iteration 11, loss = 0.69786776\n",
      "Iteration 12, loss = 0.69786013\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "177\n",
      "Iteration 1, loss = 0.69446761\n",
      "Iteration 2, loss = 0.69444393\n",
      "Iteration 3, loss = 0.69442891\n",
      "Iteration 4, loss = 0.69441420\n",
      "Iteration 5, loss = 0.69439976\n",
      "Iteration 6, loss = 0.69438563\n",
      "Iteration 7, loss = 0.69437186\n",
      "Iteration 8, loss = 0.69435850\n",
      "Iteration 9, loss = 0.69434554\n",
      "Iteration 10, loss = 0.69433302\n",
      "Iteration 11, loss = 0.69432092\n",
      "Iteration 12, loss = 0.69430925\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "178\n",
      "Iteration 1, loss = 0.69258967\n",
      "Iteration 2, loss = 0.69257806\n",
      "Iteration 3, loss = 0.69257070\n",
      "Iteration 4, loss = 0.69256348\n",
      "Iteration 5, loss = 0.69255639\n",
      "Iteration 6, loss = 0.69254945\n",
      "Iteration 7, loss = 0.69254269\n",
      "Iteration 8, loss = 0.69253612\n",
      "Iteration 9, loss = 0.69252975\n",
      "Iteration 10, loss = 0.69252358\n",
      "Iteration 11, loss = 0.69251763\n",
      "Iteration 12, loss = 0.69251187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "179\n",
      "Iteration 1, loss = 0.69495424\n",
      "Iteration 2, loss = 0.69493973\n",
      "Iteration 3, loss = 0.69493051\n",
      "Iteration 4, loss = 0.69492149\n",
      "Iteration 5, loss = 0.69491263\n",
      "Iteration 6, loss = 0.69490396\n",
      "Iteration 7, loss = 0.69489551\n",
      "Iteration 8, loss = 0.69488730\n",
      "Iteration 9, loss = 0.69487934\n",
      "Iteration 10, loss = 0.69487165\n",
      "Iteration 11, loss = 0.69486421\n",
      "Iteration 12, loss = 0.69485705\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "180\n",
      "Iteration 1, loss = 0.69614617\n",
      "Iteration 2, loss = 0.69612768\n",
      "Iteration 3, loss = 0.69611594\n",
      "Iteration 4, loss = 0.69610446\n",
      "Iteration 5, loss = 0.69609318\n",
      "Iteration 6, loss = 0.69608214\n",
      "Iteration 7, loss = 0.69607138\n",
      "Iteration 8, loss = 0.69606092\n",
      "Iteration 9, loss = 0.69605080\n",
      "Iteration 10, loss = 0.69604100\n",
      "Iteration 11, loss = 0.69603154\n",
      "Iteration 12, loss = 0.69602240\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "181\n",
      "Iteration 1, loss = 0.69612125\n",
      "Iteration 2, loss = 0.69611092\n",
      "Iteration 3, loss = 0.69610436\n",
      "Iteration 4, loss = 0.69609793\n",
      "Iteration 5, loss = 0.69609162\n",
      "Iteration 6, loss = 0.69608544\n",
      "Iteration 7, loss = 0.69607942\n",
      "Iteration 8, loss = 0.69607357\n",
      "Iteration 9, loss = 0.69606790\n",
      "Iteration 10, loss = 0.69606241\n",
      "Iteration 11, loss = 0.69605711\n",
      "Iteration 12, loss = 0.69605199\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "182\n",
      "Iteration 1, loss = 0.69414431\n",
      "Iteration 2, loss = 0.69412594\n",
      "Iteration 3, loss = 0.69411429\n",
      "Iteration 4, loss = 0.69410289\n",
      "Iteration 5, loss = 0.69409171\n",
      "Iteration 6, loss = 0.69408077\n",
      "Iteration 7, loss = 0.69407011\n",
      "Iteration 8, loss = 0.69405976\n",
      "Iteration 9, loss = 0.69404973\n",
      "Iteration 10, loss = 0.69404003\n",
      "Iteration 11, loss = 0.69403066\n",
      "Iteration 12, loss = 0.69402162\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "183\n",
      "Iteration 1, loss = 0.69764857\n",
      "Iteration 2, loss = 0.69762289\n",
      "Iteration 3, loss = 0.69760660\n",
      "Iteration 4, loss = 0.69759065\n",
      "Iteration 5, loss = 0.69757499\n",
      "Iteration 6, loss = 0.69755967\n",
      "Iteration 7, loss = 0.69754474\n",
      "Iteration 8, loss = 0.69753025\n",
      "Iteration 9, loss = 0.69751620\n",
      "Iteration 10, loss = 0.69750262\n",
      "Iteration 11, loss = 0.69748953\n",
      "Iteration 12, loss = 0.69747691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "184\n",
      "Iteration 1, loss = 0.69024191\n",
      "Iteration 2, loss = 0.69023172\n",
      "Iteration 3, loss = 0.69022525\n",
      "Iteration 4, loss = 0.69021891\n",
      "Iteration 5, loss = 0.69021268\n",
      "Iteration 6, loss = 0.69020658\n",
      "Iteration 7, loss = 0.69020064\n",
      "Iteration 8, loss = 0.69019486\n",
      "Iteration 9, loss = 0.69018927\n",
      "Iteration 10, loss = 0.69018385\n",
      "Iteration 11, loss = 0.69017862\n",
      "Iteration 12, loss = 0.69017356\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "185\n",
      "Iteration 1, loss = 0.70785239\n",
      "Iteration 2, loss = 0.70781143\n",
      "Iteration 3, loss = 0.70778545\n",
      "Iteration 4, loss = 0.70776003\n",
      "Iteration 5, loss = 0.70773506\n",
      "Iteration 6, loss = 0.70771064\n",
      "Iteration 7, loss = 0.70768685\n",
      "Iteration 8, loss = 0.70766376\n",
      "Iteration 9, loss = 0.70764139\n",
      "Iteration 10, loss = 0.70761976\n",
      "Iteration 11, loss = 0.70759887\n",
      "Iteration 12, loss = 0.70757872\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "186\n",
      "Iteration 1, loss = 0.69815261\n",
      "Iteration 2, loss = 0.69814177\n",
      "Iteration 3, loss = 0.69813489\n",
      "Iteration 4, loss = 0.69812815\n",
      "Iteration 5, loss = 0.69812153\n",
      "Iteration 6, loss = 0.69811505\n",
      "Iteration 7, loss = 0.69810873\n",
      "Iteration 8, loss = 0.69810259\n",
      "Iteration 9, loss = 0.69809664\n",
      "Iteration 10, loss = 0.69809089\n",
      "Iteration 11, loss = 0.69808532\n",
      "Iteration 12, loss = 0.69807995\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "187\n",
      "Iteration 1, loss = 0.69190943\n",
      "Iteration 2, loss = 0.69189490\n",
      "Iteration 3, loss = 0.69188568\n",
      "Iteration 4, loss = 0.69187665\n",
      "Iteration 5, loss = 0.69186778\n",
      "Iteration 6, loss = 0.69185909\n",
      "Iteration 7, loss = 0.69185063\n",
      "Iteration 8, loss = 0.69184245\n",
      "Iteration 9, loss = 0.69183453\n",
      "Iteration 10, loss = 0.69182687\n",
      "Iteration 11, loss = 0.69181947\n",
      "Iteration 12, loss = 0.69181232\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "188\n",
      "Iteration 1, loss = 0.69920013\n",
      "Iteration 2, loss = 0.69917878\n",
      "Iteration 3, loss = 0.69916529\n",
      "Iteration 4, loss = 0.69915209\n",
      "Iteration 5, loss = 0.69913912\n",
      "Iteration 6, loss = 0.69912642\n",
      "Iteration 7, loss = 0.69911404\n",
      "Iteration 8, loss = 0.69910202\n",
      "Iteration 9, loss = 0.69909038\n",
      "Iteration 10, loss = 0.69907911\n",
      "Iteration 11, loss = 0.69906823\n",
      "Iteration 12, loss = 0.69905772\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "189\n",
      "Iteration 1, loss = 0.69254696\n",
      "Iteration 2, loss = 0.69253588\n",
      "Iteration 3, loss = 0.69252885\n",
      "Iteration 4, loss = 0.69252197\n",
      "Iteration 5, loss = 0.69251521\n",
      "Iteration 6, loss = 0.69250859\n",
      "Iteration 7, loss = 0.69250214\n",
      "Iteration 8, loss = 0.69249588\n",
      "Iteration 9, loss = 0.69248980\n",
      "Iteration 10, loss = 0.69248393\n",
      "Iteration 11, loss = 0.69247825\n",
      "Iteration 12, loss = 0.69247277\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "190\n",
      "Iteration 1, loss = 0.68932225\n",
      "Iteration 2, loss = 0.68930782\n",
      "Iteration 3, loss = 0.68929867\n",
      "Iteration 4, loss = 0.68928970\n",
      "Iteration 5, loss = 0.68928090\n",
      "Iteration 6, loss = 0.68927228\n",
      "Iteration 7, loss = 0.68926388\n",
      "Iteration 8, loss = 0.68925572\n",
      "Iteration 9, loss = 0.68924781\n",
      "Iteration 10, loss = 0.68924016\n",
      "Iteration 11, loss = 0.68923277\n",
      "Iteration 12, loss = 0.68922563\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "191\n",
      "Iteration 1, loss = 0.68672008\n",
      "Iteration 2, loss = 0.68670732\n",
      "Iteration 3, loss = 0.68669929\n",
      "Iteration 4, loss = 0.68669145\n",
      "Iteration 5, loss = 0.68668375\n",
      "Iteration 6, loss = 0.68667622\n",
      "Iteration 7, loss = 0.68666888\n",
      "Iteration 8, loss = 0.68666176\n",
      "Iteration 9, loss = 0.68665485\n",
      "Iteration 10, loss = 0.68664817\n",
      "Iteration 11, loss = 0.68664172\n",
      "Iteration 12, loss = 0.68663550\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "192\n",
      "Iteration 1, loss = 0.69967770\n",
      "Iteration 2, loss = 0.69965355\n",
      "Iteration 3, loss = 0.69963825\n",
      "Iteration 4, loss = 0.69962328\n",
      "Iteration 5, loss = 0.69960858\n",
      "Iteration 6, loss = 0.69959419\n",
      "Iteration 7, loss = 0.69958018\n",
      "Iteration 8, loss = 0.69956658\n",
      "Iteration 9, loss = 0.69955340\n",
      "Iteration 10, loss = 0.69954065\n",
      "Iteration 11, loss = 0.69952834\n",
      "Iteration 12, loss = 0.69951647\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "193\n",
      "Iteration 1, loss = 0.69233627\n",
      "Iteration 2, loss = 0.69232506\n",
      "Iteration 3, loss = 0.69231792\n",
      "Iteration 4, loss = 0.69231093\n",
      "Iteration 5, loss = 0.69230405\n",
      "Iteration 6, loss = 0.69229731\n",
      "Iteration 7, loss = 0.69229075\n",
      "Iteration 8, loss = 0.69228436\n",
      "Iteration 9, loss = 0.69227818\n",
      "Iteration 10, loss = 0.69227219\n",
      "Iteration 11, loss = 0.69226640\n",
      "Iteration 12, loss = 0.69226081\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "194\n",
      "Iteration 1, loss = 0.69217101\n",
      "Iteration 2, loss = 0.69215403\n",
      "Iteration 3, loss = 0.69214324\n",
      "Iteration 4, loss = 0.69213266\n",
      "Iteration 5, loss = 0.69212227\n",
      "Iteration 6, loss = 0.69211210\n",
      "Iteration 7, loss = 0.69210218\n",
      "Iteration 8, loss = 0.69209255\n",
      "Iteration 9, loss = 0.69208322\n",
      "Iteration 10, loss = 0.69207419\n",
      "Iteration 11, loss = 0.69206546\n",
      "Iteration 12, loss = 0.69205709\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "195\n",
      "Iteration 1, loss = 0.69118899\n",
      "Iteration 2, loss = 0.69117759\n",
      "Iteration 3, loss = 0.69117036\n",
      "Iteration 4, loss = 0.69116328\n",
      "Iteration 5, loss = 0.69115631\n",
      "Iteration 6, loss = 0.69114950\n",
      "Iteration 7, loss = 0.69114285\n",
      "Iteration 8, loss = 0.69113640\n",
      "Iteration 9, loss = 0.69113014\n",
      "Iteration 10, loss = 0.69112409\n",
      "Iteration 11, loss = 0.69111824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.69111259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "196\n",
      "Iteration 1, loss = 0.69773884\n",
      "Iteration 2, loss = 0.69772176\n",
      "Iteration 3, loss = 0.69771092\n",
      "Iteration 4, loss = 0.69770031\n",
      "Iteration 5, loss = 0.69768989\n",
      "Iteration 6, loss = 0.69767969\n",
      "Iteration 7, loss = 0.69766975\n",
      "Iteration 8, loss = 0.69766010\n",
      "Iteration 9, loss = 0.69765075\n",
      "Iteration 10, loss = 0.69764170\n",
      "Iteration 11, loss = 0.69763296\n",
      "Iteration 12, loss = 0.69762454\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "197\n",
      "Iteration 1, loss = 0.69699380\n",
      "Iteration 2, loss = 0.69698195\n",
      "Iteration 3, loss = 0.69697443\n",
      "Iteration 4, loss = 0.69696707\n",
      "Iteration 5, loss = 0.69695983\n",
      "Iteration 6, loss = 0.69695274\n",
      "Iteration 7, loss = 0.69694584\n",
      "Iteration 8, loss = 0.69693913\n",
      "Iteration 9, loss = 0.69693263\n",
      "Iteration 10, loss = 0.69692634\n",
      "Iteration 11, loss = 0.69692026\n",
      "Iteration 12, loss = 0.69691439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "198\n",
      "Iteration 1, loss = 0.69278488\n",
      "Iteration 2, loss = 0.69276765\n",
      "Iteration 3, loss = 0.69275680\n",
      "Iteration 4, loss = 0.69274617\n",
      "Iteration 5, loss = 0.69273573\n",
      "Iteration 6, loss = 0.69272552\n",
      "Iteration 7, loss = 0.69271557\n",
      "Iteration 8, loss = 0.69270592\n",
      "Iteration 9, loss = 0.69269656\n",
      "Iteration 10, loss = 0.69268751\n",
      "Iteration 11, loss = 0.69267877\n",
      "Iteration 12, loss = 0.69267033\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "199\n",
      "Iteration 1, loss = 0.71181456\n",
      "Iteration 2, loss = 0.71178313\n",
      "Iteration 3, loss = 0.71176321\n",
      "Iteration 4, loss = 0.71174372\n",
      "Iteration 5, loss = 0.71172458\n",
      "Iteration 6, loss = 0.71170586\n",
      "Iteration 7, loss = 0.71168762\n",
      "Iteration 8, loss = 0.71166992\n",
      "Iteration 9, loss = 0.71165277\n",
      "Iteration 10, loss = 0.71163619\n",
      "Iteration 11, loss = 0.71162017\n",
      "Iteration 12, loss = 0.71160472\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "200\n",
      "Iteration 1, loss = 0.69578173\n",
      "Iteration 2, loss = 0.69576787\n",
      "Iteration 3, loss = 0.69575907\n",
      "Iteration 4, loss = 0.69575046\n",
      "Iteration 5, loss = 0.69574199\n",
      "Iteration 6, loss = 0.69573371\n",
      "Iteration 7, loss = 0.69572564\n",
      "Iteration 8, loss = 0.69571779\n",
      "Iteration 9, loss = 0.69571019\n",
      "Iteration 10, loss = 0.69570284\n",
      "Iteration 11, loss = 0.69569574\n",
      "Iteration 12, loss = 0.69568888\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "201\n",
      "Iteration 1, loss = 0.69910146\n",
      "Iteration 2, loss = 0.69908517\n",
      "Iteration 3, loss = 0.69907483\n",
      "Iteration 4, loss = 0.69906471\n",
      "Iteration 5, loss = 0.69905476\n",
      "Iteration 6, loss = 0.69904503\n",
      "Iteration 7, loss = 0.69903555\n",
      "Iteration 8, loss = 0.69902634\n",
      "Iteration 9, loss = 0.69901742\n",
      "Iteration 10, loss = 0.69900878\n",
      "Iteration 11, loss = 0.69900044\n",
      "Iteration 12, loss = 0.69899239\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "202\n",
      "Iteration 1, loss = 0.69221712\n",
      "Iteration 2, loss = 0.69220446\n",
      "Iteration 3, loss = 0.69219643\n",
      "Iteration 4, loss = 0.69218856\n",
      "Iteration 5, loss = 0.69218083\n",
      "Iteration 6, loss = 0.69217327\n",
      "Iteration 7, loss = 0.69216589\n",
      "Iteration 8, loss = 0.69215873\n",
      "Iteration 9, loss = 0.69215178\n",
      "Iteration 10, loss = 0.69214507\n",
      "Iteration 11, loss = 0.69213857\n",
      "Iteration 12, loss = 0.69213231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "203\n",
      "Iteration 1, loss = 0.69284790\n",
      "Iteration 2, loss = 0.69282968\n",
      "Iteration 3, loss = 0.69281812\n",
      "Iteration 4, loss = 0.69280681\n",
      "Iteration 5, loss = 0.69279570\n",
      "Iteration 6, loss = 0.69278482\n",
      "Iteration 7, loss = 0.69277423\n",
      "Iteration 8, loss = 0.69276394\n",
      "Iteration 9, loss = 0.69275397\n",
      "Iteration 10, loss = 0.69274432\n",
      "Iteration 11, loss = 0.69273502\n",
      "Iteration 12, loss = 0.69272605\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "204\n",
      "Iteration 1, loss = 0.69874312\n",
      "Iteration 2, loss = 0.69873216\n",
      "Iteration 3, loss = 0.69872520\n",
      "Iteration 4, loss = 0.69871839\n",
      "Iteration 5, loss = 0.69871169\n",
      "Iteration 6, loss = 0.69870514\n",
      "Iteration 7, loss = 0.69869876\n",
      "Iteration 8, loss = 0.69869255\n",
      "Iteration 9, loss = 0.69868654\n",
      "Iteration 10, loss = 0.69868072\n",
      "Iteration 11, loss = 0.69867510\n",
      "Iteration 12, loss = 0.69866967\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "205\n",
      "Iteration 1, loss = 0.69300932\n",
      "Iteration 2, loss = 0.69299867\n",
      "Iteration 3, loss = 0.69299191\n",
      "Iteration 4, loss = 0.69298529\n",
      "Iteration 5, loss = 0.69297879\n",
      "Iteration 6, loss = 0.69297242\n",
      "Iteration 7, loss = 0.69296622\n",
      "Iteration 8, loss = 0.69296019\n",
      "Iteration 9, loss = 0.69295434\n",
      "Iteration 10, loss = 0.69294869\n",
      "Iteration 11, loss = 0.69294322\n",
      "Iteration 12, loss = 0.69293795\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "206\n",
      "Iteration 1, loss = 0.69412923\n",
      "Iteration 2, loss = 0.69411761\n",
      "Iteration 3, loss = 0.69411024\n",
      "Iteration 4, loss = 0.69410301\n",
      "Iteration 5, loss = 0.69409591\n",
      "Iteration 6, loss = 0.69408896\n",
      "Iteration 7, loss = 0.69408218\n",
      "Iteration 8, loss = 0.69407560\n",
      "Iteration 9, loss = 0.69406922\n",
      "Iteration 10, loss = 0.69406305\n",
      "Iteration 11, loss = 0.69405709\n",
      "Iteration 12, loss = 0.69405133\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "207\n",
      "Iteration 1, loss = 0.69815775\n",
      "Iteration 2, loss = 0.69814290\n",
      "Iteration 3, loss = 0.69813350\n",
      "Iteration 4, loss = 0.69812431\n",
      "Iteration 5, loss = 0.69811527\n",
      "Iteration 6, loss = 0.69810643\n",
      "Iteration 7, loss = 0.69809782\n",
      "Iteration 8, loss = 0.69808946\n",
      "Iteration 9, loss = 0.69808135\n",
      "Iteration 10, loss = 0.69807352\n",
      "Iteration 11, loss = 0.69806594\n",
      "Iteration 12, loss = 0.69805862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "208\n",
      "Iteration 1, loss = 0.69049591\n",
      "Iteration 2, loss = 0.69048296\n",
      "Iteration 3, loss = 0.69047474\n",
      "Iteration 4, loss = 0.69046669\n",
      "Iteration 5, loss = 0.69045878\n",
      "Iteration 6, loss = 0.69045104\n",
      "Iteration 7, loss = 0.69044350\n",
      "Iteration 8, loss = 0.69043617\n",
      "Iteration 9, loss = 0.69042907\n",
      "Iteration 10, loss = 0.69042220\n",
      "Iteration 11, loss = 0.69041556\n",
      "Iteration 12, loss = 0.69040916\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "209\n",
      "Iteration 1, loss = 0.69824152\n",
      "Iteration 2, loss = 0.69822940\n",
      "Iteration 3, loss = 0.69822171\n",
      "Iteration 4, loss = 0.69821418\n",
      "Iteration 5, loss = 0.69820677\n",
      "Iteration 6, loss = 0.69819953\n",
      "Iteration 7, loss = 0.69819247\n",
      "Iteration 8, loss = 0.69818561\n",
      "Iteration 9, loss = 0.69817896\n",
      "Iteration 10, loss = 0.69817252\n",
      "Iteration 11, loss = 0.69816630\n",
      "Iteration 12, loss = 0.69816030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "210\n",
      "Iteration 1, loss = 0.69830940\n",
      "Iteration 2, loss = 0.69829928\n",
      "Iteration 3, loss = 0.69829285\n",
      "Iteration 4, loss = 0.69828656\n",
      "Iteration 5, loss = 0.69828038\n",
      "Iteration 6, loss = 0.69827433\n",
      "Iteration 7, loss = 0.69826843\n",
      "Iteration 8, loss = 0.69826270\n",
      "Iteration 9, loss = 0.69825714\n",
      "Iteration 10, loss = 0.69825177\n",
      "Iteration 11, loss = 0.69824657\n",
      "Iteration 12, loss = 0.69824156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "211\n",
      "Iteration 1, loss = 0.69662239\n",
      "Iteration 2, loss = 0.69660332\n",
      "Iteration 3, loss = 0.69659123\n",
      "Iteration 4, loss = 0.69657939\n",
      "Iteration 5, loss = 0.69656775\n",
      "Iteration 6, loss = 0.69655637\n",
      "Iteration 7, loss = 0.69654528\n",
      "Iteration 8, loss = 0.69653452\n",
      "Iteration 9, loss = 0.69652409\n",
      "Iteration 10, loss = 0.69651401\n",
      "Iteration 11, loss = 0.69650427\n",
      "Iteration 12, loss = 0.69649486\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "212\n",
      "Iteration 1, loss = 0.68845170\n",
      "Iteration 2, loss = 0.68843905\n",
      "Iteration 3, loss = 0.68843103\n",
      "Iteration 4, loss = 0.68842318\n",
      "Iteration 5, loss = 0.68841546\n",
      "Iteration 6, loss = 0.68840790\n",
      "Iteration 7, loss = 0.68840054\n",
      "Iteration 8, loss = 0.68839339\n",
      "Iteration 9, loss = 0.68838646\n",
      "Iteration 10, loss = 0.68837976\n",
      "Iteration 11, loss = 0.68837328\n",
      "Iteration 12, loss = 0.68836702\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "213\n",
      "Iteration 1, loss = 0.70523259\n",
      "Iteration 2, loss = 0.70521036\n",
      "Iteration 3, loss = 0.70519626\n",
      "Iteration 4, loss = 0.70518246\n",
      "Iteration 5, loss = 0.70516890\n",
      "Iteration 6, loss = 0.70515564\n",
      "Iteration 7, loss = 0.70514272\n",
      "Iteration 8, loss = 0.70513017\n",
      "Iteration 9, loss = 0.70511802\n",
      "Iteration 10, loss = 0.70510626\n",
      "Iteration 11, loss = 0.70509491\n",
      "Iteration 12, loss = 0.70508395\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "214\n",
      "Iteration 1, loss = 0.69534487\n",
      "Iteration 2, loss = 0.69533000\n",
      "Iteration 3, loss = 0.69532053\n",
      "Iteration 4, loss = 0.69531126\n",
      "Iteration 5, loss = 0.69530215\n",
      "Iteration 6, loss = 0.69529323\n",
      "Iteration 7, loss = 0.69528454\n",
      "Iteration 8, loss = 0.69527610\n",
      "Iteration 9, loss = 0.69526792\n",
      "Iteration 10, loss = 0.69526000\n",
      "Iteration 11, loss = 0.69525236\n",
      "Iteration 12, loss = 0.69524497\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "215\n",
      "Iteration 1, loss = 0.69470854\n",
      "Iteration 2, loss = 0.69469509\n",
      "Iteration 3, loss = 0.69468656\n",
      "Iteration 4, loss = 0.69467822\n",
      "Iteration 5, loss = 0.69467002\n",
      "Iteration 6, loss = 0.69466199\n",
      "Iteration 7, loss = 0.69465417\n",
      "Iteration 8, loss = 0.69464657\n",
      "Iteration 9, loss = 0.69463920\n",
      "Iteration 10, loss = 0.69463207\n",
      "Iteration 11, loss = 0.69462514\n",
      "Iteration 12, loss = 0.69461846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "216\n",
      "Iteration 1, loss = 0.69698443\n",
      "Iteration 2, loss = 0.69696647\n",
      "Iteration 3, loss = 0.69695508\n",
      "Iteration 4, loss = 0.69694393\n",
      "Iteration 5, loss = 0.69693298\n",
      "Iteration 6, loss = 0.69692227\n",
      "Iteration 7, loss = 0.69691183\n",
      "Iteration 8, loss = 0.69690169\n",
      "Iteration 9, loss = 0.69689187\n",
      "Iteration 10, loss = 0.69688237\n",
      "Iteration 11, loss = 0.69687319\n",
      "Iteration 12, loss = 0.69686433\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "217\n",
      "Iteration 1, loss = 0.69971028\n",
      "Iteration 2, loss = 0.69968860\n",
      "Iteration 3, loss = 0.69967485\n",
      "Iteration 4, loss = 0.69966139\n",
      "Iteration 5, loss = 0.69964817\n",
      "Iteration 6, loss = 0.69963525\n",
      "Iteration 7, loss = 0.69962270\n",
      "Iteration 8, loss = 0.69961052\n",
      "Iteration 9, loss = 0.69959874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.69958735\n",
      "Iteration 11, loss = 0.69957636\n",
      "Iteration 12, loss = 0.69956574\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "218\n",
      "Iteration 1, loss = 0.69520433\n",
      "Iteration 2, loss = 0.69519056\n",
      "Iteration 3, loss = 0.69518181\n",
      "Iteration 4, loss = 0.69517325\n",
      "Iteration 5, loss = 0.69516484\n",
      "Iteration 6, loss = 0.69515661\n",
      "Iteration 7, loss = 0.69514859\n",
      "Iteration 8, loss = 0.69514080\n",
      "Iteration 9, loss = 0.69513324\n",
      "Iteration 10, loss = 0.69512594\n",
      "Iteration 11, loss = 0.69511888\n",
      "Iteration 12, loss = 0.69511206\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "219\n",
      "Iteration 1, loss = 0.69211426\n",
      "Iteration 2, loss = 0.69210365\n",
      "Iteration 3, loss = 0.69209691\n",
      "Iteration 4, loss = 0.69209032\n",
      "Iteration 5, loss = 0.69208384\n",
      "Iteration 6, loss = 0.69207749\n",
      "Iteration 7, loss = 0.69207131\n",
      "Iteration 8, loss = 0.69206530\n",
      "Iteration 9, loss = 0.69205950\n",
      "Iteration 10, loss = 0.69205390\n",
      "Iteration 11, loss = 0.69204848\n",
      "Iteration 12, loss = 0.69204324\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "220\n",
      "Iteration 1, loss = 0.69798306\n",
      "Iteration 2, loss = 0.69796778\n",
      "Iteration 3, loss = 0.69795808\n",
      "Iteration 4, loss = 0.69794859\n",
      "Iteration 5, loss = 0.69793926\n",
      "Iteration 6, loss = 0.69793014\n",
      "Iteration 7, loss = 0.69792125\n",
      "Iteration 8, loss = 0.69791261\n",
      "Iteration 9, loss = 0.69790424\n",
      "Iteration 10, loss = 0.69789614\n",
      "Iteration 11, loss = 0.69788832\n",
      "Iteration 12, loss = 0.69788077\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "221\n",
      "Iteration 1, loss = 0.69507766\n",
      "Iteration 2, loss = 0.69505825\n",
      "Iteration 3, loss = 0.69504593\n",
      "Iteration 4, loss = 0.69503388\n",
      "Iteration 5, loss = 0.69502204\n",
      "Iteration 6, loss = 0.69501045\n",
      "Iteration 7, loss = 0.69499916\n",
      "Iteration 8, loss = 0.69498817\n",
      "Iteration 9, loss = 0.69497752\n",
      "Iteration 10, loss = 0.69496722\n",
      "Iteration 11, loss = 0.69495727\n",
      "Iteration 12, loss = 0.69494766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "222\n",
      "Iteration 1, loss = 0.70349448\n",
      "Iteration 2, loss = 0.70347508\n",
      "Iteration 3, loss = 0.70346278\n",
      "Iteration 4, loss = 0.70345073\n",
      "Iteration 5, loss = 0.70343889\n",
      "Iteration 6, loss = 0.70342731\n",
      "Iteration 7, loss = 0.70341603\n",
      "Iteration 8, loss = 0.70340508\n",
      "Iteration 9, loss = 0.70339446\n",
      "Iteration 10, loss = 0.70338420\n",
      "Iteration 11, loss = 0.70337428\n",
      "Iteration 12, loss = 0.70336471\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "223\n",
      "Iteration 1, loss = 0.70271120\n",
      "Iteration 2, loss = 0.70268628\n",
      "Iteration 3, loss = 0.70267046\n",
      "Iteration 4, loss = 0.70265499\n",
      "Iteration 5, loss = 0.70263979\n",
      "Iteration 6, loss = 0.70262492\n",
      "Iteration 7, loss = 0.70261043\n",
      "Iteration 8, loss = 0.70259637\n",
      "Iteration 9, loss = 0.70258274\n",
      "Iteration 10, loss = 0.70256957\n",
      "Iteration 11, loss = 0.70255684\n",
      "Iteration 12, loss = 0.70254456\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "224\n",
      "Iteration 1, loss = 0.69125253\n",
      "Iteration 2, loss = 0.69123685\n",
      "Iteration 3, loss = 0.69122688\n",
      "Iteration 4, loss = 0.69121713\n",
      "Iteration 5, loss = 0.69120755\n",
      "Iteration 6, loss = 0.69119817\n",
      "Iteration 7, loss = 0.69118903\n",
      "Iteration 8, loss = 0.69118016\n",
      "Iteration 9, loss = 0.69117151\n",
      "Iteration 10, loss = 0.69116312\n",
      "Iteration 11, loss = 0.69115501\n",
      "Iteration 12, loss = 0.69114721\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "225\n",
      "Iteration 1, loss = 0.69428658\n",
      "Iteration 2, loss = 0.69427481\n",
      "Iteration 3, loss = 0.69426733\n",
      "Iteration 4, loss = 0.69426002\n",
      "Iteration 5, loss = 0.69425283\n",
      "Iteration 6, loss = 0.69424579\n",
      "Iteration 7, loss = 0.69423894\n",
      "Iteration 8, loss = 0.69423228\n",
      "Iteration 9, loss = 0.69422582\n",
      "Iteration 10, loss = 0.69421958\n",
      "Iteration 11, loss = 0.69421354\n",
      "Iteration 12, loss = 0.69420772\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "226\n",
      "Iteration 1, loss = 0.69643526\n",
      "Iteration 2, loss = 0.69642503\n",
      "Iteration 3, loss = 0.69641854\n",
      "Iteration 4, loss = 0.69641219\n",
      "Iteration 5, loss = 0.69640595\n",
      "Iteration 6, loss = 0.69639984\n",
      "Iteration 7, loss = 0.69639389\n",
      "Iteration 8, loss = 0.69638811\n",
      "Iteration 9, loss = 0.69638250\n",
      "Iteration 10, loss = 0.69637708\n",
      "Iteration 11, loss = 0.69637184\n",
      "Iteration 12, loss = 0.69636679\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "227\n",
      "Iteration 1, loss = 0.70073064\n",
      "Iteration 2, loss = 0.70071730\n",
      "Iteration 3, loss = 0.70070882\n",
      "Iteration 4, loss = 0.70070052\n",
      "Iteration 5, loss = 0.70069237\n",
      "Iteration 6, loss = 0.70068439\n",
      "Iteration 7, loss = 0.70067661\n",
      "Iteration 8, loss = 0.70066906\n",
      "Iteration 9, loss = 0.70066174\n",
      "Iteration 10, loss = 0.70065465\n",
      "Iteration 11, loss = 0.70064781\n",
      "Iteration 12, loss = 0.70064120\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "228\n",
      "Iteration 1, loss = 0.69822993\n",
      "Iteration 2, loss = 0.69821199\n",
      "Iteration 3, loss = 0.69820060\n",
      "Iteration 4, loss = 0.69818945\n",
      "Iteration 5, loss = 0.69817850\n",
      "Iteration 6, loss = 0.69816779\n",
      "Iteration 7, loss = 0.69815735\n",
      "Iteration 8, loss = 0.69814721\n",
      "Iteration 9, loss = 0.69813738\n",
      "Iteration 10, loss = 0.69812787\n",
      "Iteration 11, loss = 0.69811869\n",
      "Iteration 12, loss = 0.69810983\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "229\n",
      "Iteration 1, loss = 0.68925615\n",
      "Iteration 2, loss = 0.68923603\n",
      "Iteration 3, loss = 0.68922326\n",
      "Iteration 4, loss = 0.68921077\n",
      "Iteration 5, loss = 0.68919850\n",
      "Iteration 6, loss = 0.68918649\n",
      "Iteration 7, loss = 0.68917479\n",
      "Iteration 8, loss = 0.68916343\n",
      "Iteration 9, loss = 0.68915242\n",
      "Iteration 10, loss = 0.68914177\n",
      "Iteration 11, loss = 0.68913149\n",
      "Iteration 12, loss = 0.68912156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "230\n",
      "Iteration 1, loss = 0.70531073\n",
      "Iteration 2, loss = 0.70528280\n",
      "Iteration 3, loss = 0.70526510\n",
      "Iteration 4, loss = 0.70524777\n",
      "Iteration 5, loss = 0.70523074\n",
      "Iteration 6, loss = 0.70521410\n",
      "Iteration 7, loss = 0.70519788\n",
      "Iteration 8, loss = 0.70518213\n",
      "Iteration 9, loss = 0.70516688\n",
      "Iteration 10, loss = 0.70515213\n",
      "Iteration 11, loss = 0.70513788\n",
      "Iteration 12, loss = 0.70512414\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "231\n",
      "Iteration 1, loss = 0.69385384\n",
      "Iteration 2, loss = 0.69383795\n",
      "Iteration 3, loss = 0.69382787\n",
      "Iteration 4, loss = 0.69381800\n",
      "Iteration 5, loss = 0.69380830\n",
      "Iteration 6, loss = 0.69379881\n",
      "Iteration 7, loss = 0.69378957\n",
      "Iteration 8, loss = 0.69378058\n",
      "Iteration 9, loss = 0.69377188\n",
      "Iteration 10, loss = 0.69376346\n",
      "Iteration 11, loss = 0.69375532\n",
      "Iteration 12, loss = 0.69374747\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "232\n",
      "Iteration 1, loss = 0.70260502\n",
      "Iteration 2, loss = 0.70258994\n",
      "Iteration 3, loss = 0.70258037\n",
      "Iteration 4, loss = 0.70257100\n",
      "Iteration 5, loss = 0.70256179\n",
      "Iteration 6, loss = 0.70255278\n",
      "Iteration 7, loss = 0.70254399\n",
      "Iteration 8, loss = 0.70253546\n",
      "Iteration 9, loss = 0.70252720\n",
      "Iteration 10, loss = 0.70251920\n",
      "Iteration 11, loss = 0.70251147\n",
      "Iteration 12, loss = 0.70250401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "233\n",
      "Iteration 1, loss = 0.69685485\n",
      "Iteration 2, loss = 0.69683350\n",
      "Iteration 3, loss = 0.69681996\n",
      "Iteration 4, loss = 0.69680671\n",
      "Iteration 5, loss = 0.69679369\n",
      "Iteration 6, loss = 0.69678097\n",
      "Iteration 7, loss = 0.69676859\n",
      "Iteration 8, loss = 0.69675656\n",
      "Iteration 9, loss = 0.69674492\n",
      "Iteration 10, loss = 0.69673365\n",
      "Iteration 11, loss = 0.69672278\n",
      "Iteration 12, loss = 0.69671228\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "234\n",
      "Iteration 1, loss = 0.68992840\n",
      "Iteration 2, loss = 0.68991612\n",
      "Iteration 3, loss = 0.68990832\n",
      "Iteration 4, loss = 0.68990068\n",
      "Iteration 5, loss = 0.68989317\n",
      "Iteration 6, loss = 0.68988581\n",
      "Iteration 7, loss = 0.68987865\n",
      "Iteration 8, loss = 0.68987169\n",
      "Iteration 9, loss = 0.68986494\n",
      "Iteration 10, loss = 0.68985841\n",
      "Iteration 11, loss = 0.68985210\n",
      "Iteration 12, loss = 0.68984600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "235\n",
      "Iteration 1, loss = 0.69365186\n",
      "Iteration 2, loss = 0.69364073\n",
      "Iteration 3, loss = 0.69363366\n",
      "Iteration 4, loss = 0.69362675\n",
      "Iteration 5, loss = 0.69361995\n",
      "Iteration 6, loss = 0.69361329\n",
      "Iteration 7, loss = 0.69360680\n",
      "Iteration 8, loss = 0.69360050\n",
      "Iteration 9, loss = 0.69359439\n",
      "Iteration 10, loss = 0.69358848\n",
      "Iteration 11, loss = 0.69358277\n",
      "Iteration 12, loss = 0.69357725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "236\n",
      "Iteration 1, loss = 0.69846729\n",
      "Iteration 2, loss = 0.69844667\n",
      "Iteration 3, loss = 0.69843360\n",
      "Iteration 4, loss = 0.69842080\n",
      "Iteration 5, loss = 0.69840822\n",
      "Iteration 6, loss = 0.69839592\n",
      "Iteration 7, loss = 0.69838393\n",
      "Iteration 8, loss = 0.69837229\n",
      "Iteration 9, loss = 0.69836102\n",
      "Iteration 10, loss = 0.69835011\n",
      "Iteration 11, loss = 0.69833957\n",
      "Iteration 12, loss = 0.69832940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "237\n",
      "Iteration 1, loss = 0.69544774\n",
      "Iteration 2, loss = 0.69543749\n",
      "Iteration 3, loss = 0.69543098\n",
      "Iteration 4, loss = 0.69542460\n",
      "Iteration 5, loss = 0.69541834\n",
      "Iteration 6, loss = 0.69541220\n",
      "Iteration 7, loss = 0.69540623\n",
      "Iteration 8, loss = 0.69540042\n",
      "Iteration 9, loss = 0.69539479\n",
      "Iteration 10, loss = 0.69538935\n",
      "Iteration 11, loss = 0.69538409\n",
      "Iteration 12, loss = 0.69537901\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "238\n",
      "Iteration 1, loss = 0.69673172\n",
      "Iteration 2, loss = 0.69671877\n",
      "Iteration 3, loss = 0.69671055\n",
      "Iteration 4, loss = 0.69670251\n",
      "Iteration 5, loss = 0.69669460\n",
      "Iteration 6, loss = 0.69668687\n",
      "Iteration 7, loss = 0.69667932\n",
      "Iteration 8, loss = 0.69667199\n",
      "Iteration 9, loss = 0.69666489\n",
      "Iteration 10, loss = 0.69665802\n",
      "Iteration 11, loss = 0.69665138\n",
      "Iteration 12, loss = 0.69664497\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "239\n",
      "Iteration 1, loss = 0.69380214\n",
      "Iteration 2, loss = 0.69379096\n",
      "Iteration 3, loss = 0.69378387\n",
      "Iteration 4, loss = 0.69377692\n",
      "Iteration 5, loss = 0.69377009\n",
      "Iteration 6, loss = 0.69376340\n",
      "Iteration 7, loss = 0.69375690\n",
      "Iteration 8, loss = 0.69375058\n",
      "Iteration 9, loss = 0.69374446\n",
      "Iteration 10, loss = 0.69373854\n",
      "Iteration 11, loss = 0.69373281\n",
      "Iteration 12, loss = 0.69372729\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69173889\n",
      "Iteration 2, loss = 0.69172193\n",
      "Iteration 3, loss = 0.69171116\n",
      "Iteration 4, loss = 0.69170062\n",
      "Iteration 5, loss = 0.69169027\n",
      "Iteration 6, loss = 0.69168014\n",
      "Iteration 7, loss = 0.69167027\n",
      "Iteration 8, loss = 0.69166068\n",
      "Iteration 9, loss = 0.69165140\n",
      "Iteration 10, loss = 0.69164241\n",
      "Iteration 11, loss = 0.69163373\n",
      "Iteration 12, loss = 0.69162536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "241\n",
      "Iteration 1, loss = 0.69953353\n",
      "Iteration 2, loss = 0.69950351\n",
      "Iteration 3, loss = 0.69948448\n",
      "Iteration 4, loss = 0.69946585\n",
      "Iteration 5, loss = 0.69944755\n",
      "Iteration 6, loss = 0.69942965\n",
      "Iteration 7, loss = 0.69941222\n",
      "Iteration 8, loss = 0.69939529\n",
      "Iteration 9, loss = 0.69937889\n",
      "Iteration 10, loss = 0.69936304\n",
      "Iteration 11, loss = 0.69934772\n",
      "Iteration 12, loss = 0.69933295\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "242\n",
      "Iteration 1, loss = 0.69938458\n",
      "Iteration 2, loss = 0.69937349\n",
      "Iteration 3, loss = 0.69936644\n",
      "Iteration 4, loss = 0.69935954\n",
      "Iteration 5, loss = 0.69935276\n",
      "Iteration 6, loss = 0.69934613\n",
      "Iteration 7, loss = 0.69933966\n",
      "Iteration 8, loss = 0.69933338\n",
      "Iteration 9, loss = 0.69932729\n",
      "Iteration 10, loss = 0.69932139\n",
      "Iteration 11, loss = 0.69931570\n",
      "Iteration 12, loss = 0.69931020\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "243\n",
      "Iteration 1, loss = 0.69109522\n",
      "Iteration 2, loss = 0.69108227\n",
      "Iteration 3, loss = 0.69107406\n",
      "Iteration 4, loss = 0.69106601\n",
      "Iteration 5, loss = 0.69105811\n",
      "Iteration 6, loss = 0.69105037\n",
      "Iteration 7, loss = 0.69104283\n",
      "Iteration 8, loss = 0.69103551\n",
      "Iteration 9, loss = 0.69102841\n",
      "Iteration 10, loss = 0.69102154\n",
      "Iteration 11, loss = 0.69101491\n",
      "Iteration 12, loss = 0.69100850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "244\n",
      "Iteration 1, loss = 0.69795421\n",
      "Iteration 2, loss = 0.69793903\n",
      "Iteration 3, loss = 0.69792938\n",
      "Iteration 4, loss = 0.69791995\n",
      "Iteration 5, loss = 0.69791067\n",
      "Iteration 6, loss = 0.69790159\n",
      "Iteration 7, loss = 0.69789275\n",
      "Iteration 8, loss = 0.69788415\n",
      "Iteration 9, loss = 0.69787582\n",
      "Iteration 10, loss = 0.69786776\n",
      "Iteration 11, loss = 0.69785998\n",
      "Iteration 12, loss = 0.69785246\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "245\n",
      "Iteration 1, loss = 0.69841206\n",
      "Iteration 2, loss = 0.69839837\n",
      "Iteration 3, loss = 0.69838968\n",
      "Iteration 4, loss = 0.69838118\n",
      "Iteration 5, loss = 0.69837281\n",
      "Iteration 6, loss = 0.69836463\n",
      "Iteration 7, loss = 0.69835665\n",
      "Iteration 8, loss = 0.69834890\n",
      "Iteration 9, loss = 0.69834139\n",
      "Iteration 10, loss = 0.69833412\n",
      "Iteration 11, loss = 0.69832710\n",
      "Iteration 12, loss = 0.69832032\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "246\n",
      "Iteration 1, loss = 0.69837316\n",
      "Iteration 2, loss = 0.69836034\n",
      "Iteration 3, loss = 0.69835220\n",
      "Iteration 4, loss = 0.69834423\n",
      "Iteration 5, loss = 0.69833639\n",
      "Iteration 6, loss = 0.69832872\n",
      "Iteration 7, loss = 0.69832125\n",
      "Iteration 8, loss = 0.69831399\n",
      "Iteration 9, loss = 0.69830695\n",
      "Iteration 10, loss = 0.69830014\n",
      "Iteration 11, loss = 0.69829356\n",
      "Iteration 12, loss = 0.69828721\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "247\n",
      "Iteration 1, loss = 0.69596902\n",
      "Iteration 2, loss = 0.69595314\n",
      "Iteration 3, loss = 0.69594305\n",
      "Iteration 4, loss = 0.69593318\n",
      "Iteration 5, loss = 0.69592347\n",
      "Iteration 6, loss = 0.69591398\n",
      "Iteration 7, loss = 0.69590473\n",
      "Iteration 8, loss = 0.69589575\n",
      "Iteration 9, loss = 0.69588706\n",
      "Iteration 10, loss = 0.69587864\n",
      "Iteration 11, loss = 0.69587051\n",
      "Iteration 12, loss = 0.69586267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "248\n",
      "Iteration 1, loss = 0.69658232\n",
      "Iteration 2, loss = 0.69655743\n",
      "Iteration 3, loss = 0.69654165\n",
      "Iteration 4, loss = 0.69652620\n",
      "Iteration 5, loss = 0.69651102\n",
      "Iteration 6, loss = 0.69649617\n",
      "Iteration 7, loss = 0.69648171\n",
      "Iteration 8, loss = 0.69646767\n",
      "Iteration 9, loss = 0.69645406\n",
      "Iteration 10, loss = 0.69644090\n",
      "Iteration 11, loss = 0.69642819\n",
      "Iteration 12, loss = 0.69641593\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "249\n",
      "Iteration 1, loss = 0.69034167\n",
      "Iteration 2, loss = 0.69033125\n",
      "Iteration 3, loss = 0.69032463\n",
      "Iteration 4, loss = 0.69031815\n",
      "Iteration 5, loss = 0.69031179\n",
      "Iteration 6, loss = 0.69030556\n",
      "Iteration 7, loss = 0.69029948\n",
      "Iteration 8, loss = 0.69029358\n",
      "Iteration 9, loss = 0.69028787\n",
      "Iteration 10, loss = 0.69028233\n",
      "Iteration 11, loss = 0.69027699\n",
      "Iteration 12, loss = 0.69027183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "250\n",
      "Iteration 1, loss = 0.69530068\n",
      "Iteration 2, loss = 0.69528700\n",
      "Iteration 3, loss = 0.69527831\n",
      "Iteration 4, loss = 0.69526981\n",
      "Iteration 5, loss = 0.69526146\n",
      "Iteration 6, loss = 0.69525329\n",
      "Iteration 7, loss = 0.69524532\n",
      "Iteration 8, loss = 0.69523758\n",
      "Iteration 9, loss = 0.69523008\n",
      "Iteration 10, loss = 0.69522282\n",
      "Iteration 11, loss = 0.69521581\n",
      "Iteration 12, loss = 0.69520905\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "251\n",
      "Iteration 1, loss = 0.69798223\n",
      "Iteration 2, loss = 0.69796769\n",
      "Iteration 3, loss = 0.69795847\n",
      "Iteration 4, loss = 0.69794944\n",
      "Iteration 5, loss = 0.69794057\n",
      "Iteration 6, loss = 0.69793189\n",
      "Iteration 7, loss = 0.69792344\n",
      "Iteration 8, loss = 0.69791522\n",
      "Iteration 9, loss = 0.69790727\n",
      "Iteration 10, loss = 0.69789957\n",
      "Iteration 11, loss = 0.69789213\n",
      "Iteration 12, loss = 0.69788495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "252\n",
      "Iteration 1, loss = 0.69206270\n",
      "Iteration 2, loss = 0.69205058\n",
      "Iteration 3, loss = 0.69204288\n",
      "Iteration 4, loss = 0.69203535\n",
      "Iteration 5, loss = 0.69202794\n",
      "Iteration 6, loss = 0.69202070\n",
      "Iteration 7, loss = 0.69201363\n",
      "Iteration 8, loss = 0.69200677\n",
      "Iteration 9, loss = 0.69200011\n",
      "Iteration 10, loss = 0.69199368\n",
      "Iteration 11, loss = 0.69198746\n",
      "Iteration 12, loss = 0.69198145\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "253\n",
      "Iteration 1, loss = 0.69822097\n",
      "Iteration 2, loss = 0.69820863\n",
      "Iteration 3, loss = 0.69820080\n",
      "Iteration 4, loss = 0.69819314\n",
      "Iteration 5, loss = 0.69818560\n",
      "Iteration 6, loss = 0.69817823\n",
      "Iteration 7, loss = 0.69817104\n",
      "Iteration 8, loss = 0.69816407\n",
      "Iteration 9, loss = 0.69815733\n",
      "Iteration 10, loss = 0.69815082\n",
      "Iteration 11, loss = 0.69814452\n",
      "Iteration 12, loss = 0.69813845\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "254\n",
      "Iteration 1, loss = 0.69075545\n",
      "Iteration 2, loss = 0.69074397\n",
      "Iteration 3, loss = 0.69073668\n",
      "Iteration 4, loss = 0.69072955\n",
      "Iteration 5, loss = 0.69072253\n",
      "Iteration 6, loss = 0.69071567\n",
      "Iteration 7, loss = 0.69070897\n",
      "Iteration 8, loss = 0.69070247\n",
      "Iteration 9, loss = 0.69069617\n",
      "Iteration 10, loss = 0.69069008\n",
      "Iteration 11, loss = 0.69068419\n",
      "Iteration 12, loss = 0.69067850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "255\n",
      "Iteration 1, loss = 0.70291783\n",
      "Iteration 2, loss = 0.70289586\n",
      "Iteration 3, loss = 0.70288193\n",
      "Iteration 4, loss = 0.70286830\n",
      "Iteration 5, loss = 0.70285490\n",
      "Iteration 6, loss = 0.70284179\n",
      "Iteration 7, loss = 0.70282903\n",
      "Iteration 8, loss = 0.70281667\n",
      "Iteration 9, loss = 0.70280470\n",
      "Iteration 10, loss = 0.70279313\n",
      "Iteration 11, loss = 0.70278195\n",
      "Iteration 12, loss = 0.70277116\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "256\n",
      "Iteration 1, loss = 0.69868922\n",
      "Iteration 2, loss = 0.69867785\n",
      "Iteration 3, loss = 0.69867063\n",
      "Iteration 4, loss = 0.69866356\n",
      "Iteration 5, loss = 0.69865662\n",
      "Iteration 6, loss = 0.69864984\n",
      "Iteration 7, loss = 0.69864322\n",
      "Iteration 8, loss = 0.69863679\n",
      "Iteration 9, loss = 0.69863056\n",
      "Iteration 10, loss = 0.69862453\n",
      "Iteration 11, loss = 0.69861870\n",
      "Iteration 12, loss = 0.69861308\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "257\n",
      "Iteration 1, loss = 0.69614823\n",
      "Iteration 2, loss = 0.69613752\n",
      "Iteration 3, loss = 0.69613073\n",
      "Iteration 4, loss = 0.69612408\n",
      "Iteration 5, loss = 0.69611754\n",
      "Iteration 6, loss = 0.69611114\n",
      "Iteration 7, loss = 0.69610490\n",
      "Iteration 8, loss = 0.69609881\n",
      "Iteration 9, loss = 0.69609291\n",
      "Iteration 10, loss = 0.69608720\n",
      "Iteration 11, loss = 0.69608168\n",
      "Iteration 12, loss = 0.69607636\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "258\n",
      "Iteration 1, loss = 0.69037843\n",
      "Iteration 2, loss = 0.69036322\n",
      "Iteration 3, loss = 0.69035356\n",
      "Iteration 4, loss = 0.69034411\n",
      "Iteration 5, loss = 0.69033483\n",
      "Iteration 6, loss = 0.69032574\n",
      "Iteration 7, loss = 0.69031688\n",
      "Iteration 8, loss = 0.69030828\n",
      "Iteration 9, loss = 0.69029994\n",
      "Iteration 10, loss = 0.69029187\n",
      "Iteration 11, loss = 0.69028407\n",
      "Iteration 12, loss = 0.69027655\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "259\n",
      "Iteration 1, loss = 0.70261714\n",
      "Iteration 2, loss = 0.70260423\n",
      "Iteration 3, loss = 0.70259603\n",
      "Iteration 4, loss = 0.70258801\n",
      "Iteration 5, loss = 0.70258012\n",
      "Iteration 6, loss = 0.70257240\n",
      "Iteration 7, loss = 0.70256487\n",
      "Iteration 8, loss = 0.70255756\n",
      "Iteration 9, loss = 0.70255048\n",
      "Iteration 10, loss = 0.70254362\n",
      "Iteration 11, loss = 0.70253701\n",
      "Iteration 12, loss = 0.70253063\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "260\n",
      "Iteration 1, loss = 0.68940550\n",
      "Iteration 2, loss = 0.68939265\n",
      "Iteration 3, loss = 0.68938450\n",
      "Iteration 4, loss = 0.68937653\n",
      "Iteration 5, loss = 0.68936871\n",
      "Iteration 6, loss = 0.68936106\n",
      "Iteration 7, loss = 0.68935360\n",
      "Iteration 8, loss = 0.68934635\n",
      "Iteration 9, loss = 0.68933933\n",
      "Iteration 10, loss = 0.68933254\n",
      "Iteration 11, loss = 0.68932598\n",
      "Iteration 12, loss = 0.68931964\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "261\n",
      "Iteration 1, loss = 0.69892766\n",
      "Iteration 2, loss = 0.69890989\n",
      "Iteration 3, loss = 0.69889861\n",
      "Iteration 4, loss = 0.69888758\n",
      "Iteration 5, loss = 0.69887674\n",
      "Iteration 6, loss = 0.69886613\n",
      "Iteration 7, loss = 0.69885580\n",
      "Iteration 8, loss = 0.69884576\n",
      "Iteration 9, loss = 0.69883603\n",
      "Iteration 10, loss = 0.69882663\n",
      "Iteration 11, loss = 0.69881754\n",
      "Iteration 12, loss = 0.69880877\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "262\n",
      "Iteration 1, loss = 0.69385997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.69384799\n",
      "Iteration 3, loss = 0.69384039\n",
      "Iteration 4, loss = 0.69383295\n",
      "Iteration 5, loss = 0.69382563\n",
      "Iteration 6, loss = 0.69381847\n",
      "Iteration 7, loss = 0.69381149\n",
      "Iteration 8, loss = 0.69380472\n",
      "Iteration 9, loss = 0.69379814\n",
      "Iteration 10, loss = 0.69379179\n",
      "Iteration 11, loss = 0.69378564\n",
      "Iteration 12, loss = 0.69377971\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "263\n",
      "Iteration 1, loss = 0.69492592\n",
      "Iteration 2, loss = 0.69490920\n",
      "Iteration 3, loss = 0.69489859\n",
      "Iteration 4, loss = 0.69488820\n",
      "Iteration 5, loss = 0.69487799\n",
      "Iteration 6, loss = 0.69486801\n",
      "Iteration 7, loss = 0.69485828\n",
      "Iteration 8, loss = 0.69484882\n",
      "Iteration 9, loss = 0.69483967\n",
      "Iteration 10, loss = 0.69483081\n",
      "Iteration 11, loss = 0.69482225\n",
      "Iteration 12, loss = 0.69481400\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "264\n",
      "Iteration 1, loss = 0.69583506\n",
      "Iteration 2, loss = 0.69582430\n",
      "Iteration 3, loss = 0.69581747\n",
      "Iteration 4, loss = 0.69581078\n",
      "Iteration 5, loss = 0.69580421\n",
      "Iteration 6, loss = 0.69579778\n",
      "Iteration 7, loss = 0.69579151\n",
      "Iteration 8, loss = 0.69578542\n",
      "Iteration 9, loss = 0.69577951\n",
      "Iteration 10, loss = 0.69577380\n",
      "Iteration 11, loss = 0.69576828\n",
      "Iteration 12, loss = 0.69576295\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "265\n",
      "Iteration 1, loss = 0.69613910\n",
      "Iteration 2, loss = 0.69612095\n",
      "Iteration 3, loss = 0.69610943\n",
      "Iteration 4, loss = 0.69609816\n",
      "Iteration 5, loss = 0.69608708\n",
      "Iteration 6, loss = 0.69607624\n",
      "Iteration 7, loss = 0.69606567\n",
      "Iteration 8, loss = 0.69605539\n",
      "Iteration 9, loss = 0.69604543\n",
      "Iteration 10, loss = 0.69603580\n",
      "Iteration 11, loss = 0.69602649\n",
      "Iteration 12, loss = 0.69601750\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "266\n",
      "Iteration 1, loss = 0.69735874\n",
      "Iteration 2, loss = 0.69734412\n",
      "Iteration 3, loss = 0.69733484\n",
      "Iteration 4, loss = 0.69732576\n",
      "Iteration 5, loss = 0.69731683\n",
      "Iteration 6, loss = 0.69730809\n",
      "Iteration 7, loss = 0.69729958\n",
      "Iteration 8, loss = 0.69729131\n",
      "Iteration 9, loss = 0.69728329\n",
      "Iteration 10, loss = 0.69727554\n",
      "Iteration 11, loss = 0.69726804\n",
      "Iteration 12, loss = 0.69726081\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "267\n",
      "Iteration 1, loss = 0.69690584\n",
      "Iteration 2, loss = 0.69688995\n",
      "Iteration 3, loss = 0.69687987\n",
      "Iteration 4, loss = 0.69687000\n",
      "Iteration 5, loss = 0.69686030\n",
      "Iteration 6, loss = 0.69685081\n",
      "Iteration 7, loss = 0.69684156\n",
      "Iteration 8, loss = 0.69683257\n",
      "Iteration 9, loss = 0.69682388\n",
      "Iteration 10, loss = 0.69681549\n",
      "Iteration 11, loss = 0.69680738\n",
      "Iteration 12, loss = 0.69679956\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "268\n",
      "Iteration 1, loss = 0.69975385\n",
      "Iteration 2, loss = 0.69973877\n",
      "Iteration 3, loss = 0.69972920\n",
      "Iteration 4, loss = 0.69971982\n",
      "Iteration 5, loss = 0.69971061\n",
      "Iteration 6, loss = 0.69970160\n",
      "Iteration 7, loss = 0.69969281\n",
      "Iteration 8, loss = 0.69968428\n",
      "Iteration 9, loss = 0.69967601\n",
      "Iteration 10, loss = 0.69966800\n",
      "Iteration 11, loss = 0.69966027\n",
      "Iteration 12, loss = 0.69965281\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "269\n",
      "Iteration 1, loss = 0.69407071\n",
      "Iteration 2, loss = 0.69405837\n",
      "Iteration 3, loss = 0.69405055\n",
      "Iteration 4, loss = 0.69404288\n",
      "Iteration 5, loss = 0.69403535\n",
      "Iteration 6, loss = 0.69402798\n",
      "Iteration 7, loss = 0.69402080\n",
      "Iteration 8, loss = 0.69401382\n",
      "Iteration 9, loss = 0.69400706\n",
      "Iteration 10, loss = 0.69400052\n",
      "Iteration 11, loss = 0.69399420\n",
      "Iteration 12, loss = 0.69398807\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "270\n",
      "Iteration 1, loss = 0.69837481\n",
      "Iteration 2, loss = 0.69836331\n",
      "Iteration 3, loss = 0.69835601\n",
      "Iteration 4, loss = 0.69834886\n",
      "Iteration 5, loss = 0.69834183\n",
      "Iteration 6, loss = 0.69833496\n",
      "Iteration 7, loss = 0.69832826\n",
      "Iteration 8, loss = 0.69832174\n",
      "Iteration 9, loss = 0.69831543\n",
      "Iteration 10, loss = 0.69830933\n",
      "Iteration 11, loss = 0.69830343\n",
      "Iteration 12, loss = 0.69829773\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "271\n",
      "Iteration 1, loss = 0.70072035\n",
      "Iteration 2, loss = 0.70070720\n",
      "Iteration 3, loss = 0.70069886\n",
      "Iteration 4, loss = 0.70069069\n",
      "Iteration 5, loss = 0.70068266\n",
      "Iteration 6, loss = 0.70067480\n",
      "Iteration 7, loss = 0.70066714\n",
      "Iteration 8, loss = 0.70065970\n",
      "Iteration 9, loss = 0.70065249\n",
      "Iteration 10, loss = 0.70064551\n",
      "Iteration 11, loss = 0.70063877\n",
      "Iteration 12, loss = 0.70063225\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "272\n",
      "Iteration 1, loss = 0.69982810\n",
      "Iteration 2, loss = 0.69980561\n",
      "Iteration 3, loss = 0.69979135\n",
      "Iteration 4, loss = 0.69977740\n",
      "Iteration 5, loss = 0.69976368\n",
      "Iteration 6, loss = 0.69975026\n",
      "Iteration 7, loss = 0.69973718\n",
      "Iteration 8, loss = 0.69972448\n",
      "Iteration 9, loss = 0.69971217\n",
      "Iteration 10, loss = 0.69970029\n",
      "Iteration 11, loss = 0.69968883\n",
      "Iteration 12, loss = 0.69967776\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "273\n",
      "Iteration 1, loss = 0.70287626\n",
      "Iteration 2, loss = 0.70285757\n",
      "Iteration 3, loss = 0.70284571\n",
      "Iteration 4, loss = 0.70283410\n",
      "Iteration 5, loss = 0.70282270\n",
      "Iteration 6, loss = 0.70281154\n",
      "Iteration 7, loss = 0.70280067\n",
      "Iteration 8, loss = 0.70279011\n",
      "Iteration 9, loss = 0.70277988\n",
      "Iteration 10, loss = 0.70276998\n",
      "Iteration 11, loss = 0.70276043\n",
      "Iteration 12, loss = 0.70275120\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "274\n",
      "Iteration 1, loss = 0.68807153\n",
      "Iteration 2, loss = 0.68805949\n",
      "Iteration 3, loss = 0.68805184\n",
      "Iteration 4, loss = 0.68804435\n",
      "Iteration 5, loss = 0.68803700\n",
      "Iteration 6, loss = 0.68802979\n",
      "Iteration 7, loss = 0.68802277\n",
      "Iteration 8, loss = 0.68801595\n",
      "Iteration 9, loss = 0.68800934\n",
      "Iteration 10, loss = 0.68800294\n",
      "Iteration 11, loss = 0.68799676\n",
      "Iteration 12, loss = 0.68799080\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "275\n",
      "Iteration 1, loss = 0.68729311\n",
      "Iteration 2, loss = 0.68728183\n",
      "Iteration 3, loss = 0.68727466\n",
      "Iteration 4, loss = 0.68726765\n",
      "Iteration 5, loss = 0.68726075\n",
      "Iteration 6, loss = 0.68725401\n",
      "Iteration 7, loss = 0.68724743\n",
      "Iteration 8, loss = 0.68724104\n",
      "Iteration 9, loss = 0.68723484\n",
      "Iteration 10, loss = 0.68722885\n",
      "Iteration 11, loss = 0.68722306\n",
      "Iteration 12, loss = 0.68721747\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "276\n",
      "Iteration 1, loss = 0.69123136\n",
      "Iteration 2, loss = 0.69122075\n",
      "Iteration 3, loss = 0.69121401\n",
      "Iteration 4, loss = 0.69120741\n",
      "Iteration 5, loss = 0.69120093\n",
      "Iteration 6, loss = 0.69119458\n",
      "Iteration 7, loss = 0.69118839\n",
      "Iteration 8, loss = 0.69118238\n",
      "Iteration 9, loss = 0.69117655\n",
      "Iteration 10, loss = 0.69117092\n",
      "Iteration 11, loss = 0.69116547\n",
      "Iteration 12, loss = 0.69116021\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "277\n",
      "Iteration 1, loss = 0.69097121\n",
      "Iteration 2, loss = 0.69095175\n",
      "Iteration 3, loss = 0.69093940\n",
      "Iteration 4, loss = 0.69092732\n",
      "Iteration 5, loss = 0.69091545\n",
      "Iteration 6, loss = 0.69090382\n",
      "Iteration 7, loss = 0.69089249\n",
      "Iteration 8, loss = 0.69088148\n",
      "Iteration 9, loss = 0.69087082\n",
      "Iteration 10, loss = 0.69086050\n",
      "Iteration 11, loss = 0.69085054\n",
      "Iteration 12, loss = 0.69084092\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "278\n",
      "Iteration 1, loss = 0.69436631\n",
      "Iteration 2, loss = 0.69435508\n",
      "Iteration 3, loss = 0.69434795\n",
      "Iteration 4, loss = 0.69434099\n",
      "Iteration 5, loss = 0.69433416\n",
      "Iteration 6, loss = 0.69432747\n",
      "Iteration 7, loss = 0.69432095\n",
      "Iteration 8, loss = 0.69431462\n",
      "Iteration 9, loss = 0.69430848\n",
      "Iteration 10, loss = 0.69430255\n",
      "Iteration 11, loss = 0.69429681\n",
      "Iteration 12, loss = 0.69429127\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "279\n",
      "Iteration 1, loss = 0.69830310\n",
      "Iteration 2, loss = 0.69828784\n",
      "Iteration 3, loss = 0.69827816\n",
      "Iteration 4, loss = 0.69826868\n",
      "Iteration 5, loss = 0.69825937\n",
      "Iteration 6, loss = 0.69825025\n",
      "Iteration 7, loss = 0.69824136\n",
      "Iteration 8, loss = 0.69823273\n",
      "Iteration 9, loss = 0.69822437\n",
      "Iteration 10, loss = 0.69821628\n",
      "Iteration 11, loss = 0.69820846\n",
      "Iteration 12, loss = 0.69820091\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "280\n",
      "Iteration 1, loss = 0.69314941\n",
      "Iteration 2, loss = 0.69313374\n",
      "Iteration 3, loss = 0.69312380\n",
      "Iteration 4, loss = 0.69311407\n",
      "Iteration 5, loss = 0.69310451\n",
      "Iteration 6, loss = 0.69309515\n",
      "Iteration 7, loss = 0.69308603\n",
      "Iteration 8, loss = 0.69307719\n",
      "Iteration 9, loss = 0.69306861\n",
      "Iteration 10, loss = 0.69306032\n",
      "Iteration 11, loss = 0.69305231\n",
      "Iteration 12, loss = 0.69304457\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "281\n",
      "Iteration 1, loss = 0.69496991\n",
      "Iteration 2, loss = 0.69495526\n",
      "Iteration 3, loss = 0.69494597\n",
      "Iteration 4, loss = 0.69493686\n",
      "Iteration 5, loss = 0.69492792\n",
      "Iteration 6, loss = 0.69491917\n",
      "Iteration 7, loss = 0.69491064\n",
      "Iteration 8, loss = 0.69490235\n",
      "Iteration 9, loss = 0.69489433\n",
      "Iteration 10, loss = 0.69488656\n",
      "Iteration 11, loss = 0.69487905\n",
      "Iteration 12, loss = 0.69487181\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "282\n",
      "Iteration 1, loss = 0.68794185\n",
      "Iteration 2, loss = 0.68793062\n",
      "Iteration 3, loss = 0.68792351\n",
      "Iteration 4, loss = 0.68791658\n",
      "Iteration 5, loss = 0.68790976\n",
      "Iteration 6, loss = 0.68790308\n",
      "Iteration 7, loss = 0.68789658\n",
      "Iteration 8, loss = 0.68789026\n",
      "Iteration 9, loss = 0.68788414\n",
      "Iteration 10, loss = 0.68787821\n",
      "Iteration 11, loss = 0.68787249\n",
      "Iteration 12, loss = 0.68786696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "283\n",
      "Iteration 1, loss = 0.70078193\n",
      "Iteration 2, loss = 0.70075931\n",
      "Iteration 3, loss = 0.70074497\n",
      "Iteration 4, loss = 0.70073093\n",
      "Iteration 5, loss = 0.70071713\n",
      "Iteration 6, loss = 0.70070364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.70069049\n",
      "Iteration 8, loss = 0.70067772\n",
      "Iteration 9, loss = 0.70066535\n",
      "Iteration 10, loss = 0.70065339\n",
      "Iteration 11, loss = 0.70064183\n",
      "Iteration 12, loss = 0.70063068\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "284\n",
      "Iteration 1, loss = 0.69774080\n",
      "Iteration 2, loss = 0.69772462\n",
      "Iteration 3, loss = 0.69771436\n",
      "Iteration 4, loss = 0.69770432\n",
      "Iteration 5, loss = 0.69769447\n",
      "Iteration 6, loss = 0.69768482\n",
      "Iteration 7, loss = 0.69767543\n",
      "Iteration 8, loss = 0.69766630\n",
      "Iteration 9, loss = 0.69765746\n",
      "Iteration 10, loss = 0.69764891\n",
      "Iteration 11, loss = 0.69764064\n",
      "Iteration 12, loss = 0.69763267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "285\n",
      "Iteration 1, loss = 0.69338742\n",
      "Iteration 2, loss = 0.69337436\n",
      "Iteration 3, loss = 0.69336608\n",
      "Iteration 4, loss = 0.69335796\n",
      "Iteration 5, loss = 0.69334999\n",
      "Iteration 6, loss = 0.69334219\n",
      "Iteration 7, loss = 0.69333460\n",
      "Iteration 8, loss = 0.69332722\n",
      "Iteration 9, loss = 0.69332007\n",
      "Iteration 10, loss = 0.69331316\n",
      "Iteration 11, loss = 0.69330648\n",
      "Iteration 12, loss = 0.69330004\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "286\n",
      "Iteration 1, loss = 0.69130464\n",
      "Iteration 2, loss = 0.69129398\n",
      "Iteration 3, loss = 0.69128721\n",
      "Iteration 4, loss = 0.69128058\n",
      "Iteration 5, loss = 0.69127406\n",
      "Iteration 6, loss = 0.69126769\n",
      "Iteration 7, loss = 0.69126147\n",
      "Iteration 8, loss = 0.69125543\n",
      "Iteration 9, loss = 0.69124957\n",
      "Iteration 10, loss = 0.69124391\n",
      "Iteration 11, loss = 0.69123843\n",
      "Iteration 12, loss = 0.69123315\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "287\n",
      "Iteration 1, loss = 0.69570818\n",
      "Iteration 2, loss = 0.69569621\n",
      "Iteration 3, loss = 0.69568861\n",
      "Iteration 4, loss = 0.69568117\n",
      "Iteration 5, loss = 0.69567385\n",
      "Iteration 6, loss = 0.69566669\n",
      "Iteration 7, loss = 0.69565971\n",
      "Iteration 8, loss = 0.69565293\n",
      "Iteration 9, loss = 0.69564636\n",
      "Iteration 10, loss = 0.69564000\n",
      "Iteration 11, loss = 0.69563386\n",
      "Iteration 12, loss = 0.69562797\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "288\n",
      "Iteration 1, loss = 0.69303975\n",
      "Iteration 2, loss = 0.69302550\n",
      "Iteration 3, loss = 0.69301646\n",
      "Iteration 4, loss = 0.69300761\n",
      "Iteration 5, loss = 0.69299893\n",
      "Iteration 6, loss = 0.69299045\n",
      "Iteration 7, loss = 0.69298220\n",
      "Iteration 8, loss = 0.69297418\n",
      "Iteration 9, loss = 0.69296641\n",
      "Iteration 10, loss = 0.69295889\n",
      "Iteration 11, loss = 0.69295161\n",
      "Iteration 12, loss = 0.69294458\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "289\n",
      "Iteration 1, loss = 0.69817483\n",
      "Iteration 2, loss = 0.69814789\n",
      "Iteration 3, loss = 0.69813080\n",
      "Iteration 4, loss = 0.69811408\n",
      "Iteration 5, loss = 0.69809765\n",
      "Iteration 6, loss = 0.69808158\n",
      "Iteration 7, loss = 0.69806592\n",
      "Iteration 8, loss = 0.69805072\n",
      "Iteration 9, loss = 0.69803599\n",
      "Iteration 10, loss = 0.69802175\n",
      "Iteration 11, loss = 0.69800799\n",
      "Iteration 12, loss = 0.69799472\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "290\n",
      "Iteration 1, loss = 0.69251006\n",
      "Iteration 2, loss = 0.69249425\n",
      "Iteration 3, loss = 0.69248422\n",
      "Iteration 4, loss = 0.69247440\n",
      "Iteration 5, loss = 0.69246475\n",
      "Iteration 6, loss = 0.69245531\n",
      "Iteration 7, loss = 0.69244611\n",
      "Iteration 8, loss = 0.69243718\n",
      "Iteration 9, loss = 0.69242852\n",
      "Iteration 10, loss = 0.69242015\n",
      "Iteration 11, loss = 0.69241206\n",
      "Iteration 12, loss = 0.69240426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "291\n",
      "Iteration 1, loss = 0.69722747\n",
      "Iteration 2, loss = 0.69720930\n",
      "Iteration 3, loss = 0.69719778\n",
      "Iteration 4, loss = 0.69718650\n",
      "Iteration 5, loss = 0.69717541\n",
      "Iteration 6, loss = 0.69716457\n",
      "Iteration 7, loss = 0.69715400\n",
      "Iteration 8, loss = 0.69714374\n",
      "Iteration 9, loss = 0.69713382\n",
      "Iteration 10, loss = 0.69712422\n",
      "Iteration 11, loss = 0.69711493\n",
      "Iteration 12, loss = 0.69710597\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "292\n",
      "Iteration 1, loss = 0.69400476\n",
      "Iteration 2, loss = 0.69398117\n",
      "Iteration 3, loss = 0.69396621\n",
      "Iteration 4, loss = 0.69395157\n",
      "Iteration 5, loss = 0.69393718\n",
      "Iteration 6, loss = 0.69392310\n",
      "Iteration 7, loss = 0.69390939\n",
      "Iteration 8, loss = 0.69389609\n",
      "Iteration 9, loss = 0.69388321\n",
      "Iteration 10, loss = 0.69387075\n",
      "Iteration 11, loss = 0.69385872\n",
      "Iteration 12, loss = 0.69384710\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "293\n",
      "Iteration 1, loss = 0.69565164\n",
      "Iteration 2, loss = 0.69563891\n",
      "Iteration 3, loss = 0.69563082\n",
      "Iteration 4, loss = 0.69562291\n",
      "Iteration 5, loss = 0.69561513\n",
      "Iteration 6, loss = 0.69560752\n",
      "Iteration 7, loss = 0.69560010\n",
      "Iteration 8, loss = 0.69559289\n",
      "Iteration 9, loss = 0.69558590\n",
      "Iteration 10, loss = 0.69557914\n",
      "Iteration 11, loss = 0.69557260\n",
      "Iteration 12, loss = 0.69556629\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "294\n",
      "Iteration 1, loss = 0.69152346\n",
      "Iteration 2, loss = 0.69151160\n",
      "Iteration 3, loss = 0.69150407\n",
      "Iteration 4, loss = 0.69149670\n",
      "Iteration 5, loss = 0.69148946\n",
      "Iteration 6, loss = 0.69148237\n",
      "Iteration 7, loss = 0.69147546\n",
      "Iteration 8, loss = 0.69146875\n",
      "Iteration 9, loss = 0.69146224\n",
      "Iteration 10, loss = 0.69145595\n",
      "Iteration 11, loss = 0.69144987\n",
      "Iteration 12, loss = 0.69144399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "295\n",
      "Iteration 1, loss = 0.69390119\n",
      "Iteration 2, loss = 0.69388181\n",
      "Iteration 3, loss = 0.69386951\n",
      "Iteration 4, loss = 0.69385748\n",
      "Iteration 5, loss = 0.69384565\n",
      "Iteration 6, loss = 0.69383409\n",
      "Iteration 7, loss = 0.69382282\n",
      "Iteration 8, loss = 0.69381187\n",
      "Iteration 9, loss = 0.69380127\n",
      "Iteration 10, loss = 0.69379102\n",
      "Iteration 11, loss = 0.69378112\n",
      "Iteration 12, loss = 0.69377156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "296\n",
      "Iteration 1, loss = 0.69658967\n",
      "Iteration 2, loss = 0.69657783\n",
      "Iteration 3, loss = 0.69657031\n",
      "Iteration 4, loss = 0.69656295\n",
      "Iteration 5, loss = 0.69655571\n",
      "Iteration 6, loss = 0.69654863\n",
      "Iteration 7, loss = 0.69654173\n",
      "Iteration 8, loss = 0.69653503\n",
      "Iteration 9, loss = 0.69652853\n",
      "Iteration 10, loss = 0.69652225\n",
      "Iteration 11, loss = 0.69651617\n",
      "Iteration 12, loss = 0.69651031\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "297\n",
      "Iteration 1, loss = 0.69801448\n",
      "Iteration 2, loss = 0.69799851\n",
      "Iteration 3, loss = 0.69798837\n",
      "Iteration 4, loss = 0.69797845\n",
      "Iteration 5, loss = 0.69796870\n",
      "Iteration 6, loss = 0.69795915\n",
      "Iteration 7, loss = 0.69794985\n",
      "Iteration 8, loss = 0.69794082\n",
      "Iteration 9, loss = 0.69793206\n",
      "Iteration 10, loss = 0.69792363\n",
      "Iteration 11, loss = 0.69791548\n",
      "Iteration 12, loss = 0.69790760\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "298\n",
      "Iteration 1, loss = 0.69622792\n",
      "Iteration 2, loss = 0.69620295\n",
      "Iteration 3, loss = 0.69618711\n",
      "Iteration 4, loss = 0.69617160\n",
      "Iteration 5, loss = 0.69615636\n",
      "Iteration 6, loss = 0.69614145\n",
      "Iteration 7, loss = 0.69612693\n",
      "Iteration 8, loss = 0.69611283\n",
      "Iteration 9, loss = 0.69609917\n",
      "Iteration 10, loss = 0.69608596\n",
      "Iteration 11, loss = 0.69607320\n",
      "Iteration 12, loss = 0.69606089\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "299\n",
      "Iteration 1, loss = 0.70441083\n",
      "Iteration 2, loss = 0.70439102\n",
      "Iteration 3, loss = 0.70437845\n",
      "Iteration 4, loss = 0.70436615\n",
      "Iteration 5, loss = 0.70435406\n",
      "Iteration 6, loss = 0.70434224\n",
      "Iteration 7, loss = 0.70433071\n",
      "Iteration 8, loss = 0.70431952\n",
      "Iteration 9, loss = 0.70430868\n",
      "Iteration 10, loss = 0.70429819\n",
      "Iteration 11, loss = 0.70428805\n",
      "Iteration 12, loss = 0.70427827\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "300\n",
      "Iteration 1, loss = 0.69296872\n",
      "Iteration 2, loss = 0.69294846\n",
      "Iteration 3, loss = 0.69293560\n",
      "Iteration 4, loss = 0.69292302\n",
      "Iteration 5, loss = 0.69291066\n",
      "Iteration 6, loss = 0.69289857\n",
      "Iteration 7, loss = 0.69288678\n",
      "Iteration 8, loss = 0.69287534\n",
      "Iteration 9, loss = 0.69286425\n",
      "Iteration 10, loss = 0.69285352\n",
      "Iteration 11, loss = 0.69284316\n",
      "Iteration 12, loss = 0.69283317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "301\n",
      "Iteration 1, loss = 0.68668949\n",
      "Iteration 2, loss = 0.68666772\n",
      "Iteration 3, loss = 0.68665391\n",
      "Iteration 4, loss = 0.68664039\n",
      "Iteration 5, loss = 0.68662710\n",
      "Iteration 6, loss = 0.68661411\n",
      "Iteration 7, loss = 0.68660142\n",
      "Iteration 8, loss = 0.68658909\n",
      "Iteration 9, loss = 0.68657715\n",
      "Iteration 10, loss = 0.68656560\n",
      "Iteration 11, loss = 0.68655444\n",
      "Iteration 12, loss = 0.68654366\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "302\n",
      "Iteration 1, loss = 0.69446445\n",
      "Iteration 2, loss = 0.69445470\n",
      "Iteration 3, loss = 0.69444851\n",
      "Iteration 4, loss = 0.69444245\n",
      "Iteration 5, loss = 0.69443649\n",
      "Iteration 6, loss = 0.69443065\n",
      "Iteration 7, loss = 0.69442497\n",
      "Iteration 8, loss = 0.69441945\n",
      "Iteration 9, loss = 0.69441409\n",
      "Iteration 10, loss = 0.69440891\n",
      "Iteration 11, loss = 0.69440391\n",
      "Iteration 12, loss = 0.69439907\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "303\n",
      "Iteration 1, loss = 0.69865657\n",
      "Iteration 2, loss = 0.69863024\n",
      "Iteration 3, loss = 0.69861354\n",
      "Iteration 4, loss = 0.69859720\n",
      "Iteration 5, loss = 0.69858114\n",
      "Iteration 6, loss = 0.69856544\n",
      "Iteration 7, loss = 0.69855014\n",
      "Iteration 8, loss = 0.69853529\n",
      "Iteration 9, loss = 0.69852090\n",
      "Iteration 10, loss = 0.69850698\n",
      "Iteration 11, loss = 0.69849354\n",
      "Iteration 12, loss = 0.69848057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "304\n",
      "Iteration 1, loss = 0.69575753\n",
      "Iteration 2, loss = 0.69574507\n",
      "Iteration 3, loss = 0.69573716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.69572942\n",
      "Iteration 5, loss = 0.69572181\n",
      "Iteration 6, loss = 0.69571437\n",
      "Iteration 7, loss = 0.69570712\n",
      "Iteration 8, loss = 0.69570008\n",
      "Iteration 9, loss = 0.69569326\n",
      "Iteration 10, loss = 0.69568666\n",
      "Iteration 11, loss = 0.69568028\n",
      "Iteration 12, loss = 0.69567412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "305\n",
      "Iteration 1, loss = 0.68719591\n",
      "Iteration 2, loss = 0.68718497\n",
      "Iteration 3, loss = 0.68717803\n",
      "Iteration 4, loss = 0.68717123\n",
      "Iteration 5, loss = 0.68716454\n",
      "Iteration 6, loss = 0.68715800\n",
      "Iteration 7, loss = 0.68715162\n",
      "Iteration 8, loss = 0.68714542\n",
      "Iteration 9, loss = 0.68713942\n",
      "Iteration 10, loss = 0.68713360\n",
      "Iteration 11, loss = 0.68712797\n",
      "Iteration 12, loss = 0.68712253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "306\n",
      "Iteration 1, loss = 0.69433751\n",
      "Iteration 2, loss = 0.69432604\n",
      "Iteration 3, loss = 0.69431875\n",
      "Iteration 4, loss = 0.69431162\n",
      "Iteration 5, loss = 0.69430461\n",
      "Iteration 6, loss = 0.69429775\n",
      "Iteration 7, loss = 0.69429107\n",
      "Iteration 8, loss = 0.69428457\n",
      "Iteration 9, loss = 0.69427827\n",
      "Iteration 10, loss = 0.69427218\n",
      "Iteration 11, loss = 0.69426629\n",
      "Iteration 12, loss = 0.69426061\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "307\n",
      "Iteration 1, loss = 0.69762447\n",
      "Iteration 2, loss = 0.69761288\n",
      "Iteration 3, loss = 0.69760552\n",
      "Iteration 4, loss = 0.69759832\n",
      "Iteration 5, loss = 0.69759124\n",
      "Iteration 6, loss = 0.69758431\n",
      "Iteration 7, loss = 0.69757755\n",
      "Iteration 8, loss = 0.69757099\n",
      "Iteration 9, loss = 0.69756461\n",
      "Iteration 10, loss = 0.69755844\n",
      "Iteration 11, loss = 0.69755248\n",
      "Iteration 12, loss = 0.69754672\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "308\n",
      "Iteration 1, loss = 0.69104829\n",
      "Iteration 2, loss = 0.69103694\n",
      "Iteration 3, loss = 0.69102973\n",
      "Iteration 4, loss = 0.69102267\n",
      "Iteration 5, loss = 0.69101573\n",
      "Iteration 6, loss = 0.69100894\n",
      "Iteration 7, loss = 0.69100232\n",
      "Iteration 8, loss = 0.69099589\n",
      "Iteration 9, loss = 0.69098966\n",
      "Iteration 10, loss = 0.69098362\n",
      "Iteration 11, loss = 0.69097780\n",
      "Iteration 12, loss = 0.69097217\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "309\n",
      "Iteration 1, loss = 0.69055843\n",
      "Iteration 2, loss = 0.69054604\n",
      "Iteration 3, loss = 0.69053818\n",
      "Iteration 4, loss = 0.69053048\n",
      "Iteration 5, loss = 0.69052291\n",
      "Iteration 6, loss = 0.69051551\n",
      "Iteration 7, loss = 0.69050829\n",
      "Iteration 8, loss = 0.69050128\n",
      "Iteration 9, loss = 0.69049448\n",
      "Iteration 10, loss = 0.69048790\n",
      "Iteration 11, loss = 0.69048155\n",
      "Iteration 12, loss = 0.69047541\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "310\n",
      "Iteration 1, loss = 0.69167858\n",
      "Iteration 2, loss = 0.69166830\n",
      "Iteration 3, loss = 0.69166177\n",
      "Iteration 4, loss = 0.69165538\n",
      "Iteration 5, loss = 0.69164909\n",
      "Iteration 6, loss = 0.69164294\n",
      "Iteration 7, loss = 0.69163695\n",
      "Iteration 8, loss = 0.69163113\n",
      "Iteration 9, loss = 0.69162548\n",
      "Iteration 10, loss = 0.69162002\n",
      "Iteration 11, loss = 0.69161474\n",
      "Iteration 12, loss = 0.69160965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "311\n",
      "Iteration 1, loss = 0.70119080\n",
      "Iteration 2, loss = 0.70117316\n",
      "Iteration 3, loss = 0.70116196\n",
      "Iteration 4, loss = 0.70115100\n",
      "Iteration 5, loss = 0.70114023\n",
      "Iteration 6, loss = 0.70112969\n",
      "Iteration 7, loss = 0.70111942\n",
      "Iteration 8, loss = 0.70110945\n",
      "Iteration 9, loss = 0.70109979\n",
      "Iteration 10, loss = 0.70109044\n",
      "Iteration 11, loss = 0.70108141\n",
      "Iteration 12, loss = 0.70107270\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "312\n",
      "Iteration 1, loss = 0.69330556\n",
      "Iteration 2, loss = 0.69329117\n",
      "Iteration 3, loss = 0.69328204\n",
      "Iteration 4, loss = 0.69327310\n",
      "Iteration 5, loss = 0.69326432\n",
      "Iteration 6, loss = 0.69325572\n",
      "Iteration 7, loss = 0.69324734\n",
      "Iteration 8, loss = 0.69323920\n",
      "Iteration 9, loss = 0.69323131\n",
      "Iteration 10, loss = 0.69322368\n",
      "Iteration 11, loss = 0.69321630\n",
      "Iteration 12, loss = 0.69320918\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "313\n",
      "Iteration 1, loss = 0.69765321\n",
      "Iteration 2, loss = 0.69763483\n",
      "Iteration 3, loss = 0.69762318\n",
      "Iteration 4, loss = 0.69761178\n",
      "Iteration 5, loss = 0.69760059\n",
      "Iteration 6, loss = 0.69758963\n",
      "Iteration 7, loss = 0.69757895\n",
      "Iteration 8, loss = 0.69756858\n",
      "Iteration 9, loss = 0.69755854\n",
      "Iteration 10, loss = 0.69754883\n",
      "Iteration 11, loss = 0.69753946\n",
      "Iteration 12, loss = 0.69753040\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "314\n",
      "Iteration 1, loss = 0.69647285\n",
      "Iteration 2, loss = 0.69645721\n",
      "Iteration 3, loss = 0.69644728\n",
      "Iteration 4, loss = 0.69643756\n",
      "Iteration 5, loss = 0.69642801\n",
      "Iteration 6, loss = 0.69641866\n",
      "Iteration 7, loss = 0.69640955\n",
      "Iteration 8, loss = 0.69640069\n",
      "Iteration 9, loss = 0.69639212\n",
      "Iteration 10, loss = 0.69638382\n",
      "Iteration 11, loss = 0.69637581\n",
      "Iteration 12, loss = 0.69636807\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "315\n",
      "Iteration 1, loss = 0.69479840\n",
      "Iteration 2, loss = 0.69478702\n",
      "Iteration 3, loss = 0.69477979\n",
      "Iteration 4, loss = 0.69477272\n",
      "Iteration 5, loss = 0.69476577\n",
      "Iteration 6, loss = 0.69475896\n",
      "Iteration 7, loss = 0.69475233\n",
      "Iteration 8, loss = 0.69474588\n",
      "Iteration 9, loss = 0.69473964\n",
      "Iteration 10, loss = 0.69473359\n",
      "Iteration 11, loss = 0.69472775\n",
      "Iteration 12, loss = 0.69472211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "316\n",
      "Iteration 1, loss = 0.69673366\n",
      "Iteration 2, loss = 0.69671404\n",
      "Iteration 3, loss = 0.69670160\n",
      "Iteration 4, loss = 0.69668942\n",
      "Iteration 5, loss = 0.69667745\n",
      "Iteration 6, loss = 0.69666574\n",
      "Iteration 7, loss = 0.69665434\n",
      "Iteration 8, loss = 0.69664325\n",
      "Iteration 9, loss = 0.69663249\n",
      "Iteration 10, loss = 0.69662208\n",
      "Iteration 11, loss = 0.69661202\n",
      "Iteration 12, loss = 0.69660232\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "317\n",
      "Iteration 1, loss = 0.69213001\n",
      "Iteration 2, loss = 0.69211741\n",
      "Iteration 3, loss = 0.69210941\n",
      "Iteration 4, loss = 0.69210158\n",
      "Iteration 5, loss = 0.69209388\n",
      "Iteration 6, loss = 0.69208634\n",
      "Iteration 7, loss = 0.69207900\n",
      "Iteration 8, loss = 0.69207187\n",
      "Iteration 9, loss = 0.69206495\n",
      "Iteration 10, loss = 0.69205826\n",
      "Iteration 11, loss = 0.69205180\n",
      "Iteration 12, loss = 0.69204555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "318\n",
      "Iteration 1, loss = 0.69561215\n",
      "Iteration 2, loss = 0.69560119\n",
      "Iteration 3, loss = 0.69559423\n",
      "Iteration 4, loss = 0.69558741\n",
      "Iteration 5, loss = 0.69558071\n",
      "Iteration 6, loss = 0.69557416\n",
      "Iteration 7, loss = 0.69556777\n",
      "Iteration 8, loss = 0.69556156\n",
      "Iteration 9, loss = 0.69555554\n",
      "Iteration 10, loss = 0.69554972\n",
      "Iteration 11, loss = 0.69554410\n",
      "Iteration 12, loss = 0.69553867\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "319\n",
      "Iteration 1, loss = 0.69881129\n",
      "Iteration 2, loss = 0.69879764\n",
      "Iteration 3, loss = 0.69878898\n",
      "Iteration 4, loss = 0.69878050\n",
      "Iteration 5, loss = 0.69877216\n",
      "Iteration 6, loss = 0.69876399\n",
      "Iteration 7, loss = 0.69875606\n",
      "Iteration 8, loss = 0.69874837\n",
      "Iteration 9, loss = 0.69874093\n",
      "Iteration 10, loss = 0.69873372\n",
      "Iteration 11, loss = 0.69872676\n",
      "Iteration 12, loss = 0.69872004\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "320\n",
      "Iteration 1, loss = 0.69806083\n",
      "Iteration 2, loss = 0.69803882\n",
      "Iteration 3, loss = 0.69802484\n",
      "Iteration 4, loss = 0.69801115\n",
      "Iteration 5, loss = 0.69799770\n",
      "Iteration 6, loss = 0.69798454\n",
      "Iteration 7, loss = 0.69797172\n",
      "Iteration 8, loss = 0.69795926\n",
      "Iteration 9, loss = 0.69794720\n",
      "Iteration 10, loss = 0.69793552\n",
      "Iteration 11, loss = 0.69792425\n",
      "Iteration 12, loss = 0.69791336\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "321\n",
      "Iteration 1, loss = 0.69934157\n",
      "Iteration 2, loss = 0.69932351\n",
      "Iteration 3, loss = 0.69931206\n",
      "Iteration 4, loss = 0.69930085\n",
      "Iteration 5, loss = 0.69928983\n",
      "Iteration 6, loss = 0.69927906\n",
      "Iteration 7, loss = 0.69926859\n",
      "Iteration 8, loss = 0.69925842\n",
      "Iteration 9, loss = 0.69924857\n",
      "Iteration 10, loss = 0.69923904\n",
      "Iteration 11, loss = 0.69922983\n",
      "Iteration 12, loss = 0.69922095\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "322\n",
      "Iteration 1, loss = 0.70155859\n",
      "Iteration 2, loss = 0.70153776\n",
      "Iteration 3, loss = 0.70152455\n",
      "Iteration 4, loss = 0.70151162\n",
      "Iteration 5, loss = 0.70149894\n",
      "Iteration 6, loss = 0.70148654\n",
      "Iteration 7, loss = 0.70147445\n",
      "Iteration 8, loss = 0.70146271\n",
      "Iteration 9, loss = 0.70145134\n",
      "Iteration 10, loss = 0.70144035\n",
      "Iteration 11, loss = 0.70142973\n",
      "Iteration 12, loss = 0.70141948\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "323\n",
      "Iteration 1, loss = 0.69560639\n",
      "Iteration 2, loss = 0.69559087\n",
      "Iteration 3, loss = 0.69558102\n",
      "Iteration 4, loss = 0.69557138\n",
      "Iteration 5, loss = 0.69556191\n",
      "Iteration 6, loss = 0.69555266\n",
      "Iteration 7, loss = 0.69554364\n",
      "Iteration 8, loss = 0.69553488\n",
      "Iteration 9, loss = 0.69552639\n",
      "Iteration 10, loss = 0.69551818\n",
      "Iteration 11, loss = 0.69551025\n",
      "Iteration 12, loss = 0.69550259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69416894\n",
      "Iteration 2, loss = 0.69415479\n",
      "Iteration 3, loss = 0.69414580\n",
      "Iteration 4, loss = 0.69413702\n",
      "Iteration 5, loss = 0.69412840\n",
      "Iteration 6, loss = 0.69411996\n",
      "Iteration 7, loss = 0.69411174\n",
      "Iteration 8, loss = 0.69410375\n",
      "Iteration 9, loss = 0.69409601\n",
      "Iteration 10, loss = 0.69408852\n",
      "Iteration 11, loss = 0.69408128\n",
      "Iteration 12, loss = 0.69407429\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "325\n",
      "Iteration 1, loss = 0.68950269\n",
      "Iteration 2, loss = 0.68949062\n",
      "Iteration 3, loss = 0.68948296\n",
      "Iteration 4, loss = 0.68947546\n",
      "Iteration 5, loss = 0.68946809\n",
      "Iteration 6, loss = 0.68946087\n",
      "Iteration 7, loss = 0.68945384\n",
      "Iteration 8, loss = 0.68944700\n",
      "Iteration 9, loss = 0.68944038\n",
      "Iteration 10, loss = 0.68943400\n",
      "Iteration 11, loss = 0.68942786\n",
      "Iteration 12, loss = 0.68942193\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "326\n",
      "Iteration 1, loss = 0.69741661\n",
      "Iteration 2, loss = 0.69740159\n",
      "Iteration 3, loss = 0.69739206\n",
      "Iteration 4, loss = 0.69738273\n",
      "Iteration 5, loss = 0.69737356\n",
      "Iteration 6, loss = 0.69736459\n",
      "Iteration 7, loss = 0.69735584\n",
      "Iteration 8, loss = 0.69734734\n",
      "Iteration 9, loss = 0.69733909\n",
      "Iteration 10, loss = 0.69733111\n",
      "Iteration 11, loss = 0.69732340\n",
      "Iteration 12, loss = 0.69731595\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "327\n",
      "Iteration 1, loss = 0.70198630\n",
      "Iteration 2, loss = 0.70196985\n",
      "Iteration 3, loss = 0.70195941\n",
      "Iteration 4, loss = 0.70194919\n",
      "Iteration 5, loss = 0.70193915\n",
      "Iteration 6, loss = 0.70192933\n",
      "Iteration 7, loss = 0.70191976\n",
      "Iteration 8, loss = 0.70191046\n",
      "Iteration 9, loss = 0.70190145\n",
      "Iteration 10, loss = 0.70189274\n",
      "Iteration 11, loss = 0.70188432\n",
      "Iteration 12, loss = 0.70187619\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "328\n",
      "Iteration 1, loss = 0.69278567\n",
      "Iteration 2, loss = 0.69277388\n",
      "Iteration 3, loss = 0.69276640\n",
      "Iteration 4, loss = 0.69275908\n",
      "Iteration 5, loss = 0.69275190\n",
      "Iteration 6, loss = 0.69274486\n",
      "Iteration 7, loss = 0.69273801\n",
      "Iteration 8, loss = 0.69273136\n",
      "Iteration 9, loss = 0.69272491\n",
      "Iteration 10, loss = 0.69271866\n",
      "Iteration 11, loss = 0.69271263\n",
      "Iteration 12, loss = 0.69270681\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "329\n",
      "Iteration 1, loss = 0.68959271\n",
      "Iteration 2, loss = 0.68957754\n",
      "Iteration 3, loss = 0.68956792\n",
      "Iteration 4, loss = 0.68955849\n",
      "Iteration 5, loss = 0.68954923\n",
      "Iteration 6, loss = 0.68954017\n",
      "Iteration 7, loss = 0.68953134\n",
      "Iteration 8, loss = 0.68952276\n",
      "Iteration 9, loss = 0.68951445\n",
      "Iteration 10, loss = 0.68950641\n",
      "Iteration 11, loss = 0.68949864\n",
      "Iteration 12, loss = 0.68949114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "330\n",
      "Iteration 1, loss = 0.69206809\n",
      "Iteration 2, loss = 0.69205662\n",
      "Iteration 3, loss = 0.69204934\n",
      "Iteration 4, loss = 0.69204221\n",
      "Iteration 5, loss = 0.69203521\n",
      "Iteration 6, loss = 0.69202835\n",
      "Iteration 7, loss = 0.69202167\n",
      "Iteration 8, loss = 0.69201517\n",
      "Iteration 9, loss = 0.69200887\n",
      "Iteration 10, loss = 0.69200276\n",
      "Iteration 11, loss = 0.69199686\n",
      "Iteration 12, loss = 0.69199116\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "331\n",
      "Iteration 1, loss = 0.68926840\n",
      "Iteration 2, loss = 0.68925381\n",
      "Iteration 3, loss = 0.68924456\n",
      "Iteration 4, loss = 0.68923549\n",
      "Iteration 5, loss = 0.68922659\n",
      "Iteration 6, loss = 0.68921788\n",
      "Iteration 7, loss = 0.68920938\n",
      "Iteration 8, loss = 0.68920114\n",
      "Iteration 9, loss = 0.68919314\n",
      "Iteration 10, loss = 0.68918541\n",
      "Iteration 11, loss = 0.68917794\n",
      "Iteration 12, loss = 0.68917073\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "332\n",
      "Iteration 1, loss = 0.69159609\n",
      "Iteration 2, loss = 0.69157753\n",
      "Iteration 3, loss = 0.69156576\n",
      "Iteration 4, loss = 0.69155423\n",
      "Iteration 5, loss = 0.69154291\n",
      "Iteration 6, loss = 0.69153183\n",
      "Iteration 7, loss = 0.69152103\n",
      "Iteration 8, loss = 0.69151055\n",
      "Iteration 9, loss = 0.69150039\n",
      "Iteration 10, loss = 0.69149057\n",
      "Iteration 11, loss = 0.69148108\n",
      "Iteration 12, loss = 0.69147192\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "333\n",
      "Iteration 1, loss = 0.69723936\n",
      "Iteration 2, loss = 0.69722192\n",
      "Iteration 3, loss = 0.69721085\n",
      "Iteration 4, loss = 0.69720001\n",
      "Iteration 5, loss = 0.69718936\n",
      "Iteration 6, loss = 0.69717895\n",
      "Iteration 7, loss = 0.69716880\n",
      "Iteration 8, loss = 0.69715894\n",
      "Iteration 9, loss = 0.69714939\n",
      "Iteration 10, loss = 0.69714015\n",
      "Iteration 11, loss = 0.69713122\n",
      "Iteration 12, loss = 0.69712260\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "334\n",
      "Iteration 1, loss = 0.69130575\n",
      "Iteration 2, loss = 0.69129456\n",
      "Iteration 3, loss = 0.69128746\n",
      "Iteration 4, loss = 0.69128051\n",
      "Iteration 5, loss = 0.69127367\n",
      "Iteration 6, loss = 0.69126698\n",
      "Iteration 7, loss = 0.69126046\n",
      "Iteration 8, loss = 0.69125413\n",
      "Iteration 9, loss = 0.69124799\n",
      "Iteration 10, loss = 0.69124204\n",
      "Iteration 11, loss = 0.69123630\n",
      "Iteration 12, loss = 0.69123076\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "335\n",
      "Iteration 1, loss = 0.69563716\n",
      "Iteration 2, loss = 0.69562221\n",
      "Iteration 3, loss = 0.69561272\n",
      "Iteration 4, loss = 0.69560343\n",
      "Iteration 5, loss = 0.69559431\n",
      "Iteration 6, loss = 0.69558537\n",
      "Iteration 7, loss = 0.69557667\n",
      "Iteration 8, loss = 0.69556822\n",
      "Iteration 9, loss = 0.69556002\n",
      "Iteration 10, loss = 0.69555210\n",
      "Iteration 11, loss = 0.69554444\n",
      "Iteration 12, loss = 0.69553705\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "336\n",
      "Iteration 1, loss = 0.69875694\n",
      "Iteration 2, loss = 0.69874176\n",
      "Iteration 3, loss = 0.69873213\n",
      "Iteration 4, loss = 0.69872270\n",
      "Iteration 5, loss = 0.69871344\n",
      "Iteration 6, loss = 0.69870437\n",
      "Iteration 7, loss = 0.69869553\n",
      "Iteration 8, loss = 0.69868695\n",
      "Iteration 9, loss = 0.69867863\n",
      "Iteration 10, loss = 0.69867058\n",
      "Iteration 11, loss = 0.69866280\n",
      "Iteration 12, loss = 0.69865530\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "337\n",
      "Iteration 1, loss = 0.69243395\n",
      "Iteration 2, loss = 0.69241808\n",
      "Iteration 3, loss = 0.69240801\n",
      "Iteration 4, loss = 0.69239815\n",
      "Iteration 5, loss = 0.69238846\n",
      "Iteration 6, loss = 0.69237898\n",
      "Iteration 7, loss = 0.69236975\n",
      "Iteration 8, loss = 0.69236077\n",
      "Iteration 9, loss = 0.69235208\n",
      "Iteration 10, loss = 0.69234367\n",
      "Iteration 11, loss = 0.69233554\n",
      "Iteration 12, loss = 0.69232769\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "338\n",
      "Iteration 1, loss = 0.69115201\n",
      "Iteration 2, loss = 0.69113932\n",
      "Iteration 3, loss = 0.69113126\n",
      "Iteration 4, loss = 0.69112337\n",
      "Iteration 5, loss = 0.69111562\n",
      "Iteration 6, loss = 0.69110803\n",
      "Iteration 7, loss = 0.69110064\n",
      "Iteration 8, loss = 0.69109345\n",
      "Iteration 9, loss = 0.69108649\n",
      "Iteration 10, loss = 0.69107975\n",
      "Iteration 11, loss = 0.69107324\n",
      "Iteration 12, loss = 0.69106696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "339\n",
      "Iteration 1, loss = 0.69733858\n",
      "Iteration 2, loss = 0.69732659\n",
      "Iteration 3, loss = 0.69731898\n",
      "Iteration 4, loss = 0.69731152\n",
      "Iteration 5, loss = 0.69730420\n",
      "Iteration 6, loss = 0.69729703\n",
      "Iteration 7, loss = 0.69729004\n",
      "Iteration 8, loss = 0.69728325\n",
      "Iteration 9, loss = 0.69727668\n",
      "Iteration 10, loss = 0.69727032\n",
      "Iteration 11, loss = 0.69726418\n",
      "Iteration 12, loss = 0.69725825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "340\n",
      "Iteration 1, loss = 0.69013422\n",
      "Iteration 2, loss = 0.69012160\n",
      "Iteration 3, loss = 0.69011359\n",
      "Iteration 4, loss = 0.69010576\n",
      "Iteration 5, loss = 0.69009807\n",
      "Iteration 6, loss = 0.69009054\n",
      "Iteration 7, loss = 0.69008318\n",
      "Iteration 8, loss = 0.69007604\n",
      "Iteration 9, loss = 0.69006911\n",
      "Iteration 10, loss = 0.69006240\n",
      "Iteration 11, loss = 0.69005592\n",
      "Iteration 12, loss = 0.69004966\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "341\n",
      "Iteration 1, loss = 0.68951956\n",
      "Iteration 2, loss = 0.68950812\n",
      "Iteration 3, loss = 0.68950086\n",
      "Iteration 4, loss = 0.68949375\n",
      "Iteration 5, loss = 0.68948679\n",
      "Iteration 6, loss = 0.68947997\n",
      "Iteration 7, loss = 0.68947333\n",
      "Iteration 8, loss = 0.68946689\n",
      "Iteration 9, loss = 0.68946063\n",
      "Iteration 10, loss = 0.68945459\n",
      "Iteration 11, loss = 0.68944875\n",
      "Iteration 12, loss = 0.68944310\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "342\n",
      "Iteration 1, loss = 0.69989728\n",
      "Iteration 2, loss = 0.69987462\n",
      "Iteration 3, loss = 0.69986025\n",
      "Iteration 4, loss = 0.69984618\n",
      "Iteration 5, loss = 0.69983236\n",
      "Iteration 6, loss = 0.69981884\n",
      "Iteration 7, loss = 0.69980567\n",
      "Iteration 8, loss = 0.69979288\n",
      "Iteration 9, loss = 0.69978048\n",
      "Iteration 10, loss = 0.69976850\n",
      "Iteration 11, loss = 0.69975692\n",
      "Iteration 12, loss = 0.69974575\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "343\n",
      "Iteration 1, loss = 0.69742851\n",
      "Iteration 2, loss = 0.69741138\n",
      "Iteration 3, loss = 0.69740052\n",
      "Iteration 4, loss = 0.69738988\n",
      "Iteration 5, loss = 0.69737942\n",
      "Iteration 6, loss = 0.69736919\n",
      "Iteration 7, loss = 0.69735922\n",
      "Iteration 8, loss = 0.69734954\n",
      "Iteration 9, loss = 0.69734015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.69733108\n",
      "Iteration 11, loss = 0.69732231\n",
      "Iteration 12, loss = 0.69731385\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "344\n",
      "Iteration 1, loss = 0.70027447\n",
      "Iteration 2, loss = 0.70026042\n",
      "Iteration 3, loss = 0.70025150\n",
      "Iteration 4, loss = 0.70024277\n",
      "Iteration 5, loss = 0.70023419\n",
      "Iteration 6, loss = 0.70022580\n",
      "Iteration 7, loss = 0.70021762\n",
      "Iteration 8, loss = 0.70020966\n",
      "Iteration 9, loss = 0.70020195\n",
      "Iteration 10, loss = 0.70019448\n",
      "Iteration 11, loss = 0.70018727\n",
      "Iteration 12, loss = 0.70018030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "345\n",
      "Iteration 1, loss = 0.69655819\n",
      "Iteration 2, loss = 0.69654487\n",
      "Iteration 3, loss = 0.69653641\n",
      "Iteration 4, loss = 0.69652813\n",
      "Iteration 5, loss = 0.69652000\n",
      "Iteration 6, loss = 0.69651203\n",
      "Iteration 7, loss = 0.69650428\n",
      "Iteration 8, loss = 0.69649674\n",
      "Iteration 9, loss = 0.69648943\n",
      "Iteration 10, loss = 0.69648237\n",
      "Iteration 11, loss = 0.69647554\n",
      "Iteration 12, loss = 0.69646895\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "346\n",
      "Iteration 1, loss = 0.69353393\n",
      "Iteration 2, loss = 0.69352364\n",
      "Iteration 3, loss = 0.69351711\n",
      "Iteration 4, loss = 0.69351071\n",
      "Iteration 5, loss = 0.69350442\n",
      "Iteration 6, loss = 0.69349827\n",
      "Iteration 7, loss = 0.69349227\n",
      "Iteration 8, loss = 0.69348644\n",
      "Iteration 9, loss = 0.69348079\n",
      "Iteration 10, loss = 0.69347532\n",
      "Iteration 11, loss = 0.69347004\n",
      "Iteration 12, loss = 0.69346494\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "347\n",
      "Iteration 1, loss = 0.69904835\n",
      "Iteration 2, loss = 0.69903547\n",
      "Iteration 3, loss = 0.69902728\n",
      "Iteration 4, loss = 0.69901923\n",
      "Iteration 5, loss = 0.69901132\n",
      "Iteration 6, loss = 0.69900357\n",
      "Iteration 7, loss = 0.69899602\n",
      "Iteration 8, loss = 0.69898868\n",
      "Iteration 9, loss = 0.69898156\n",
      "Iteration 10, loss = 0.69897467\n",
      "Iteration 11, loss = 0.69896802\n",
      "Iteration 12, loss = 0.69896159\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "348\n",
      "Iteration 1, loss = 0.69152969\n",
      "Iteration 2, loss = 0.69151520\n",
      "Iteration 3, loss = 0.69150600\n",
      "Iteration 4, loss = 0.69149700\n",
      "Iteration 5, loss = 0.69148815\n",
      "Iteration 6, loss = 0.69147949\n",
      "Iteration 7, loss = 0.69147105\n",
      "Iteration 8, loss = 0.69146286\n",
      "Iteration 9, loss = 0.69145492\n",
      "Iteration 10, loss = 0.69144726\n",
      "Iteration 11, loss = 0.69143986\n",
      "Iteration 12, loss = 0.69143272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "349\n",
      "Iteration 1, loss = 0.70723110\n",
      "Iteration 2, loss = 0.70721508\n",
      "Iteration 3, loss = 0.70720492\n",
      "Iteration 4, loss = 0.70719496\n",
      "Iteration 5, loss = 0.70718521\n",
      "Iteration 6, loss = 0.70717570\n",
      "Iteration 7, loss = 0.70716643\n",
      "Iteration 8, loss = 0.70715742\n",
      "Iteration 9, loss = 0.70714870\n",
      "Iteration 10, loss = 0.70714028\n",
      "Iteration 11, loss = 0.70713215\n",
      "Iteration 12, loss = 0.70712430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "350\n",
      "Iteration 1, loss = 0.69359695\n",
      "Iteration 2, loss = 0.69358255\n",
      "Iteration 3, loss = 0.69357341\n",
      "Iteration 4, loss = 0.69356446\n",
      "Iteration 5, loss = 0.69355566\n",
      "Iteration 6, loss = 0.69354705\n",
      "Iteration 7, loss = 0.69353866\n",
      "Iteration 8, loss = 0.69353052\n",
      "Iteration 9, loss = 0.69352262\n",
      "Iteration 10, loss = 0.69351498\n",
      "Iteration 11, loss = 0.69350759\n",
      "Iteration 12, loss = 0.69350047\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "351\n",
      "Iteration 1, loss = 0.69001808\n",
      "Iteration 2, loss = 0.69000131\n",
      "Iteration 3, loss = 0.68999067\n",
      "Iteration 4, loss = 0.68998026\n",
      "Iteration 5, loss = 0.68997003\n",
      "Iteration 6, loss = 0.68996003\n",
      "Iteration 7, loss = 0.68995029\n",
      "Iteration 8, loss = 0.68994082\n",
      "Iteration 9, loss = 0.68993165\n",
      "Iteration 10, loss = 0.68992278\n",
      "Iteration 11, loss = 0.68991421\n",
      "Iteration 12, loss = 0.68990594\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "352\n",
      "Iteration 1, loss = 0.69140310\n",
      "Iteration 2, loss = 0.69139157\n",
      "Iteration 3, loss = 0.69138424\n",
      "Iteration 4, loss = 0.69137707\n",
      "Iteration 5, loss = 0.69137002\n",
      "Iteration 6, loss = 0.69136312\n",
      "Iteration 7, loss = 0.69135639\n",
      "Iteration 8, loss = 0.69134986\n",
      "Iteration 9, loss = 0.69134352\n",
      "Iteration 10, loss = 0.69133739\n",
      "Iteration 11, loss = 0.69133146\n",
      "Iteration 12, loss = 0.69132573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "353\n",
      "Iteration 1, loss = 0.69847785\n",
      "Iteration 2, loss = 0.69845714\n",
      "Iteration 3, loss = 0.69844400\n",
      "Iteration 4, loss = 0.69843113\n",
      "Iteration 5, loss = 0.69841850\n",
      "Iteration 6, loss = 0.69840613\n",
      "Iteration 7, loss = 0.69839409\n",
      "Iteration 8, loss = 0.69838239\n",
      "Iteration 9, loss = 0.69837105\n",
      "Iteration 10, loss = 0.69836009\n",
      "Iteration 11, loss = 0.69834950\n",
      "Iteration 12, loss = 0.69833927\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "354\n",
      "Iteration 1, loss = 0.70033938\n",
      "Iteration 2, loss = 0.70030244\n",
      "Iteration 3, loss = 0.70027901\n",
      "Iteration 4, loss = 0.70025609\n",
      "Iteration 5, loss = 0.70023357\n",
      "Iteration 6, loss = 0.70021155\n",
      "Iteration 7, loss = 0.70019011\n",
      "Iteration 8, loss = 0.70016931\n",
      "Iteration 9, loss = 0.70014917\n",
      "Iteration 10, loss = 0.70012969\n",
      "Iteration 11, loss = 0.70011089\n",
      "Iteration 12, loss = 0.70009275\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "355\n",
      "Iteration 1, loss = 0.69272642\n",
      "Iteration 2, loss = 0.69271420\n",
      "Iteration 3, loss = 0.69270645\n",
      "Iteration 4, loss = 0.69269885\n",
      "Iteration 5, loss = 0.69269140\n",
      "Iteration 6, loss = 0.69268411\n",
      "Iteration 7, loss = 0.69267701\n",
      "Iteration 8, loss = 0.69267010\n",
      "Iteration 9, loss = 0.69266341\n",
      "Iteration 10, loss = 0.69265694\n",
      "Iteration 11, loss = 0.69265069\n",
      "Iteration 12, loss = 0.69264465\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "356\n",
      "Iteration 1, loss = 0.69560104\n",
      "Iteration 2, loss = 0.69558866\n",
      "Iteration 3, loss = 0.69558079\n",
      "Iteration 4, loss = 0.69557308\n",
      "Iteration 5, loss = 0.69556551\n",
      "Iteration 6, loss = 0.69555810\n",
      "Iteration 7, loss = 0.69555087\n",
      "Iteration 8, loss = 0.69554379\n",
      "Iteration 9, loss = 0.69553692\n",
      "Iteration 10, loss = 0.69553028\n",
      "Iteration 11, loss = 0.69552385\n",
      "Iteration 12, loss = 0.69551765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "357\n",
      "Iteration 1, loss = 0.69146055\n",
      "Iteration 2, loss = 0.69144989\n",
      "Iteration 3, loss = 0.69144312\n",
      "Iteration 4, loss = 0.69143649\n",
      "Iteration 5, loss = 0.69142997\n",
      "Iteration 6, loss = 0.69142360\n",
      "Iteration 7, loss = 0.69141738\n",
      "Iteration 8, loss = 0.69141135\n",
      "Iteration 9, loss = 0.69140550\n",
      "Iteration 10, loss = 0.69139984\n",
      "Iteration 11, loss = 0.69139436\n",
      "Iteration 12, loss = 0.69138908\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "358\n",
      "Iteration 1, loss = 0.69018112\n",
      "Iteration 2, loss = 0.69016999\n",
      "Iteration 3, loss = 0.69016293\n",
      "Iteration 4, loss = 0.69015602\n",
      "Iteration 5, loss = 0.69014922\n",
      "Iteration 6, loss = 0.69014257\n",
      "Iteration 7, loss = 0.69013608\n",
      "Iteration 8, loss = 0.69012978\n",
      "Iteration 9, loss = 0.69012368\n",
      "Iteration 10, loss = 0.69011777\n",
      "Iteration 11, loss = 0.69011206\n",
      "Iteration 12, loss = 0.69010655\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "359\n",
      "Iteration 1, loss = 0.69287322\n",
      "Iteration 2, loss = 0.69285928\n",
      "Iteration 3, loss = 0.69285044\n",
      "Iteration 4, loss = 0.69284178\n",
      "Iteration 5, loss = 0.69283327\n",
      "Iteration 6, loss = 0.69282494\n",
      "Iteration 7, loss = 0.69281682\n",
      "Iteration 8, loss = 0.69280894\n",
      "Iteration 9, loss = 0.69280130\n",
      "Iteration 10, loss = 0.69279391\n",
      "Iteration 11, loss = 0.69278676\n",
      "Iteration 12, loss = 0.69277986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "360\n",
      "Iteration 1, loss = 0.69278514\n",
      "Iteration 2, loss = 0.69277268\n",
      "Iteration 3, loss = 0.69276476\n",
      "Iteration 4, loss = 0.69275700\n",
      "Iteration 5, loss = 0.69274937\n",
      "Iteration 6, loss = 0.69274191\n",
      "Iteration 7, loss = 0.69273463\n",
      "Iteration 8, loss = 0.69272756\n",
      "Iteration 9, loss = 0.69272071\n",
      "Iteration 10, loss = 0.69271408\n",
      "Iteration 11, loss = 0.69270767\n",
      "Iteration 12, loss = 0.69270148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "361\n",
      "Iteration 1, loss = 0.69556214\n",
      "Iteration 2, loss = 0.69554854\n",
      "Iteration 3, loss = 0.69553991\n",
      "Iteration 4, loss = 0.69553146\n",
      "Iteration 5, loss = 0.69552315\n",
      "Iteration 6, loss = 0.69551502\n",
      "Iteration 7, loss = 0.69550710\n",
      "Iteration 8, loss = 0.69549940\n",
      "Iteration 9, loss = 0.69549194\n",
      "Iteration 10, loss = 0.69548472\n",
      "Iteration 11, loss = 0.69547775\n",
      "Iteration 12, loss = 0.69547102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "362\n",
      "Iteration 1, loss = 0.69371713\n",
      "Iteration 2, loss = 0.69370488\n",
      "Iteration 3, loss = 0.69369711\n",
      "Iteration 4, loss = 0.69368949\n",
      "Iteration 5, loss = 0.69368201\n",
      "Iteration 6, loss = 0.69367469\n",
      "Iteration 7, loss = 0.69366756\n",
      "Iteration 8, loss = 0.69366062\n",
      "Iteration 9, loss = 0.69365390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.69364740\n",
      "Iteration 11, loss = 0.69364112\n",
      "Iteration 12, loss = 0.69363506\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "363\n",
      "Iteration 1, loss = 0.69415026\n",
      "Iteration 2, loss = 0.69413685\n",
      "Iteration 3, loss = 0.69412835\n",
      "Iteration 4, loss = 0.69412003\n",
      "Iteration 5, loss = 0.69411186\n",
      "Iteration 6, loss = 0.69410386\n",
      "Iteration 7, loss = 0.69409606\n",
      "Iteration 8, loss = 0.69408849\n",
      "Iteration 9, loss = 0.69408115\n",
      "Iteration 10, loss = 0.69407405\n",
      "Iteration 11, loss = 0.69406719\n",
      "Iteration 12, loss = 0.69406057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "364\n",
      "Iteration 1, loss = 0.68965659\n",
      "Iteration 2, loss = 0.68964371\n",
      "Iteration 3, loss = 0.68963554\n",
      "Iteration 4, loss = 0.68962754\n",
      "Iteration 5, loss = 0.68961967\n",
      "Iteration 6, loss = 0.68961197\n",
      "Iteration 7, loss = 0.68960447\n",
      "Iteration 8, loss = 0.68959718\n",
      "Iteration 9, loss = 0.68959011\n",
      "Iteration 10, loss = 0.68958328\n",
      "Iteration 11, loss = 0.68957667\n",
      "Iteration 12, loss = 0.68957029\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "365\n",
      "Iteration 1, loss = 0.69546747\n",
      "Iteration 2, loss = 0.69545495\n",
      "Iteration 3, loss = 0.69544701\n",
      "Iteration 4, loss = 0.69543920\n",
      "Iteration 5, loss = 0.69543150\n",
      "Iteration 6, loss = 0.69542396\n",
      "Iteration 7, loss = 0.69541660\n",
      "Iteration 8, loss = 0.69540944\n",
      "Iteration 9, loss = 0.69540250\n",
      "Iteration 10, loss = 0.69539578\n",
      "Iteration 11, loss = 0.69538929\n",
      "Iteration 12, loss = 0.69538301\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "366\n",
      "Iteration 1, loss = 0.69319913\n",
      "Iteration 2, loss = 0.69318580\n",
      "Iteration 3, loss = 0.69317734\n",
      "Iteration 4, loss = 0.69316905\n",
      "Iteration 5, loss = 0.69316091\n",
      "Iteration 6, loss = 0.69315294\n",
      "Iteration 7, loss = 0.69314517\n",
      "Iteration 8, loss = 0.69313762\n",
      "Iteration 9, loss = 0.69313031\n",
      "Iteration 10, loss = 0.69312323\n",
      "Iteration 11, loss = 0.69311639\n",
      "Iteration 12, loss = 0.69310979\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "367\n",
      "Iteration 1, loss = 0.69406956\n",
      "Iteration 2, loss = 0.69405658\n",
      "Iteration 3, loss = 0.69404835\n",
      "Iteration 4, loss = 0.69404029\n",
      "Iteration 5, loss = 0.69403236\n",
      "Iteration 6, loss = 0.69402461\n",
      "Iteration 7, loss = 0.69401705\n",
      "Iteration 8, loss = 0.69400971\n",
      "Iteration 9, loss = 0.69400258\n",
      "Iteration 10, loss = 0.69399568\n",
      "Iteration 11, loss = 0.69398901\n",
      "Iteration 12, loss = 0.69398257\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "368\n",
      "Iteration 1, loss = 0.69205933\n",
      "Iteration 2, loss = 0.69204785\n",
      "Iteration 3, loss = 0.69204056\n",
      "Iteration 4, loss = 0.69203342\n",
      "Iteration 5, loss = 0.69202641\n",
      "Iteration 6, loss = 0.69201957\n",
      "Iteration 7, loss = 0.69201290\n",
      "Iteration 8, loss = 0.69200641\n",
      "Iteration 9, loss = 0.69200013\n",
      "Iteration 10, loss = 0.69199406\n",
      "Iteration 11, loss = 0.69198818\n",
      "Iteration 12, loss = 0.69198251\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "369\n",
      "Iteration 1, loss = 0.69613688\n",
      "Iteration 2, loss = 0.69612229\n",
      "Iteration 3, loss = 0.69611302\n",
      "Iteration 4, loss = 0.69610395\n",
      "Iteration 5, loss = 0.69609504\n",
      "Iteration 6, loss = 0.69608631\n",
      "Iteration 7, loss = 0.69607781\n",
      "Iteration 8, loss = 0.69606955\n",
      "Iteration 9, loss = 0.69606155\n",
      "Iteration 10, loss = 0.69605381\n",
      "Iteration 11, loss = 0.69604632\n",
      "Iteration 12, loss = 0.69603910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "370\n",
      "Iteration 1, loss = 0.69790802\n",
      "Iteration 2, loss = 0.69789302\n",
      "Iteration 3, loss = 0.69788349\n",
      "Iteration 4, loss = 0.69787417\n",
      "Iteration 5, loss = 0.69786501\n",
      "Iteration 6, loss = 0.69785604\n",
      "Iteration 7, loss = 0.69784729\n",
      "Iteration 8, loss = 0.69783879\n",
      "Iteration 9, loss = 0.69783056\n",
      "Iteration 10, loss = 0.69782258\n",
      "Iteration 11, loss = 0.69781488\n",
      "Iteration 12, loss = 0.69780744\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "371\n",
      "Iteration 1, loss = 0.69397836\n",
      "Iteration 2, loss = 0.69396598\n",
      "Iteration 3, loss = 0.69395812\n",
      "Iteration 4, loss = 0.69395043\n",
      "Iteration 5, loss = 0.69394286\n",
      "Iteration 6, loss = 0.69393546\n",
      "Iteration 7, loss = 0.69392825\n",
      "Iteration 8, loss = 0.69392125\n",
      "Iteration 9, loss = 0.69391446\n",
      "Iteration 10, loss = 0.69390789\n",
      "Iteration 11, loss = 0.69390154\n",
      "Iteration 12, loss = 0.69389541\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "372\n",
      "Iteration 1, loss = 0.69520827\n",
      "Iteration 2, loss = 0.69519698\n",
      "Iteration 3, loss = 0.69518983\n",
      "Iteration 4, loss = 0.69518283\n",
      "Iteration 5, loss = 0.69517594\n",
      "Iteration 6, loss = 0.69516920\n",
      "Iteration 7, loss = 0.69516264\n",
      "Iteration 8, loss = 0.69515626\n",
      "Iteration 9, loss = 0.69515007\n",
      "Iteration 10, loss = 0.69514409\n",
      "Iteration 11, loss = 0.69513831\n",
      "Iteration 12, loss = 0.69513273\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "373\n",
      "Iteration 1, loss = 0.69445530\n",
      "Iteration 2, loss = 0.69444356\n",
      "Iteration 3, loss = 0.69443611\n",
      "Iteration 4, loss = 0.69442881\n",
      "Iteration 5, loss = 0.69442164\n",
      "Iteration 6, loss = 0.69441461\n",
      "Iteration 7, loss = 0.69440777\n",
      "Iteration 8, loss = 0.69440112\n",
      "Iteration 9, loss = 0.69439468\n",
      "Iteration 10, loss = 0.69438844\n",
      "Iteration 11, loss = 0.69438241\n",
      "Iteration 12, loss = 0.69437659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "374\n",
      "Iteration 1, loss = 0.69604526\n",
      "Iteration 2, loss = 0.69603225\n",
      "Iteration 3, loss = 0.69602399\n",
      "Iteration 4, loss = 0.69601590\n",
      "Iteration 5, loss = 0.69600795\n",
      "Iteration 6, loss = 0.69600018\n",
      "Iteration 7, loss = 0.69599260\n",
      "Iteration 8, loss = 0.69598524\n",
      "Iteration 9, loss = 0.69597810\n",
      "Iteration 10, loss = 0.69597120\n",
      "Iteration 11, loss = 0.69596453\n",
      "Iteration 12, loss = 0.69595809\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "375\n",
      "Iteration 1, loss = 0.69310992\n",
      "Iteration 2, loss = 0.69309604\n",
      "Iteration 3, loss = 0.69308723\n",
      "Iteration 4, loss = 0.69307861\n",
      "Iteration 5, loss = 0.69307014\n",
      "Iteration 6, loss = 0.69306185\n",
      "Iteration 7, loss = 0.69305377\n",
      "Iteration 8, loss = 0.69304592\n",
      "Iteration 9, loss = 0.69303831\n",
      "Iteration 10, loss = 0.69303095\n",
      "Iteration 11, loss = 0.69302385\n",
      "Iteration 12, loss = 0.69301698\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "376\n",
      "Iteration 1, loss = 0.69814673\n",
      "Iteration 2, loss = 0.69812638\n",
      "Iteration 3, loss = 0.69811346\n",
      "Iteration 4, loss = 0.69810082\n",
      "Iteration 5, loss = 0.69808840\n",
      "Iteration 6, loss = 0.69807626\n",
      "Iteration 7, loss = 0.69806442\n",
      "Iteration 8, loss = 0.69805292\n",
      "Iteration 9, loss = 0.69804179\n",
      "Iteration 10, loss = 0.69803104\n",
      "Iteration 11, loss = 0.69802065\n",
      "Iteration 12, loss = 0.69801063\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "377\n",
      "Iteration 1, loss = 0.69357295\n",
      "Iteration 2, loss = 0.69355469\n",
      "Iteration 3, loss = 0.69354310\n",
      "Iteration 4, loss = 0.69353176\n",
      "Iteration 5, loss = 0.69352062\n",
      "Iteration 6, loss = 0.69350972\n",
      "Iteration 7, loss = 0.69349909\n",
      "Iteration 8, loss = 0.69348876\n",
      "Iteration 9, loss = 0.69347875\n",
      "Iteration 10, loss = 0.69346907\n",
      "Iteration 11, loss = 0.69345971\n",
      "Iteration 12, loss = 0.69345068\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "378\n",
      "Iteration 1, loss = 0.69246878\n",
      "Iteration 2, loss = 0.69245501\n",
      "Iteration 3, loss = 0.69244626\n",
      "Iteration 4, loss = 0.69243770\n",
      "Iteration 5, loss = 0.69242929\n",
      "Iteration 6, loss = 0.69242106\n",
      "Iteration 7, loss = 0.69241304\n",
      "Iteration 8, loss = 0.69240524\n",
      "Iteration 9, loss = 0.69239769\n",
      "Iteration 10, loss = 0.69239038\n",
      "Iteration 11, loss = 0.69238332\n",
      "Iteration 12, loss = 0.69237650\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "379\n",
      "Iteration 1, loss = 0.69519414\n",
      "Iteration 2, loss = 0.69518232\n",
      "Iteration 3, loss = 0.69517482\n",
      "Iteration 4, loss = 0.69516747\n",
      "Iteration 5, loss = 0.69516025\n",
      "Iteration 6, loss = 0.69515318\n",
      "Iteration 7, loss = 0.69514630\n",
      "Iteration 8, loss = 0.69513962\n",
      "Iteration 9, loss = 0.69513314\n",
      "Iteration 10, loss = 0.69512688\n",
      "Iteration 11, loss = 0.69512083\n",
      "Iteration 12, loss = 0.69511498\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "380\n",
      "Iteration 1, loss = 0.69502097\n",
      "Iteration 2, loss = 0.69500484\n",
      "Iteration 3, loss = 0.69499461\n",
      "Iteration 4, loss = 0.69498459\n",
      "Iteration 5, loss = 0.69497475\n",
      "Iteration 6, loss = 0.69496513\n",
      "Iteration 7, loss = 0.69495575\n",
      "Iteration 8, loss = 0.69494663\n",
      "Iteration 9, loss = 0.69493781\n",
      "Iteration 10, loss = 0.69492926\n",
      "Iteration 11, loss = 0.69492101\n",
      "Iteration 12, loss = 0.69491305\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "381\n",
      "Iteration 1, loss = 0.69088586\n",
      "Iteration 2, loss = 0.69086882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.69085801\n",
      "Iteration 4, loss = 0.69084742\n",
      "Iteration 5, loss = 0.69083700\n",
      "Iteration 6, loss = 0.69082679\n",
      "Iteration 7, loss = 0.69081685\n",
      "Iteration 8, loss = 0.69080719\n",
      "Iteration 9, loss = 0.69079782\n",
      "Iteration 10, loss = 0.69078877\n",
      "Iteration 11, loss = 0.69078001\n",
      "Iteration 12, loss = 0.69077156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "382\n",
      "Iteration 1, loss = 0.69438428\n",
      "Iteration 2, loss = 0.69436436\n",
      "Iteration 3, loss = 0.69435173\n",
      "Iteration 4, loss = 0.69433937\n",
      "Iteration 5, loss = 0.69432723\n",
      "Iteration 6, loss = 0.69431536\n",
      "Iteration 7, loss = 0.69430379\n",
      "Iteration 8, loss = 0.69429255\n",
      "Iteration 9, loss = 0.69428167\n",
      "Iteration 10, loss = 0.69427114\n",
      "Iteration 11, loss = 0.69426097\n",
      "Iteration 12, loss = 0.69425115\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "383\n",
      "Iteration 1, loss = 0.69835825\n",
      "Iteration 2, loss = 0.69834536\n",
      "Iteration 3, loss = 0.69833718\n",
      "Iteration 4, loss = 0.69832917\n",
      "Iteration 5, loss = 0.69832129\n",
      "Iteration 6, loss = 0.69831359\n",
      "Iteration 7, loss = 0.69830607\n",
      "Iteration 8, loss = 0.69829878\n",
      "Iteration 9, loss = 0.69829170\n",
      "Iteration 10, loss = 0.69828486\n",
      "Iteration 11, loss = 0.69827824\n",
      "Iteration 12, loss = 0.69827186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "384\n",
      "Iteration 1, loss = 0.69521750\n",
      "Iteration 2, loss = 0.69519891\n",
      "Iteration 3, loss = 0.69518712\n",
      "Iteration 4, loss = 0.69517558\n",
      "Iteration 5, loss = 0.69516423\n",
      "Iteration 6, loss = 0.69515314\n",
      "Iteration 7, loss = 0.69514233\n",
      "Iteration 8, loss = 0.69513182\n",
      "Iteration 9, loss = 0.69512165\n",
      "Iteration 10, loss = 0.69511181\n",
      "Iteration 11, loss = 0.69510230\n",
      "Iteration 12, loss = 0.69509313\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "385\n",
      "Iteration 1, loss = 0.69866793\n",
      "Iteration 2, loss = 0.69865434\n",
      "Iteration 3, loss = 0.69864572\n",
      "Iteration 4, loss = 0.69863728\n",
      "Iteration 5, loss = 0.69862898\n",
      "Iteration 6, loss = 0.69862087\n",
      "Iteration 7, loss = 0.69861295\n",
      "Iteration 8, loss = 0.69860526\n",
      "Iteration 9, loss = 0.69859781\n",
      "Iteration 10, loss = 0.69859061\n",
      "Iteration 11, loss = 0.69858364\n",
      "Iteration 12, loss = 0.69857693\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "386\n",
      "Iteration 1, loss = 0.69513752\n",
      "Iteration 2, loss = 0.69512254\n",
      "Iteration 3, loss = 0.69511303\n",
      "Iteration 4, loss = 0.69510372\n",
      "Iteration 5, loss = 0.69509457\n",
      "Iteration 6, loss = 0.69508562\n",
      "Iteration 7, loss = 0.69507690\n",
      "Iteration 8, loss = 0.69506843\n",
      "Iteration 9, loss = 0.69506022\n",
      "Iteration 10, loss = 0.69505228\n",
      "Iteration 11, loss = 0.69504460\n",
      "Iteration 12, loss = 0.69503719\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "387\n",
      "Iteration 1, loss = 0.69320579\n",
      "Iteration 2, loss = 0.69319415\n",
      "Iteration 3, loss = 0.69318676\n",
      "Iteration 4, loss = 0.69317952\n",
      "Iteration 5, loss = 0.69317241\n",
      "Iteration 6, loss = 0.69316545\n",
      "Iteration 7, loss = 0.69315866\n",
      "Iteration 8, loss = 0.69315207\n",
      "Iteration 9, loss = 0.69314568\n",
      "Iteration 10, loss = 0.69313950\n",
      "Iteration 11, loss = 0.69313353\n",
      "Iteration 12, loss = 0.69312776\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "388\n",
      "Iteration 1, loss = 0.69241691\n",
      "Iteration 2, loss = 0.69240501\n",
      "Iteration 3, loss = 0.69239745\n",
      "Iteration 4, loss = 0.69239006\n",
      "Iteration 5, loss = 0.69238279\n",
      "Iteration 6, loss = 0.69237567\n",
      "Iteration 7, loss = 0.69236874\n",
      "Iteration 8, loss = 0.69236200\n",
      "Iteration 9, loss = 0.69235547\n",
      "Iteration 10, loss = 0.69234915\n",
      "Iteration 11, loss = 0.69234303\n",
      "Iteration 12, loss = 0.69233713\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "389\n",
      "Iteration 1, loss = 0.69472438\n",
      "Iteration 2, loss = 0.69471338\n",
      "Iteration 3, loss = 0.69470640\n",
      "Iteration 4, loss = 0.69469957\n",
      "Iteration 5, loss = 0.69469285\n",
      "Iteration 6, loss = 0.69468628\n",
      "Iteration 7, loss = 0.69467987\n",
      "Iteration 8, loss = 0.69467364\n",
      "Iteration 9, loss = 0.69466761\n",
      "Iteration 10, loss = 0.69466177\n",
      "Iteration 11, loss = 0.69465612\n",
      "Iteration 12, loss = 0.69465067\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "390\n",
      "Iteration 1, loss = 0.69485098\n",
      "Iteration 2, loss = 0.69483924\n",
      "Iteration 3, loss = 0.69483178\n",
      "Iteration 4, loss = 0.69482449\n",
      "Iteration 5, loss = 0.69481732\n",
      "Iteration 6, loss = 0.69481030\n",
      "Iteration 7, loss = 0.69480346\n",
      "Iteration 8, loss = 0.69479682\n",
      "Iteration 9, loss = 0.69479038\n",
      "Iteration 10, loss = 0.69478415\n",
      "Iteration 11, loss = 0.69477813\n",
      "Iteration 12, loss = 0.69477231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "391\n",
      "Iteration 1, loss = 0.70331116\n",
      "Iteration 2, loss = 0.70329966\n",
      "Iteration 3, loss = 0.70329236\n",
      "Iteration 4, loss = 0.70328521\n",
      "Iteration 5, loss = 0.70327819\n",
      "Iteration 6, loss = 0.70327132\n",
      "Iteration 7, loss = 0.70326462\n",
      "Iteration 8, loss = 0.70325811\n",
      "Iteration 9, loss = 0.70325180\n",
      "Iteration 10, loss = 0.70324570\n",
      "Iteration 11, loss = 0.70323980\n",
      "Iteration 12, loss = 0.70323410\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "392\n",
      "Iteration 1, loss = 0.69058222\n",
      "Iteration 2, loss = 0.69056717\n",
      "Iteration 3, loss = 0.69055763\n",
      "Iteration 4, loss = 0.69054828\n",
      "Iteration 5, loss = 0.69053909\n",
      "Iteration 6, loss = 0.69053010\n",
      "Iteration 7, loss = 0.69052134\n",
      "Iteration 8, loss = 0.69051283\n",
      "Iteration 9, loss = 0.69050459\n",
      "Iteration 10, loss = 0.69049661\n",
      "Iteration 11, loss = 0.69048890\n",
      "Iteration 12, loss = 0.69048146\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "393\n",
      "Iteration 1, loss = 0.69743219\n",
      "Iteration 2, loss = 0.69741341\n",
      "Iteration 3, loss = 0.69740150\n",
      "Iteration 4, loss = 0.69738984\n",
      "Iteration 5, loss = 0.69737838\n",
      "Iteration 6, loss = 0.69736717\n",
      "Iteration 7, loss = 0.69735625\n",
      "Iteration 8, loss = 0.69734565\n",
      "Iteration 9, loss = 0.69733539\n",
      "Iteration 10, loss = 0.69732548\n",
      "Iteration 11, loss = 0.69731590\n",
      "Iteration 12, loss = 0.69730666\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "394\n",
      "Iteration 1, loss = 0.69989849\n",
      "Iteration 2, loss = 0.69987636\n",
      "Iteration 3, loss = 0.69986233\n",
      "Iteration 4, loss = 0.69984859\n",
      "Iteration 5, loss = 0.69983509\n",
      "Iteration 6, loss = 0.69982189\n",
      "Iteration 7, loss = 0.69980902\n",
      "Iteration 8, loss = 0.69979653\n",
      "Iteration 9, loss = 0.69978442\n",
      "Iteration 10, loss = 0.69977270\n",
      "Iteration 11, loss = 0.69976138\n",
      "Iteration 12, loss = 0.69975046\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "395\n",
      "Iteration 1, loss = 0.69939266\n",
      "Iteration 2, loss = 0.69937572\n",
      "Iteration 3, loss = 0.69936498\n",
      "Iteration 4, loss = 0.69935447\n",
      "Iteration 5, loss = 0.69934415\n",
      "Iteration 6, loss = 0.69933404\n",
      "Iteration 7, loss = 0.69932420\n",
      "Iteration 8, loss = 0.69931464\n",
      "Iteration 9, loss = 0.69930537\n",
      "Iteration 10, loss = 0.69929643\n",
      "Iteration 11, loss = 0.69928779\n",
      "Iteration 12, loss = 0.69927944\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "396\n",
      "Iteration 1, loss = 0.69202619\n",
      "Iteration 2, loss = 0.69201279\n",
      "Iteration 3, loss = 0.69200429\n",
      "Iteration 4, loss = 0.69199596\n",
      "Iteration 5, loss = 0.69198781\n",
      "Iteration 6, loss = 0.69197983\n",
      "Iteration 7, loss = 0.69197205\n",
      "Iteration 8, loss = 0.69196449\n",
      "Iteration 9, loss = 0.69195717\n",
      "Iteration 10, loss = 0.69195009\n",
      "Iteration 11, loss = 0.69194324\n",
      "Iteration 12, loss = 0.69193663\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "397\n",
      "Iteration 1, loss = 0.68762084\n",
      "Iteration 2, loss = 0.68760876\n",
      "Iteration 3, loss = 0.68760111\n",
      "Iteration 4, loss = 0.68759361\n",
      "Iteration 5, loss = 0.68758625\n",
      "Iteration 6, loss = 0.68757904\n",
      "Iteration 7, loss = 0.68757202\n",
      "Iteration 8, loss = 0.68756519\n",
      "Iteration 9, loss = 0.68755858\n",
      "Iteration 10, loss = 0.68755218\n",
      "Iteration 11, loss = 0.68754598\n",
      "Iteration 12, loss = 0.68754000\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "398\n",
      "Iteration 1, loss = 0.69263636\n",
      "Iteration 2, loss = 0.69262441\n",
      "Iteration 3, loss = 0.69261682\n",
      "Iteration 4, loss = 0.69260938\n",
      "Iteration 5, loss = 0.69260208\n",
      "Iteration 6, loss = 0.69259494\n",
      "Iteration 7, loss = 0.69258797\n",
      "Iteration 8, loss = 0.69258121\n",
      "Iteration 9, loss = 0.69257465\n",
      "Iteration 10, loss = 0.69256830\n",
      "Iteration 11, loss = 0.69256217\n",
      "Iteration 12, loss = 0.69255628\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "399\n",
      "Iteration 1, loss = 0.69629983\n",
      "Iteration 2, loss = 0.69628206\n",
      "Iteration 3, loss = 0.69627078\n",
      "Iteration 4, loss = 0.69625974\n",
      "Iteration 5, loss = 0.69624890\n",
      "Iteration 6, loss = 0.69623828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.69622794\n",
      "Iteration 8, loss = 0.69621790\n",
      "Iteration 9, loss = 0.69620816\n",
      "Iteration 10, loss = 0.69619875\n",
      "Iteration 11, loss = 0.69618965\n",
      "Iteration 12, loss = 0.69618087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "400\n",
      "Iteration 1, loss = 0.69734300\n",
      "Iteration 2, loss = 0.69732799\n",
      "Iteration 3, loss = 0.69731846\n",
      "Iteration 4, loss = 0.69730914\n",
      "Iteration 5, loss = 0.69730000\n",
      "Iteration 6, loss = 0.69729105\n",
      "Iteration 7, loss = 0.69728234\n",
      "Iteration 8, loss = 0.69727388\n",
      "Iteration 9, loss = 0.69726570\n",
      "Iteration 10, loss = 0.69725778\n",
      "Iteration 11, loss = 0.69725014\n",
      "Iteration 12, loss = 0.69724275\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "401\n",
      "Iteration 1, loss = 0.68872579\n",
      "Iteration 2, loss = 0.68871133\n",
      "Iteration 3, loss = 0.68870216\n",
      "Iteration 4, loss = 0.68869317\n",
      "Iteration 5, loss = 0.68868435\n",
      "Iteration 6, loss = 0.68867571\n",
      "Iteration 7, loss = 0.68866729\n",
      "Iteration 8, loss = 0.68865911\n",
      "Iteration 9, loss = 0.68865118\n",
      "Iteration 10, loss = 0.68864351\n",
      "Iteration 11, loss = 0.68863610\n",
      "Iteration 12, loss = 0.68862895\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "402\n",
      "Iteration 1, loss = 0.69675559\n",
      "Iteration 2, loss = 0.69674405\n",
      "Iteration 3, loss = 0.69673673\n",
      "Iteration 4, loss = 0.69672956\n",
      "Iteration 5, loss = 0.69672252\n",
      "Iteration 6, loss = 0.69671562\n",
      "Iteration 7, loss = 0.69670890\n",
      "Iteration 8, loss = 0.69670237\n",
      "Iteration 9, loss = 0.69669604\n",
      "Iteration 10, loss = 0.69668991\n",
      "Iteration 11, loss = 0.69668400\n",
      "Iteration 12, loss = 0.69667828\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "403\n",
      "Iteration 1, loss = 0.69236785\n",
      "Iteration 2, loss = 0.69235744\n",
      "Iteration 3, loss = 0.69235083\n",
      "Iteration 4, loss = 0.69234435\n",
      "Iteration 5, loss = 0.69233799\n",
      "Iteration 6, loss = 0.69233176\n",
      "Iteration 7, loss = 0.69232569\n",
      "Iteration 8, loss = 0.69231979\n",
      "Iteration 9, loss = 0.69231407\n",
      "Iteration 10, loss = 0.69230854\n",
      "Iteration 11, loss = 0.69230319\n",
      "Iteration 12, loss = 0.69229803\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "404\n",
      "Iteration 1, loss = 0.69702791\n",
      "Iteration 2, loss = 0.69701040\n",
      "Iteration 3, loss = 0.69699931\n",
      "Iteration 4, loss = 0.69698845\n",
      "Iteration 5, loss = 0.69697779\n",
      "Iteration 6, loss = 0.69696735\n",
      "Iteration 7, loss = 0.69695719\n",
      "Iteration 8, loss = 0.69694731\n",
      "Iteration 9, loss = 0.69693775\n",
      "Iteration 10, loss = 0.69692850\n",
      "Iteration 11, loss = 0.69691956\n",
      "Iteration 12, loss = 0.69691093\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "405\n",
      "Iteration 1, loss = 0.69789230\n",
      "Iteration 2, loss = 0.69787970\n",
      "Iteration 3, loss = 0.69787171\n",
      "Iteration 4, loss = 0.69786389\n",
      "Iteration 5, loss = 0.69785620\n",
      "Iteration 6, loss = 0.69784868\n",
      "Iteration 7, loss = 0.69784136\n",
      "Iteration 8, loss = 0.69783424\n",
      "Iteration 9, loss = 0.69782734\n",
      "Iteration 10, loss = 0.69782067\n",
      "Iteration 11, loss = 0.69781422\n",
      "Iteration 12, loss = 0.69780799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "406\n",
      "Iteration 1, loss = 0.69357002\n",
      "Iteration 2, loss = 0.69355770\n",
      "Iteration 3, loss = 0.69354988\n",
      "Iteration 4, loss = 0.69354222\n",
      "Iteration 5, loss = 0.69353469\n",
      "Iteration 6, loss = 0.69352731\n",
      "Iteration 7, loss = 0.69352012\n",
      "Iteration 8, loss = 0.69351313\n",
      "Iteration 9, loss = 0.69350636\n",
      "Iteration 10, loss = 0.69349981\n",
      "Iteration 11, loss = 0.69349347\n",
      "Iteration 12, loss = 0.69348735\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "407\n",
      "Iteration 1, loss = 0.69804270\n",
      "Iteration 2, loss = 0.69802399\n",
      "Iteration 3, loss = 0.69801211\n",
      "Iteration 4, loss = 0.69800048\n",
      "Iteration 5, loss = 0.69798906\n",
      "Iteration 6, loss = 0.69797789\n",
      "Iteration 7, loss = 0.69796700\n",
      "Iteration 8, loss = 0.69795642\n",
      "Iteration 9, loss = 0.69794618\n",
      "Iteration 10, loss = 0.69793626\n",
      "Iteration 11, loss = 0.69792669\n",
      "Iteration 12, loss = 0.69791745\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "408\n",
      "Iteration 1, loss = 0.68680200\n",
      "Iteration 2, loss = 0.68678781\n",
      "Iteration 3, loss = 0.68677881\n",
      "Iteration 4, loss = 0.68676999\n",
      "Iteration 5, loss = 0.68676132\n",
      "Iteration 6, loss = 0.68675285\n",
      "Iteration 7, loss = 0.68674458\n",
      "Iteration 8, loss = 0.68673655\n",
      "Iteration 9, loss = 0.68672877\n",
      "Iteration 10, loss = 0.68672124\n",
      "Iteration 11, loss = 0.68671396\n",
      "Iteration 12, loss = 0.68670695\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "409\n",
      "Iteration 1, loss = 0.69303170\n",
      "Iteration 2, loss = 0.69301988\n",
      "Iteration 3, loss = 0.69301238\n",
      "Iteration 4, loss = 0.69300504\n",
      "Iteration 5, loss = 0.69299782\n",
      "Iteration 6, loss = 0.69299075\n",
      "Iteration 7, loss = 0.69298387\n",
      "Iteration 8, loss = 0.69297717\n",
      "Iteration 9, loss = 0.69297069\n",
      "Iteration 10, loss = 0.69296441\n",
      "Iteration 11, loss = 0.69295835\n",
      "Iteration 12, loss = 0.69295249\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "410\n",
      "Iteration 1, loss = 0.69521226\n",
      "Iteration 2, loss = 0.69519959\n",
      "Iteration 3, loss = 0.69519156\n",
      "Iteration 4, loss = 0.69518369\n",
      "Iteration 5, loss = 0.69517596\n",
      "Iteration 6, loss = 0.69516839\n",
      "Iteration 7, loss = 0.69516101\n",
      "Iteration 8, loss = 0.69515385\n",
      "Iteration 9, loss = 0.69514693\n",
      "Iteration 10, loss = 0.69514023\n",
      "Iteration 11, loss = 0.69513376\n",
      "Iteration 12, loss = 0.69512752\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "411\n",
      "Iteration 1, loss = 0.69273459\n",
      "Iteration 2, loss = 0.69272255\n",
      "Iteration 3, loss = 0.69271491\n",
      "Iteration 4, loss = 0.69270742\n",
      "Iteration 5, loss = 0.69270007\n",
      "Iteration 6, loss = 0.69269287\n",
      "Iteration 7, loss = 0.69268588\n",
      "Iteration 8, loss = 0.69267908\n",
      "Iteration 9, loss = 0.69267249\n",
      "Iteration 10, loss = 0.69266612\n",
      "Iteration 11, loss = 0.69265996\n",
      "Iteration 12, loss = 0.69265401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "412\n",
      "Iteration 1, loss = 0.69298844\n",
      "Iteration 2, loss = 0.69297704\n",
      "Iteration 3, loss = 0.69296980\n",
      "Iteration 4, loss = 0.69296271\n",
      "Iteration 5, loss = 0.69295574\n",
      "Iteration 6, loss = 0.69294891\n",
      "Iteration 7, loss = 0.69294226\n",
      "Iteration 8, loss = 0.69293580\n",
      "Iteration 9, loss = 0.69292954\n",
      "Iteration 10, loss = 0.69292348\n",
      "Iteration 11, loss = 0.69291762\n",
      "Iteration 12, loss = 0.69291196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "413\n",
      "Iteration 1, loss = 0.69120064\n",
      "Iteration 2, loss = 0.69118828\n",
      "Iteration 3, loss = 0.69118043\n",
      "Iteration 4, loss = 0.69117276\n",
      "Iteration 5, loss = 0.69116518\n",
      "Iteration 6, loss = 0.69115776\n",
      "Iteration 7, loss = 0.69115052\n",
      "Iteration 8, loss = 0.69114349\n",
      "Iteration 9, loss = 0.69113666\n",
      "Iteration 10, loss = 0.69113006\n",
      "Iteration 11, loss = 0.69112368\n",
      "Iteration 12, loss = 0.69111749\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "414\n",
      "Iteration 1, loss = 0.69235176\n",
      "Iteration 2, loss = 0.69234044\n",
      "Iteration 3, loss = 0.69233325\n",
      "Iteration 4, loss = 0.69232621\n",
      "Iteration 5, loss = 0.69231930\n",
      "Iteration 6, loss = 0.69231253\n",
      "Iteration 7, loss = 0.69230592\n",
      "Iteration 8, loss = 0.69229948\n",
      "Iteration 9, loss = 0.69229324\n",
      "Iteration 10, loss = 0.69228720\n",
      "Iteration 11, loss = 0.69228136\n",
      "Iteration 12, loss = 0.69227573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "415\n",
      "Iteration 1, loss = 0.69624966\n",
      "Iteration 2, loss = 0.69623107\n",
      "Iteration 3, loss = 0.69621928\n",
      "Iteration 4, loss = 0.69620774\n",
      "Iteration 5, loss = 0.69619640\n",
      "Iteration 6, loss = 0.69618531\n",
      "Iteration 7, loss = 0.69617450\n",
      "Iteration 8, loss = 0.69616401\n",
      "Iteration 9, loss = 0.69615384\n",
      "Iteration 10, loss = 0.69614400\n",
      "Iteration 11, loss = 0.69613450\n",
      "Iteration 12, loss = 0.69612533\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "416\n",
      "Iteration 1, loss = 0.69691118\n",
      "Iteration 2, loss = 0.69689967\n",
      "Iteration 3, loss = 0.69689236\n",
      "Iteration 4, loss = 0.69688521\n",
      "Iteration 5, loss = 0.69687818\n",
      "Iteration 6, loss = 0.69687130\n",
      "Iteration 7, loss = 0.69686459\n",
      "Iteration 8, loss = 0.69685808\n",
      "Iteration 9, loss = 0.69685176\n",
      "Iteration 10, loss = 0.69684565\n",
      "Iteration 11, loss = 0.69683975\n",
      "Iteration 12, loss = 0.69683405\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "417\n",
      "Iteration 1, loss = 0.69371269\n",
      "Iteration 2, loss = 0.69370064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.69369299\n",
      "Iteration 4, loss = 0.69368551\n",
      "Iteration 5, loss = 0.69367814\n",
      "Iteration 6, loss = 0.69367094\n",
      "Iteration 7, loss = 0.69366392\n",
      "Iteration 8, loss = 0.69365710\n",
      "Iteration 9, loss = 0.69365049\n",
      "Iteration 10, loss = 0.69364409\n",
      "Iteration 11, loss = 0.69363791\n",
      "Iteration 12, loss = 0.69363194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "418\n",
      "Iteration 1, loss = 0.69862010\n",
      "Iteration 2, loss = 0.69860400\n",
      "Iteration 3, loss = 0.69859378\n",
      "Iteration 4, loss = 0.69858378\n",
      "Iteration 5, loss = 0.69857395\n",
      "Iteration 6, loss = 0.69856434\n",
      "Iteration 7, loss = 0.69855497\n",
      "Iteration 8, loss = 0.69854587\n",
      "Iteration 9, loss = 0.69853706\n",
      "Iteration 10, loss = 0.69852853\n",
      "Iteration 11, loss = 0.69852030\n",
      "Iteration 12, loss = 0.69851235\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "419\n",
      "Iteration 1, loss = 0.69400909\n",
      "Iteration 2, loss = 0.69399540\n",
      "Iteration 3, loss = 0.69398672\n",
      "Iteration 4, loss = 0.69397821\n",
      "Iteration 5, loss = 0.69396983\n",
      "Iteration 6, loss = 0.69396163\n",
      "Iteration 7, loss = 0.69395363\n",
      "Iteration 8, loss = 0.69394586\n",
      "Iteration 9, loss = 0.69393832\n",
      "Iteration 10, loss = 0.69393103\n",
      "Iteration 11, loss = 0.69392399\n",
      "Iteration 12, loss = 0.69391718\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "420\n",
      "Iteration 1, loss = 0.69398830\n",
      "Iteration 2, loss = 0.69397604\n",
      "Iteration 3, loss = 0.69396826\n",
      "Iteration 4, loss = 0.69396064\n",
      "Iteration 5, loss = 0.69395316\n",
      "Iteration 6, loss = 0.69394585\n",
      "Iteration 7, loss = 0.69393873\n",
      "Iteration 8, loss = 0.69393181\n",
      "Iteration 9, loss = 0.69392511\n",
      "Iteration 10, loss = 0.69391862\n",
      "Iteration 11, loss = 0.69391233\n",
      "Iteration 12, loss = 0.69390627\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "421\n",
      "Iteration 1, loss = 0.69679889\n",
      "Iteration 2, loss = 0.69677746\n",
      "Iteration 3, loss = 0.69676387\n",
      "Iteration 4, loss = 0.69675056\n",
      "Iteration 5, loss = 0.69673749\n",
      "Iteration 6, loss = 0.69672470\n",
      "Iteration 7, loss = 0.69671226\n",
      "Iteration 8, loss = 0.69670019\n",
      "Iteration 9, loss = 0.69668850\n",
      "Iteration 10, loss = 0.69667718\n",
      "Iteration 11, loss = 0.69666624\n",
      "Iteration 12, loss = 0.69665569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "422\n",
      "Iteration 1, loss = 0.69399097\n",
      "Iteration 2, loss = 0.69397243\n",
      "Iteration 3, loss = 0.69396066\n",
      "Iteration 4, loss = 0.69394914\n",
      "Iteration 5, loss = 0.69393783\n",
      "Iteration 6, loss = 0.69392676\n",
      "Iteration 7, loss = 0.69391598\n",
      "Iteration 8, loss = 0.69390551\n",
      "Iteration 9, loss = 0.69389536\n",
      "Iteration 10, loss = 0.69388555\n",
      "Iteration 11, loss = 0.69387607\n",
      "Iteration 12, loss = 0.69386692\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "423\n",
      "Iteration 1, loss = 0.69443149\n",
      "Iteration 2, loss = 0.69441634\n",
      "Iteration 3, loss = 0.69440672\n",
      "Iteration 4, loss = 0.69439731\n",
      "Iteration 5, loss = 0.69438806\n",
      "Iteration 6, loss = 0.69437901\n",
      "Iteration 7, loss = 0.69437019\n",
      "Iteration 8, loss = 0.69436162\n",
      "Iteration 9, loss = 0.69435332\n",
      "Iteration 10, loss = 0.69434529\n",
      "Iteration 11, loss = 0.69433754\n",
      "Iteration 12, loss = 0.69433005\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "424\n",
      "Iteration 1, loss = 0.69409767\n",
      "Iteration 2, loss = 0.69408660\n",
      "Iteration 3, loss = 0.69407956\n",
      "Iteration 4, loss = 0.69407268\n",
      "Iteration 5, loss = 0.69406591\n",
      "Iteration 6, loss = 0.69405929\n",
      "Iteration 7, loss = 0.69405285\n",
      "Iteration 8, loss = 0.69404660\n",
      "Iteration 9, loss = 0.69404055\n",
      "Iteration 10, loss = 0.69403469\n",
      "Iteration 11, loss = 0.69402903\n",
      "Iteration 12, loss = 0.69402357\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "425\n",
      "Iteration 1, loss = 0.70015206\n",
      "Iteration 2, loss = 0.70013385\n",
      "Iteration 3, loss = 0.70012229\n",
      "Iteration 4, loss = 0.70011098\n",
      "Iteration 5, loss = 0.70009986\n",
      "Iteration 6, loss = 0.70008898\n",
      "Iteration 7, loss = 0.70007837\n",
      "Iteration 8, loss = 0.70006807\n",
      "Iteration 9, loss = 0.70005809\n",
      "Iteration 10, loss = 0.70004843\n",
      "Iteration 11, loss = 0.70003910\n",
      "Iteration 12, loss = 0.70003010\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "426\n",
      "Iteration 1, loss = 0.69553059\n",
      "Iteration 2, loss = 0.69551534\n",
      "Iteration 3, loss = 0.69550566\n",
      "Iteration 4, loss = 0.69549619\n",
      "Iteration 5, loss = 0.69548688\n",
      "Iteration 6, loss = 0.69547777\n",
      "Iteration 7, loss = 0.69546890\n",
      "Iteration 8, loss = 0.69546028\n",
      "Iteration 9, loss = 0.69545193\n",
      "Iteration 10, loss = 0.69544385\n",
      "Iteration 11, loss = 0.69543605\n",
      "Iteration 12, loss = 0.69542852\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "427\n",
      "Iteration 1, loss = 0.69647653\n",
      "Iteration 2, loss = 0.69646435\n",
      "Iteration 3, loss = 0.69645662\n",
      "Iteration 4, loss = 0.69644901\n",
      "Iteration 5, loss = 0.69644154\n",
      "Iteration 6, loss = 0.69643422\n",
      "Iteration 7, loss = 0.69642709\n",
      "Iteration 8, loss = 0.69642015\n",
      "Iteration 9, loss = 0.69641343\n",
      "Iteration 10, loss = 0.69640694\n",
      "Iteration 11, loss = 0.69640068\n",
      "Iteration 12, loss = 0.69639464\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "428\n",
      "Iteration 1, loss = 0.69322493\n",
      "Iteration 2, loss = 0.69321264\n",
      "Iteration 3, loss = 0.69320485\n",
      "Iteration 4, loss = 0.69319721\n",
      "Iteration 5, loss = 0.69318970\n",
      "Iteration 6, loss = 0.69318236\n",
      "Iteration 7, loss = 0.69317520\n",
      "Iteration 8, loss = 0.69316824\n",
      "Iteration 9, loss = 0.69316150\n",
      "Iteration 10, loss = 0.69315498\n",
      "Iteration 11, loss = 0.69314867\n",
      "Iteration 12, loss = 0.69314259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "429\n",
      "Iteration 1, loss = 0.69089175\n",
      "Iteration 2, loss = 0.69088033\n",
      "Iteration 3, loss = 0.69087308\n",
      "Iteration 4, loss = 0.69086599\n",
      "Iteration 5, loss = 0.69085902\n",
      "Iteration 6, loss = 0.69085220\n",
      "Iteration 7, loss = 0.69084555\n",
      "Iteration 8, loss = 0.69083909\n",
      "Iteration 9, loss = 0.69083283\n",
      "Iteration 10, loss = 0.69082677\n",
      "Iteration 11, loss = 0.69082092\n",
      "Iteration 12, loss = 0.69081526\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "430\n",
      "Iteration 1, loss = 0.69545330\n",
      "Iteration 2, loss = 0.69543890\n",
      "Iteration 3, loss = 0.69542976\n",
      "Iteration 4, loss = 0.69542081\n",
      "Iteration 5, loss = 0.69541201\n",
      "Iteration 6, loss = 0.69540339\n",
      "Iteration 7, loss = 0.69539500\n",
      "Iteration 8, loss = 0.69538685\n",
      "Iteration 9, loss = 0.69537895\n",
      "Iteration 10, loss = 0.69537131\n",
      "Iteration 11, loss = 0.69536393\n",
      "Iteration 12, loss = 0.69535680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "431\n",
      "Iteration 1, loss = 0.69107720\n",
      "Iteration 2, loss = 0.69106534\n",
      "Iteration 3, loss = 0.69105781\n",
      "Iteration 4, loss = 0.69105048\n",
      "Iteration 5, loss = 0.69104330\n",
      "Iteration 6, loss = 0.69103627\n",
      "Iteration 7, loss = 0.69102941\n",
      "Iteration 8, loss = 0.69102276\n",
      "Iteration 9, loss = 0.69101631\n",
      "Iteration 10, loss = 0.69101006\n",
      "Iteration 11, loss = 0.69100403\n",
      "Iteration 12, loss = 0.69099820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "432\n",
      "Iteration 1, loss = 0.69225034\n",
      "Iteration 2, loss = 0.69223730\n",
      "Iteration 3, loss = 0.69222902\n",
      "Iteration 4, loss = 0.69222092\n",
      "Iteration 5, loss = 0.69221295\n",
      "Iteration 6, loss = 0.69220516\n",
      "Iteration 7, loss = 0.69219756\n",
      "Iteration 8, loss = 0.69219018\n",
      "Iteration 9, loss = 0.69218303\n",
      "Iteration 10, loss = 0.69217611\n",
      "Iteration 11, loss = 0.69216942\n",
      "Iteration 12, loss = 0.69216297\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "433\n",
      "Iteration 1, loss = 0.69572843\n",
      "Iteration 2, loss = 0.69571337\n",
      "Iteration 3, loss = 0.69570381\n",
      "Iteration 4, loss = 0.69569445\n",
      "Iteration 5, loss = 0.69568525\n",
      "Iteration 6, loss = 0.69567625\n",
      "Iteration 7, loss = 0.69566748\n",
      "Iteration 8, loss = 0.69565896\n",
      "Iteration 9, loss = 0.69565071\n",
      "Iteration 10, loss = 0.69564272\n",
      "Iteration 11, loss = 0.69563500\n",
      "Iteration 12, loss = 0.69562755\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "434\n",
      "Iteration 1, loss = 0.69467691\n",
      "Iteration 2, loss = 0.69466609\n",
      "Iteration 3, loss = 0.69465922\n",
      "Iteration 4, loss = 0.69465249\n",
      "Iteration 5, loss = 0.69464587\n",
      "Iteration 6, loss = 0.69463940\n",
      "Iteration 7, loss = 0.69463309\n",
      "Iteration 8, loss = 0.69462696\n",
      "Iteration 9, loss = 0.69462102\n",
      "Iteration 10, loss = 0.69461527\n",
      "Iteration 11, loss = 0.69460972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.69460436\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "435\n",
      "Iteration 1, loss = 0.69165192\n",
      "Iteration 2, loss = 0.69164125\n",
      "Iteration 3, loss = 0.69163448\n",
      "Iteration 4, loss = 0.69162784\n",
      "Iteration 5, loss = 0.69162132\n",
      "Iteration 6, loss = 0.69161493\n",
      "Iteration 7, loss = 0.69160871\n",
      "Iteration 8, loss = 0.69160266\n",
      "Iteration 9, loss = 0.69159680\n",
      "Iteration 10, loss = 0.69159112\n",
      "Iteration 11, loss = 0.69158564\n",
      "Iteration 12, loss = 0.69158035\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "436\n",
      "Iteration 1, loss = 0.69997182\n",
      "Iteration 2, loss = 0.69995431\n",
      "Iteration 3, loss = 0.69994320\n",
      "Iteration 4, loss = 0.69993231\n",
      "Iteration 5, loss = 0.69992161\n",
      "Iteration 6, loss = 0.69991114\n",
      "Iteration 7, loss = 0.69990093\n",
      "Iteration 8, loss = 0.69989102\n",
      "Iteration 9, loss = 0.69988142\n",
      "Iteration 10, loss = 0.69987213\n",
      "Iteration 11, loss = 0.69986315\n",
      "Iteration 12, loss = 0.69985448\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "437\n",
      "Iteration 1, loss = 0.69773903\n",
      "Iteration 2, loss = 0.69772618\n",
      "Iteration 3, loss = 0.69771802\n",
      "Iteration 4, loss = 0.69771004\n",
      "Iteration 5, loss = 0.69770219\n",
      "Iteration 6, loss = 0.69769450\n",
      "Iteration 7, loss = 0.69768702\n",
      "Iteration 8, loss = 0.69767974\n",
      "Iteration 9, loss = 0.69767269\n",
      "Iteration 10, loss = 0.69766587\n",
      "Iteration 11, loss = 0.69765928\n",
      "Iteration 12, loss = 0.69765292\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "438\n",
      "Iteration 1, loss = 0.69283866\n",
      "Iteration 2, loss = 0.69282433\n",
      "Iteration 3, loss = 0.69281523\n",
      "Iteration 4, loss = 0.69280632\n",
      "Iteration 5, loss = 0.69279757\n",
      "Iteration 6, loss = 0.69278901\n",
      "Iteration 7, loss = 0.69278066\n",
      "Iteration 8, loss = 0.69277255\n",
      "Iteration 9, loss = 0.69276470\n",
      "Iteration 10, loss = 0.69275710\n",
      "Iteration 11, loss = 0.69274975\n",
      "Iteration 12, loss = 0.69274266\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "439\n",
      "Iteration 1, loss = 0.69361477\n",
      "Iteration 2, loss = 0.69359642\n",
      "Iteration 3, loss = 0.69358477\n",
      "Iteration 4, loss = 0.69357337\n",
      "Iteration 5, loss = 0.69356217\n",
      "Iteration 6, loss = 0.69355121\n",
      "Iteration 7, loss = 0.69354053\n",
      "Iteration 8, loss = 0.69353016\n",
      "Iteration 9, loss = 0.69352013\n",
      "Iteration 10, loss = 0.69351042\n",
      "Iteration 11, loss = 0.69350103\n",
      "Iteration 12, loss = 0.69349197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "440\n",
      "Iteration 1, loss = 0.69037333\n",
      "Iteration 2, loss = 0.69036063\n",
      "Iteration 3, loss = 0.69035257\n",
      "Iteration 4, loss = 0.69034468\n",
      "Iteration 5, loss = 0.69033692\n",
      "Iteration 6, loss = 0.69032933\n",
      "Iteration 7, loss = 0.69032193\n",
      "Iteration 8, loss = 0.69031474\n",
      "Iteration 9, loss = 0.69030777\n",
      "Iteration 10, loss = 0.69030103\n",
      "Iteration 11, loss = 0.69029451\n",
      "Iteration 12, loss = 0.69028823\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "441\n",
      "Iteration 1, loss = 0.69687782\n",
      "Iteration 2, loss = 0.69686363\n",
      "Iteration 3, loss = 0.69685463\n",
      "Iteration 4, loss = 0.69684582\n",
      "Iteration 5, loss = 0.69683715\n",
      "Iteration 6, loss = 0.69682866\n",
      "Iteration 7, loss = 0.69682038\n",
      "Iteration 8, loss = 0.69681234\n",
      "Iteration 9, loss = 0.69680456\n",
      "Iteration 10, loss = 0.69679703\n",
      "Iteration 11, loss = 0.69678975\n",
      "Iteration 12, loss = 0.69678272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "442\n",
      "Iteration 1, loss = 0.68992623\n",
      "Iteration 2, loss = 0.68991409\n",
      "Iteration 3, loss = 0.68990639\n",
      "Iteration 4, loss = 0.68989884\n",
      "Iteration 5, loss = 0.68989142\n",
      "Iteration 6, loss = 0.68988416\n",
      "Iteration 7, loss = 0.68987709\n",
      "Iteration 8, loss = 0.68987021\n",
      "Iteration 9, loss = 0.68986355\n",
      "Iteration 10, loss = 0.68985710\n",
      "Iteration 11, loss = 0.68985088\n",
      "Iteration 12, loss = 0.68984487\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "443\n",
      "Iteration 1, loss = 0.69400564\n",
      "Iteration 2, loss = 0.69399189\n",
      "Iteration 3, loss = 0.69398317\n",
      "Iteration 4, loss = 0.69397462\n",
      "Iteration 5, loss = 0.69396623\n",
      "Iteration 6, loss = 0.69395801\n",
      "Iteration 7, loss = 0.69395001\n",
      "Iteration 8, loss = 0.69394224\n",
      "Iteration 9, loss = 0.69393471\n",
      "Iteration 10, loss = 0.69392742\n",
      "Iteration 11, loss = 0.69392038\n",
      "Iteration 12, loss = 0.69391358\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "444\n",
      "Iteration 1, loss = 0.69444082\n",
      "Iteration 2, loss = 0.69442820\n",
      "Iteration 3, loss = 0.69442019\n",
      "Iteration 4, loss = 0.69441235\n",
      "Iteration 5, loss = 0.69440465\n",
      "Iteration 6, loss = 0.69439712\n",
      "Iteration 7, loss = 0.69438978\n",
      "Iteration 8, loss = 0.69438265\n",
      "Iteration 9, loss = 0.69437575\n",
      "Iteration 10, loss = 0.69436906\n",
      "Iteration 11, loss = 0.69436261\n",
      "Iteration 12, loss = 0.69435639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "445\n",
      "Iteration 1, loss = 0.69684390\n",
      "Iteration 2, loss = 0.69682584\n",
      "Iteration 3, loss = 0.69681439\n",
      "Iteration 4, loss = 0.69680317\n",
      "Iteration 5, loss = 0.69679216\n",
      "Iteration 6, loss = 0.69678138\n",
      "Iteration 7, loss = 0.69677088\n",
      "Iteration 8, loss = 0.69676068\n",
      "Iteration 9, loss = 0.69675080\n",
      "Iteration 10, loss = 0.69674125\n",
      "Iteration 11, loss = 0.69673202\n",
      "Iteration 12, loss = 0.69672311\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "446\n",
      "Iteration 1, loss = 0.69288749\n",
      "Iteration 2, loss = 0.69287674\n",
      "Iteration 3, loss = 0.69286991\n",
      "Iteration 4, loss = 0.69286323\n",
      "Iteration 5, loss = 0.69285667\n",
      "Iteration 6, loss = 0.69285025\n",
      "Iteration 7, loss = 0.69284400\n",
      "Iteration 8, loss = 0.69283793\n",
      "Iteration 9, loss = 0.69283205\n",
      "Iteration 10, loss = 0.69282635\n",
      "Iteration 11, loss = 0.69282085\n",
      "Iteration 12, loss = 0.69281554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "447\n",
      "Iteration 1, loss = 0.69311002\n",
      "Iteration 2, loss = 0.69309752\n",
      "Iteration 3, loss = 0.69308958\n",
      "Iteration 4, loss = 0.69308181\n",
      "Iteration 5, loss = 0.69307417\n",
      "Iteration 6, loss = 0.69306670\n",
      "Iteration 7, loss = 0.69305942\n",
      "Iteration 8, loss = 0.69305234\n",
      "Iteration 9, loss = 0.69304549\n",
      "Iteration 10, loss = 0.69303886\n",
      "Iteration 11, loss = 0.69303245\n",
      "Iteration 12, loss = 0.69302626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "448\n",
      "Iteration 1, loss = 0.69034672\n",
      "Iteration 2, loss = 0.69033498\n",
      "Iteration 3, loss = 0.69032752\n",
      "Iteration 4, loss = 0.69032023\n",
      "Iteration 5, loss = 0.69031307\n",
      "Iteration 6, loss = 0.69030606\n",
      "Iteration 7, loss = 0.69029923\n",
      "Iteration 8, loss = 0.69029260\n",
      "Iteration 9, loss = 0.69028617\n",
      "Iteration 10, loss = 0.69027995\n",
      "Iteration 11, loss = 0.69027394\n",
      "Iteration 12, loss = 0.69026813\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "449\n",
      "Iteration 1, loss = 0.70179321\n",
      "Iteration 2, loss = 0.70176699\n",
      "Iteration 3, loss = 0.70175036\n",
      "Iteration 4, loss = 0.70173408\n",
      "Iteration 5, loss = 0.70171809\n",
      "Iteration 6, loss = 0.70170245\n",
      "Iteration 7, loss = 0.70168722\n",
      "Iteration 8, loss = 0.70167242\n",
      "Iteration 9, loss = 0.70165809\n",
      "Iteration 10, loss = 0.70164422\n",
      "Iteration 11, loss = 0.70163082\n",
      "Iteration 12, loss = 0.70161789\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "450\n",
      "Iteration 1, loss = 0.69346440\n",
      "Iteration 2, loss = 0.69345305\n",
      "Iteration 3, loss = 0.69344585\n",
      "Iteration 4, loss = 0.69343879\n",
      "Iteration 5, loss = 0.69343185\n",
      "Iteration 6, loss = 0.69342506\n",
      "Iteration 7, loss = 0.69341844\n",
      "Iteration 8, loss = 0.69341202\n",
      "Iteration 9, loss = 0.69340578\n",
      "Iteration 10, loss = 0.69339975\n",
      "Iteration 11, loss = 0.69339393\n",
      "Iteration 12, loss = 0.69338830\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "451\n",
      "Iteration 1, loss = 0.69276568\n",
      "Iteration 2, loss = 0.69275369\n",
      "Iteration 3, loss = 0.69274608\n",
      "Iteration 4, loss = 0.69273863\n",
      "Iteration 5, loss = 0.69273130\n",
      "Iteration 6, loss = 0.69272413\n",
      "Iteration 7, loss = 0.69271715\n",
      "Iteration 8, loss = 0.69271037\n",
      "Iteration 9, loss = 0.69270379\n",
      "Iteration 10, loss = 0.69269743\n",
      "Iteration 11, loss = 0.69269129\n",
      "Iteration 12, loss = 0.69268535\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69007378\n",
      "Iteration 2, loss = 0.69006131\n",
      "Iteration 3, loss = 0.69005340\n",
      "Iteration 4, loss = 0.69004565\n",
      "Iteration 5, loss = 0.69003803\n",
      "Iteration 6, loss = 0.69003057\n",
      "Iteration 7, loss = 0.69002330\n",
      "Iteration 8, loss = 0.69001624\n",
      "Iteration 9, loss = 0.69000940\n",
      "Iteration 10, loss = 0.69000278\n",
      "Iteration 11, loss = 0.68999638\n",
      "Iteration 12, loss = 0.68999020\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.0\n",
      "453\n",
      "Iteration 1, loss = 0.69366778\n",
      "Iteration 2, loss = 0.69365554\n",
      "Iteration 3, loss = 0.69364777\n",
      "Iteration 4, loss = 0.69364016\n",
      "Iteration 5, loss = 0.69363268\n",
      "Iteration 6, loss = 0.69362536\n",
      "Iteration 7, loss = 0.69361822\n",
      "Iteration 8, loss = 0.69361129\n",
      "Iteration 9, loss = 0.69360457\n",
      "Iteration 10, loss = 0.69359807\n",
      "Iteration 11, loss = 0.69359179\n",
      "Iteration 12, loss = 0.69358572\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "454\n",
      "Iteration 1, loss = 0.69545252\n",
      "Iteration 2, loss = 0.69543738\n",
      "Iteration 3, loss = 0.69542776\n",
      "Iteration 4, loss = 0.69541835\n",
      "Iteration 5, loss = 0.69540910\n",
      "Iteration 6, loss = 0.69540006\n",
      "Iteration 7, loss = 0.69539125\n",
      "Iteration 8, loss = 0.69538269\n",
      "Iteration 9, loss = 0.69537440\n",
      "Iteration 10, loss = 0.69536638\n",
      "Iteration 11, loss = 0.69535865\n",
      "Iteration 12, loss = 0.69535118\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "455\n",
      "Iteration 1, loss = 0.69849649\n",
      "Iteration 2, loss = 0.69847932\n",
      "Iteration 3, loss = 0.69846843\n",
      "Iteration 4, loss = 0.69845776\n",
      "Iteration 5, loss = 0.69844729\n",
      "Iteration 6, loss = 0.69843705\n",
      "Iteration 7, loss = 0.69842706\n",
      "Iteration 8, loss = 0.69841737\n",
      "Iteration 9, loss = 0.69840797\n",
      "Iteration 10, loss = 0.69839888\n",
      "Iteration 11, loss = 0.69839011\n",
      "Iteration 12, loss = 0.69838163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "456\n",
      "Iteration 1, loss = 0.69426455\n",
      "Iteration 2, loss = 0.69425404\n",
      "Iteration 3, loss = 0.69424736\n",
      "Iteration 4, loss = 0.69424083\n",
      "Iteration 5, loss = 0.69423440\n",
      "Iteration 6, loss = 0.69422812\n",
      "Iteration 7, loss = 0.69422199\n",
      "Iteration 8, loss = 0.69421604\n",
      "Iteration 9, loss = 0.69421027\n",
      "Iteration 10, loss = 0.69420468\n",
      "Iteration 11, loss = 0.69419929\n",
      "Iteration 12, loss = 0.69419408\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 1.0\n",
      "457\n",
      "Iteration 1, loss = 0.69466633\n",
      "Iteration 2, loss = 0.69465452\n",
      "Iteration 3, loss = 0.69464700\n",
      "Iteration 4, loss = 0.69463963\n",
      "Iteration 5, loss = 0.69463239\n",
      "Iteration 6, loss = 0.69462531\n",
      "Iteration 7, loss = 0.69461840\n",
      "Iteration 8, loss = 0.69461168\n",
      "Iteration 9, loss = 0.69460517\n",
      "Iteration 10, loss = 0.69459887\n",
      "Iteration 11, loss = 0.69459279\n",
      "Iteration 12, loss = 0.69458691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "458\n",
      "Iteration 1, loss = 0.69228785\n",
      "Iteration 2, loss = 0.69227611\n",
      "Iteration 3, loss = 0.69226866\n",
      "Iteration 4, loss = 0.69226137\n",
      "Iteration 5, loss = 0.69225419\n",
      "Iteration 6, loss = 0.69224718\n",
      "Iteration 7, loss = 0.69224033\n",
      "Iteration 8, loss = 0.69223369\n",
      "Iteration 9, loss = 0.69222725\n",
      "Iteration 10, loss = 0.69222101\n",
      "Iteration 11, loss = 0.69221499\n",
      "Iteration 12, loss = 0.69220917\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "459\n",
      "Iteration 1, loss = 0.69206153\n",
      "Iteration 2, loss = 0.69204956\n",
      "Iteration 3, loss = 0.69204197\n",
      "Iteration 4, loss = 0.69203453\n",
      "Iteration 5, loss = 0.69202722\n",
      "Iteration 6, loss = 0.69202007\n",
      "Iteration 7, loss = 0.69201310\n",
      "Iteration 8, loss = 0.69200632\n",
      "Iteration 9, loss = 0.69199976\n",
      "Iteration 10, loss = 0.69199340\n",
      "Iteration 11, loss = 0.69198726\n",
      "Iteration 12, loss = 0.69198133\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "460\n",
      "Iteration 1, loss = 0.69504365\n",
      "Iteration 2, loss = 0.69502767\n",
      "Iteration 3, loss = 0.69501752\n",
      "Iteration 4, loss = 0.69500759\n",
      "Iteration 5, loss = 0.69499783\n",
      "Iteration 6, loss = 0.69498827\n",
      "Iteration 7, loss = 0.69497896\n",
      "Iteration 8, loss = 0.69496991\n",
      "Iteration 9, loss = 0.69496115\n",
      "Iteration 10, loss = 0.69495267\n",
      "Iteration 11, loss = 0.69494447\n",
      "Iteration 12, loss = 0.69493656\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "461\n",
      "Iteration 1, loss = 0.69423321\n",
      "Iteration 2, loss = 0.69421838\n",
      "Iteration 3, loss = 0.69420897\n",
      "Iteration 4, loss = 0.69419975\n",
      "Iteration 5, loss = 0.69419069\n",
      "Iteration 6, loss = 0.69418184\n",
      "Iteration 7, loss = 0.69417322\n",
      "Iteration 8, loss = 0.69416484\n",
      "Iteration 9, loss = 0.69415670\n",
      "Iteration 10, loss = 0.69414883\n",
      "Iteration 11, loss = 0.69414122\n",
      "Iteration 12, loss = 0.69413388\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "462\n",
      "Iteration 1, loss = 0.69311545\n",
      "Iteration 2, loss = 0.69310361\n",
      "Iteration 3, loss = 0.69309610\n",
      "Iteration 4, loss = 0.69308876\n",
      "Iteration 5, loss = 0.69308156\n",
      "Iteration 6, loss = 0.69307454\n",
      "Iteration 7, loss = 0.69306771\n",
      "Iteration 8, loss = 0.69306107\n",
      "Iteration 9, loss = 0.69305463\n",
      "Iteration 10, loss = 0.69304841\n",
      "Iteration 11, loss = 0.69304240\n",
      "Iteration 12, loss = 0.69303659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "463\n",
      "Iteration 1, loss = 0.70099422\n",
      "Iteration 2, loss = 0.70097932\n",
      "Iteration 3, loss = 0.70096986\n",
      "Iteration 4, loss = 0.70096061\n",
      "Iteration 5, loss = 0.70095151\n",
      "Iteration 6, loss = 0.70094261\n",
      "Iteration 7, loss = 0.70093394\n",
      "Iteration 8, loss = 0.70092550\n",
      "Iteration 9, loss = 0.70091733\n",
      "Iteration 10, loss = 0.70090942\n",
      "Iteration 11, loss = 0.70090178\n",
      "Iteration 12, loss = 0.70089441\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "464\n",
      "Iteration 1, loss = 0.69124826\n",
      "Iteration 2, loss = 0.69123436\n",
      "Iteration 3, loss = 0.69122554\n",
      "Iteration 4, loss = 0.69121690\n",
      "Iteration 5, loss = 0.69120841\n",
      "Iteration 6, loss = 0.69120010\n",
      "Iteration 7, loss = 0.69119201\n",
      "Iteration 8, loss = 0.69118414\n",
      "Iteration 9, loss = 0.69117651\n",
      "Iteration 10, loss = 0.69116914\n",
      "Iteration 11, loss = 0.69116202\n",
      "Iteration 12, loss = 0.69115515\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "465\n",
      "Iteration 1, loss = 0.69516270\n",
      "Iteration 2, loss = 0.69514409\n",
      "Iteration 3, loss = 0.69513229\n",
      "Iteration 4, loss = 0.69512073\n",
      "Iteration 5, loss = 0.69510937\n",
      "Iteration 6, loss = 0.69509826\n",
      "Iteration 7, loss = 0.69508743\n",
      "Iteration 8, loss = 0.69507691\n",
      "Iteration 9, loss = 0.69506672\n",
      "Iteration 10, loss = 0.69505687\n",
      "Iteration 11, loss = 0.69504734\n",
      "Iteration 12, loss = 0.69503815\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "466\n",
      "Iteration 1, loss = 0.69523979\n",
      "Iteration 2, loss = 0.69522533\n",
      "Iteration 3, loss = 0.69521616\n",
      "Iteration 4, loss = 0.69520717\n",
      "Iteration 5, loss = 0.69519834\n",
      "Iteration 6, loss = 0.69518970\n",
      "Iteration 7, loss = 0.69518128\n",
      "Iteration 8, loss = 0.69517310\n",
      "Iteration 9, loss = 0.69516518\n",
      "Iteration 10, loss = 0.69515751\n",
      "Iteration 11, loss = 0.69515010\n",
      "Iteration 12, loss = 0.69514295\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "467\n",
      "Iteration 1, loss = 0.69266145\n",
      "Iteration 2, loss = 0.69264937\n",
      "Iteration 3, loss = 0.69264170\n",
      "Iteration 4, loss = 0.69263419\n",
      "Iteration 5, loss = 0.69262681\n",
      "Iteration 6, loss = 0.69261959\n",
      "Iteration 7, loss = 0.69261255\n",
      "Iteration 8, loss = 0.69260571\n",
      "Iteration 9, loss = 0.69259908\n",
      "Iteration 10, loss = 0.69259266\n",
      "Iteration 11, loss = 0.69258647\n",
      "Iteration 12, loss = 0.69258048\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "468\n",
      "Iteration 1, loss = 0.69808269\n",
      "Iteration 2, loss = 0.69806610\n",
      "Iteration 3, loss = 0.69805558\n",
      "Iteration 4, loss = 0.69804528\n",
      "Iteration 5, loss = 0.69803516\n",
      "Iteration 6, loss = 0.69802525\n",
      "Iteration 7, loss = 0.69801560\n",
      "Iteration 8, loss = 0.69800623\n",
      "Iteration 9, loss = 0.69799715\n",
      "Iteration 10, loss = 0.69798836\n",
      "Iteration 11, loss = 0.69797987\n",
      "Iteration 12, loss = 0.69797167\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "469\n",
      "Iteration 1, loss = 0.69371507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.69370316\n",
      "Iteration 3, loss = 0.69369561\n",
      "Iteration 4, loss = 0.69368821\n",
      "Iteration 5, loss = 0.69368094\n",
      "Iteration 6, loss = 0.69367382\n",
      "Iteration 7, loss = 0.69366689\n",
      "Iteration 8, loss = 0.69366016\n",
      "Iteration 9, loss = 0.69365364\n",
      "Iteration 10, loss = 0.69364733\n",
      "Iteration 11, loss = 0.69364124\n",
      "Iteration 12, loss = 0.69363536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "470\n",
      "Iteration 1, loss = 0.69321942\n",
      "Iteration 2, loss = 0.69320794\n",
      "Iteration 3, loss = 0.69320066\n",
      "Iteration 4, loss = 0.69319352\n",
      "Iteration 5, loss = 0.69318651\n",
      "Iteration 6, loss = 0.69317965\n",
      "Iteration 7, loss = 0.69317296\n",
      "Iteration 8, loss = 0.69316646\n",
      "Iteration 9, loss = 0.69316016\n",
      "Iteration 10, loss = 0.69315406\n",
      "Iteration 11, loss = 0.69314817\n",
      "Iteration 12, loss = 0.69314248\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "471\n",
      "Iteration 1, loss = 0.69471824\n",
      "Iteration 2, loss = 0.69470468\n",
      "Iteration 3, loss = 0.69469605\n",
      "Iteration 4, loss = 0.69468761\n",
      "Iteration 5, loss = 0.69467930\n",
      "Iteration 6, loss = 0.69467112\n",
      "Iteration 7, loss = 0.69466315\n",
      "Iteration 8, loss = 0.69465541\n",
      "Iteration 9, loss = 0.69464790\n",
      "Iteration 10, loss = 0.69464064\n",
      "Iteration 11, loss = 0.69463366\n",
      "Iteration 12, loss = 0.69462692\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "472\n",
      "Iteration 1, loss = 0.69747290\n",
      "Iteration 2, loss = 0.69745900\n",
      "Iteration 3, loss = 0.69745018\n",
      "Iteration 4, loss = 0.69744155\n",
      "Iteration 5, loss = 0.69743306\n",
      "Iteration 6, loss = 0.69742476\n",
      "Iteration 7, loss = 0.69741666\n",
      "Iteration 8, loss = 0.69740880\n",
      "Iteration 9, loss = 0.69740118\n",
      "Iteration 10, loss = 0.69739380\n",
      "Iteration 11, loss = 0.69738668\n",
      "Iteration 12, loss = 0.69737980\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "473\n",
      "Iteration 1, loss = 0.69238300\n",
      "Iteration 2, loss = 0.69236097\n",
      "Iteration 3, loss = 0.69234700\n",
      "Iteration 4, loss = 0.69233333\n",
      "Iteration 5, loss = 0.69231989\n",
      "Iteration 6, loss = 0.69230675\n",
      "Iteration 7, loss = 0.69229395\n",
      "Iteration 8, loss = 0.69228151\n",
      "Iteration 9, loss = 0.69226946\n",
      "Iteration 10, loss = 0.69225781\n",
      "Iteration 11, loss = 0.69224656\n",
      "Iteration 12, loss = 0.69223570\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "474\n",
      "Iteration 1, loss = 0.69106223\n",
      "Iteration 2, loss = 0.69104712\n",
      "Iteration 3, loss = 0.69103755\n",
      "Iteration 4, loss = 0.69102817\n",
      "Iteration 5, loss = 0.69101898\n",
      "Iteration 6, loss = 0.69100998\n",
      "Iteration 7, loss = 0.69100122\n",
      "Iteration 8, loss = 0.69099271\n",
      "Iteration 9, loss = 0.69098447\n",
      "Iteration 10, loss = 0.69097650\n",
      "Iteration 11, loss = 0.69096880\n",
      "Iteration 12, loss = 0.69096137\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "475\n",
      "Iteration 1, loss = 0.69144682\n",
      "Iteration 2, loss = 0.69143504\n",
      "Iteration 3, loss = 0.69142757\n",
      "Iteration 4, loss = 0.69142024\n",
      "Iteration 5, loss = 0.69141305\n",
      "Iteration 6, loss = 0.69140601\n",
      "Iteration 7, loss = 0.69139914\n",
      "Iteration 8, loss = 0.69139248\n",
      "Iteration 9, loss = 0.69138602\n",
      "Iteration 10, loss = 0.69137977\n",
      "Iteration 11, loss = 0.69137374\n",
      "Iteration 12, loss = 0.69136791\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "476\n",
      "Iteration 1, loss = 0.69578731\n",
      "Iteration 2, loss = 0.69576981\n",
      "Iteration 3, loss = 0.69575871\n",
      "Iteration 4, loss = 0.69574785\n",
      "Iteration 5, loss = 0.69573717\n",
      "Iteration 6, loss = 0.69572673\n",
      "Iteration 7, loss = 0.69571656\n",
      "Iteration 8, loss = 0.69570669\n",
      "Iteration 9, loss = 0.69569712\n",
      "Iteration 10, loss = 0.69568787\n",
      "Iteration 11, loss = 0.69567894\n",
      "Iteration 12, loss = 0.69567031\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "477\n",
      "Iteration 1, loss = 0.69406827\n",
      "Iteration 2, loss = 0.69405800\n",
      "Iteration 3, loss = 0.69405148\n",
      "Iteration 4, loss = 0.69404512\n",
      "Iteration 5, loss = 0.69403886\n",
      "Iteration 6, loss = 0.69403274\n",
      "Iteration 7, loss = 0.69402677\n",
      "Iteration 8, loss = 0.69402098\n",
      "Iteration 9, loss = 0.69401539\n",
      "Iteration 10, loss = 0.69400998\n",
      "Iteration 11, loss = 0.69400475\n",
      "Iteration 12, loss = 0.69399970\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "478\n",
      "Iteration 1, loss = 0.69775836\n",
      "Iteration 2, loss = 0.69774472\n",
      "Iteration 3, loss = 0.69773607\n",
      "Iteration 4, loss = 0.69772760\n",
      "Iteration 5, loss = 0.69771927\n",
      "Iteration 6, loss = 0.69771113\n",
      "Iteration 7, loss = 0.69770319\n",
      "Iteration 8, loss = 0.69769548\n",
      "Iteration 9, loss = 0.69768801\n",
      "Iteration 10, loss = 0.69768078\n",
      "Iteration 11, loss = 0.69767380\n",
      "Iteration 12, loss = 0.69766706\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "479\n",
      "Iteration 1, loss = 0.69463693\n",
      "Iteration 2, loss = 0.69462311\n",
      "Iteration 3, loss = 0.69461433\n",
      "Iteration 4, loss = 0.69460574\n",
      "Iteration 5, loss = 0.69459730\n",
      "Iteration 6, loss = 0.69458904\n",
      "Iteration 7, loss = 0.69458099\n",
      "Iteration 8, loss = 0.69457317\n",
      "Iteration 9, loss = 0.69456559\n",
      "Iteration 10, loss = 0.69455826\n",
      "Iteration 11, loss = 0.69455117\n",
      "Iteration 12, loss = 0.69454433\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "480\n",
      "Iteration 1, loss = 0.69776040\n",
      "Iteration 2, loss = 0.69774668\n",
      "Iteration 3, loss = 0.69773797\n",
      "Iteration 4, loss = 0.69772944\n",
      "Iteration 5, loss = 0.69772106\n",
      "Iteration 6, loss = 0.69771286\n",
      "Iteration 7, loss = 0.69770487\n",
      "Iteration 8, loss = 0.69769711\n",
      "Iteration 9, loss = 0.69768959\n",
      "Iteration 10, loss = 0.69768232\n",
      "Iteration 11, loss = 0.69767529\n",
      "Iteration 12, loss = 0.69766851\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "481\n",
      "Iteration 1, loss = 0.70039991\n",
      "Iteration 2, loss = 0.70038168\n",
      "Iteration 3, loss = 0.70037012\n",
      "Iteration 4, loss = 0.70035879\n",
      "Iteration 5, loss = 0.70034768\n",
      "Iteration 6, loss = 0.70033682\n",
      "Iteration 7, loss = 0.70032624\n",
      "Iteration 8, loss = 0.70031596\n",
      "Iteration 9, loss = 0.70030601\n",
      "Iteration 10, loss = 0.70029636\n",
      "Iteration 11, loss = 0.70028704\n",
      "Iteration 12, loss = 0.70027804\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "482\n",
      "Iteration 1, loss = 0.69592278\n",
      "Iteration 2, loss = 0.69590807\n",
      "Iteration 3, loss = 0.69589874\n",
      "Iteration 4, loss = 0.69588960\n",
      "Iteration 5, loss = 0.69588062\n",
      "Iteration 6, loss = 0.69587182\n",
      "Iteration 7, loss = 0.69586326\n",
      "Iteration 8, loss = 0.69585493\n",
      "Iteration 9, loss = 0.69584686\n",
      "Iteration 10, loss = 0.69583905\n",
      "Iteration 11, loss = 0.69583151\n",
      "Iteration 12, loss = 0.69582423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "483\n",
      "Iteration 1, loss = 0.69104651\n",
      "Iteration 2, loss = 0.69103413\n",
      "Iteration 3, loss = 0.69102628\n",
      "Iteration 4, loss = 0.69101859\n",
      "Iteration 5, loss = 0.69101103\n",
      "Iteration 6, loss = 0.69100363\n",
      "Iteration 7, loss = 0.69099642\n",
      "Iteration 8, loss = 0.69098941\n",
      "Iteration 9, loss = 0.69098262\n",
      "Iteration 10, loss = 0.69097604\n",
      "Iteration 11, loss = 0.69096968\n",
      "Iteration 12, loss = 0.69096353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "484\n",
      "Iteration 1, loss = 0.69206049\n",
      "Iteration 2, loss = 0.69204655\n",
      "Iteration 3, loss = 0.69203771\n",
      "Iteration 4, loss = 0.69202905\n",
      "Iteration 5, loss = 0.69202054\n",
      "Iteration 6, loss = 0.69201220\n",
      "Iteration 7, loss = 0.69200408\n",
      "Iteration 8, loss = 0.69199619\n",
      "Iteration 9, loss = 0.69198855\n",
      "Iteration 10, loss = 0.69198115\n",
      "Iteration 11, loss = 0.69197400\n",
      "Iteration 12, loss = 0.69196710\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "485\n",
      "Iteration 1, loss = 0.69417140\n",
      "Iteration 2, loss = 0.69415852\n",
      "Iteration 3, loss = 0.69415035\n",
      "Iteration 4, loss = 0.69414235\n",
      "Iteration 5, loss = 0.69413449\n",
      "Iteration 6, loss = 0.69412679\n",
      "Iteration 7, loss = 0.69411930\n",
      "Iteration 8, loss = 0.69411202\n",
      "Iteration 9, loss = 0.69410497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.69409815\n",
      "Iteration 11, loss = 0.69409156\n",
      "Iteration 12, loss = 0.69408520\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "486\n",
      "Iteration 1, loss = 0.69499140\n",
      "Iteration 2, loss = 0.69497373\n",
      "Iteration 3, loss = 0.69496254\n",
      "Iteration 4, loss = 0.69495159\n",
      "Iteration 5, loss = 0.69494082\n",
      "Iteration 6, loss = 0.69493029\n",
      "Iteration 7, loss = 0.69492003\n",
      "Iteration 8, loss = 0.69491007\n",
      "Iteration 9, loss = 0.69490041\n",
      "Iteration 10, loss = 0.69489107\n",
      "Iteration 11, loss = 0.69488205\n",
      "Iteration 12, loss = 0.69487335\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "487\n",
      "Iteration 1, loss = 0.69652445\n",
      "Iteration 2, loss = 0.69651037\n",
      "Iteration 3, loss = 0.69650143\n",
      "Iteration 4, loss = 0.69649268\n",
      "Iteration 5, loss = 0.69648410\n",
      "Iteration 6, loss = 0.69647572\n",
      "Iteration 7, loss = 0.69646755\n",
      "Iteration 8, loss = 0.69645961\n",
      "Iteration 9, loss = 0.69645192\n",
      "Iteration 10, loss = 0.69644447\n",
      "Iteration 11, loss = 0.69643728\n",
      "Iteration 12, loss = 0.69643033\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "488\n",
      "Iteration 1, loss = 0.69169095\n",
      "Iteration 2, loss = 0.69167909\n",
      "Iteration 3, loss = 0.69167157\n",
      "Iteration 4, loss = 0.69166420\n",
      "Iteration 5, loss = 0.69165697\n",
      "Iteration 6, loss = 0.69164988\n",
      "Iteration 7, loss = 0.69164297\n",
      "Iteration 8, loss = 0.69163626\n",
      "Iteration 9, loss = 0.69162976\n",
      "Iteration 10, loss = 0.69162346\n",
      "Iteration 11, loss = 0.69161738\n",
      "Iteration 12, loss = 0.69161151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "489\n",
      "Iteration 1, loss = 0.69414416\n",
      "Iteration 2, loss = 0.69413195\n",
      "Iteration 3, loss = 0.69412422\n",
      "Iteration 4, loss = 0.69411665\n",
      "Iteration 5, loss = 0.69410921\n",
      "Iteration 6, loss = 0.69410193\n",
      "Iteration 7, loss = 0.69409484\n",
      "Iteration 8, loss = 0.69408795\n",
      "Iteration 9, loss = 0.69408127\n",
      "Iteration 10, loss = 0.69407481\n",
      "Iteration 11, loss = 0.69406856\n",
      "Iteration 12, loss = 0.69406253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "490\n",
      "Iteration 1, loss = 0.69316957\n",
      "Iteration 2, loss = 0.69315582\n",
      "Iteration 3, loss = 0.69314709\n",
      "Iteration 4, loss = 0.69313855\n",
      "Iteration 5, loss = 0.69313015\n",
      "Iteration 6, loss = 0.69312194\n",
      "Iteration 7, loss = 0.69311395\n",
      "Iteration 8, loss = 0.69310618\n",
      "Iteration 9, loss = 0.69309866\n",
      "Iteration 10, loss = 0.69309138\n",
      "Iteration 11, loss = 0.69308435\n",
      "Iteration 12, loss = 0.69307756\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "491\n",
      "Iteration 1, loss = 0.69544260\n",
      "Iteration 2, loss = 0.69542958\n",
      "Iteration 3, loss = 0.69542132\n",
      "Iteration 4, loss = 0.69541322\n",
      "Iteration 5, loss = 0.69540527\n",
      "Iteration 6, loss = 0.69539748\n",
      "Iteration 7, loss = 0.69538989\n",
      "Iteration 8, loss = 0.69538252\n",
      "Iteration 9, loss = 0.69537538\n",
      "Iteration 10, loss = 0.69536847\n",
      "Iteration 11, loss = 0.69536179\n",
      "Iteration 12, loss = 0.69535534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "492\n",
      "Iteration 1, loss = 0.69501061\n",
      "Iteration 2, loss = 0.69500028\n",
      "Iteration 3, loss = 0.69499372\n",
      "Iteration 4, loss = 0.69498730\n",
      "Iteration 5, loss = 0.69498099\n",
      "Iteration 6, loss = 0.69497482\n",
      "Iteration 7, loss = 0.69496880\n",
      "Iteration 8, loss = 0.69496295\n",
      "Iteration 9, loss = 0.69495729\n",
      "Iteration 10, loss = 0.69495180\n",
      "Iteration 11, loss = 0.69494650\n",
      "Iteration 12, loss = 0.69494139\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "493\n",
      "Iteration 1, loss = 0.69123940\n",
      "Iteration 2, loss = 0.69122305\n",
      "Iteration 3, loss = 0.69121267\n",
      "Iteration 4, loss = 0.69120250\n",
      "Iteration 5, loss = 0.69119252\n",
      "Iteration 6, loss = 0.69118275\n",
      "Iteration 7, loss = 0.69117323\n",
      "Iteration 8, loss = 0.69116397\n",
      "Iteration 9, loss = 0.69115500\n",
      "Iteration 10, loss = 0.69114631\n",
      "Iteration 11, loss = 0.69113793\n",
      "Iteration 12, loss = 0.69112983\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "494\n",
      "Iteration 1, loss = 0.69702315\n",
      "Iteration 2, loss = 0.69701080\n",
      "Iteration 3, loss = 0.69700295\n",
      "Iteration 4, loss = 0.69699527\n",
      "Iteration 5, loss = 0.69698772\n",
      "Iteration 6, loss = 0.69698033\n",
      "Iteration 7, loss = 0.69697312\n",
      "Iteration 8, loss = 0.69696612\n",
      "Iteration 9, loss = 0.69695934\n",
      "Iteration 10, loss = 0.69695277\n",
      "Iteration 11, loss = 0.69694643\n",
      "Iteration 12, loss = 0.69694031\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "495\n",
      "Iteration 1, loss = 0.69056936\n",
      "Iteration 2, loss = 0.69055389\n",
      "Iteration 3, loss = 0.69054407\n",
      "Iteration 4, loss = 0.69053446\n",
      "Iteration 5, loss = 0.69052501\n",
      "Iteration 6, loss = 0.69051577\n",
      "Iteration 7, loss = 0.69050677\n",
      "Iteration 8, loss = 0.69049802\n",
      "Iteration 9, loss = 0.69048955\n",
      "Iteration 10, loss = 0.69048135\n",
      "Iteration 11, loss = 0.69047342\n",
      "Iteration 12, loss = 0.69046578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "496\n",
      "Iteration 1, loss = 0.69459179\n",
      "Iteration 2, loss = 0.69457818\n",
      "Iteration 3, loss = 0.69456956\n",
      "Iteration 4, loss = 0.69456113\n",
      "Iteration 5, loss = 0.69455284\n",
      "Iteration 6, loss = 0.69454473\n",
      "Iteration 7, loss = 0.69453683\n",
      "Iteration 8, loss = 0.69452916\n",
      "Iteration 9, loss = 0.69452171\n",
      "Iteration 10, loss = 0.69451451\n",
      "Iteration 11, loss = 0.69450755\n",
      "Iteration 12, loss = 0.69450082\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "497\n",
      "Iteration 1, loss = 0.69356263\n",
      "Iteration 2, loss = 0.69354919\n",
      "Iteration 3, loss = 0.69354066\n",
      "Iteration 4, loss = 0.69353231\n",
      "Iteration 5, loss = 0.69352411\n",
      "Iteration 6, loss = 0.69351607\n",
      "Iteration 7, loss = 0.69350825\n",
      "Iteration 8, loss = 0.69350064\n",
      "Iteration 9, loss = 0.69349327\n",
      "Iteration 10, loss = 0.69348614\n",
      "Iteration 11, loss = 0.69347925\n",
      "Iteration 12, loss = 0.69347259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n",
      "498\n",
      "Iteration 1, loss = 0.69202618\n",
      "Iteration 2, loss = 0.69201423\n",
      "Iteration 3, loss = 0.69200664\n",
      "Iteration 4, loss = 0.69199921\n",
      "Iteration 5, loss = 0.69199191\n",
      "Iteration 6, loss = 0.69198476\n",
      "Iteration 7, loss = 0.69197780\n",
      "Iteration 8, loss = 0.69197103\n",
      "Iteration 9, loss = 0.69196447\n",
      "Iteration 10, loss = 0.69195812\n",
      "Iteration 11, loss = 0.69195199\n",
      "Iteration 12, loss = 0.69194606\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.67\n",
      "499\n",
      "Iteration 1, loss = 0.69471853\n",
      "Iteration 2, loss = 0.69470759\n",
      "Iteration 3, loss = 0.69470065\n",
      "Iteration 4, loss = 0.69469385\n",
      "Iteration 5, loss = 0.69468716\n",
      "Iteration 6, loss = 0.69468062\n",
      "Iteration 7, loss = 0.69467424\n",
      "Iteration 8, loss = 0.69466805\n",
      "Iteration 9, loss = 0.69466204\n",
      "Iteration 10, loss = 0.69465623\n",
      "Iteration 11, loss = 0.69465061\n",
      "Iteration 12, loss = 0.69464519\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.33\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,500):\n",
    "    print(i)\n",
    "    buildPreceptron(X_train, X_test, y_train, y_test, num_neurons=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a394d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
